いうところでビジネスアドオンとビジネスかける生成AIというトピックにですね 非常に多くの方が関心を持たれているのかなというふうに
認識しています 本日ですねまさにこういった生成AIの業界にですね
多様な立場から携わっておられる 本当にトップランナーの方々をお招きしまして
時間が許す限りですね 語り尽くせればと思っていますのでどうぞよろしくお願いします
今多分私しか映ってないと思うんですけども こちらトップランナーの方々がおりまして
すごくアットホームな雰囲気で渋谷のスタジオからお送りさせていただいております 今日ぜひですね試験の話もあってちょっとやりますけれども
JDLAのGenerative AIテスト こちらの試験作成の時のアットホームなですね
感じもちょっと出しながらお話しできればと思います よろしくお願いします
では早速ですねイベントの方を進めさせていただければと思いますけれども 本日ですねこちらのようなアジェンダで進めさせていただければというふうに思います
生成AIかけるビジネスというところですね 私もデロイドマツにおりまして本当に日々ですねいろんな方々とお話しさせていただくんですけども
生成AIのですね話題が出ないことはないっていうぐらいですね 本当に非常に多くの方々がビジネスかける生成AIにご関心を持ちであると
ただ一方でですね非常にいろんな課題もあるところで どうやって使えばいいのかわからないとかですね
結局何ができるのかわからないとかですね そういった課題感であったりとか一方でその生成AIをどうやってビジネスに活用していくかって
大きな方向性みたいなのが結構見えてきているところがありまして そのあたりのですね試験のところとかも今回ですね
いろいろと挟んでお話しできればというふうに考えております 本日ですね大きく3つのパネルディスカッションを用意しておりまして
生成AIの技術利活用それからリスクのところですね 大きくこの3つのテーマでですねトップランナーたちと一緒にディスカッションできればというふうに考えております
まずあのちょっと私の方からですね冒頭ちょっとお時間いただきまして 生成AIに関してですねこのパネルディスカッションの前提といいますか
結局どういったところが従来のAIと違うのかみたいなところです ちょっと簡単にお話しさせていただいて その後にですねパネルディスカッションに移れればと思いますよろしくお願いします
でこれどっから話そうかというふうにですね あちょっと渋谷っぽい音が聞こえておりますけれども
生放送あるあるですかね
はいちょっと気を取り直して
はい 生成AIも非常に多くのトピックがある中でどっから話そうかというふうにちょっと考えた中ですね
今日はちょっと生成AIの影響のところからお話しできればなというふうに思います 皆さんご承知の通りですね生成AIも本当に多方面に大きな影響を与えているかなと
ただ一方でですね特徴がすごくあるなというふうに思っているのが ちょっとここですねあの間口をコンサルっぽくちょっとまとめておりますけれども
まあこれからですねおそらくどんどんトピックに上がってくると思いますけれども 生成AI 言葉を使って振る舞いをコントロールできるという非常に大きな特徴があって
であるがゆえに誰でも使えるというようなところが大きな特徴であると なのでちょっと3巻
学民というふうに書かせていただいておりますけれども 特にあの民のところですね 利用者側への影響が非常に大きくて
2022年11月30日にチャットGPTが出ましたけれども その当時ですね1週間で100万ユーザー
2ヶ月で1億ユーザーに到達したということで 人間がこれまで作ったものの中で最も早い
普及速度であるというふうに言われていることです こういった民へのユーザー側への大きな影響が起点となってですね
3巻学それぞれに影響を与えているのかなというふうに認識しています 特にこちらのですね左側3への影響のところがまさに本日の
トピックであるビジネスかける生成アイのところになるのかなというふうに思います
なぜですねこんな感じで利用者にとって非常に大きな影響を与えているのかといった ところですねこれまでのAIとの違いといったところからちょっとひもときて
ひもときたいというふうに思います こちらですねこれまでのAI生成AI以前のAIで特に用途特化型の
AIについてその振る舞いというものですね ちょっと端的に表した図になりますけれども
これまでAIってデータが活用できるいろんなところでですね モデルが構築されて活用されてきたわけですけれども
それぞれですね用途に応じてAIをモデルをですね 作る必要があったかなというふうに思います
作ったAIを使う際はですね 入力データとして決まった形式を入れてですね
出力データとして決まった形式を想定すると こういった形だったのかなと
例えば一番上のところにありますけれども 例えば中古商品のですね価格を予測するようなAIでしたら
その商品に関する情報を入力データとして入れて それに基づいて予測価格を出力するといったような
決まった形式の入力と出力があって 用途に応じたAIを作る必要があったと
その下はローン申し込み者データの 申し込み者がですね信用に足るかを判定するようなAIですけれども
こちらも同様ですね その以下も同様であると
要は入出力の形式があらかじめ決められた形式であって それぞれ用途に特化したAIを作る必要があったというところが
これまでのAIかなというふうに思います これに対してですね生成AI 例えばチャットGPTのような対話型AIを例にとりますと
先ほどのような構図がですねちょっと一変しますと まずあの
すぐ分かるのがモデルですね 真ん中にあります生成AIがですね 先ほど用途ごとにそれぞれ3つあったと思うんですけれども
それが一つでいいと かつですね入力データが自然文になっていると ユーザーが与える自然言語ですね
AIとは何ですかとかですねコールセンターの オペレーターとして振る舞ってくださいとかですね
先ほどは決められた形式だったのが自然言語という 非常に柔軟で自由な入力データになったと
それに対して主翼データもですね入力データ 自然文に合わせてですね柔軟に主翼をしてくれるといったような形になっています
ここで非常に重要かなというふうに思うのがですね 人間であれば誰でも使えるような言葉というものを持ってですね
AIの振る舞いをコントロールできるようになったと これが非常に大きな特徴であるかなというふうに思います
前までは用途ごとにAIを作る必要がありましたので 用途ごとにですね専門家が作る必要があった
プログラミング言語とかあったりとか 技術をちゃんと学んでですね作る必要があったんですけども
今あの人間であれば誰もが使える言葉でもって振る舞いを コントロールできるということは
従来のAIの専門家がやっていたのことをですね 普通の誰でも誰もができるようになったと
そういった時代になったかなというふうに思います 本当にあの誰もが簡単にですね
どこでも最先端のAIを活用できる時代になったのかなというふうに思います
あるがゆえにですね誰でも使えるという特徴があると これをですねビジネスに適応していく
ビジネスで導入していくということを考えると いかに自信を持ってですね活用していけるかが
ポイントであるかなというふうに思います
ただこういったですねあの自信を持った活用というのは 非常に難しいということが結構ですね
いろいろなお客様であったりいろいろな人と話している中ですごく思うことに なります
これはまあ誰もが使えるという特徴があるがゆえの難しさであるというふうにも ちょっと感じてまして
まあ誰もが使えるので世界中でですね新たな活用の方法 いろんな人が見出していていろんなメディアで発信してるんですよね
情報がすごく溢れているような形ですごく煩雑ですね 結局何ができるのかわからないっていうことが結構課題としてあるのかなというふうに思います
まあこちら書かせていただいているところですと 体系的な理解が難しいというところに相当しますね
さらにまあそれにまあ気にするんでしょうけども 業務のどこに生成が活用できるかわからないであったりとかですね
あとはリテイラーシーが足りない 具体的なリスク対策の方法がわからないといった具体的な課題も出てきていると
こういったところから本日ですね 本イベントにご参加の皆様がですね 自信を持って生成AIを活用していくために必要なですね
こういった課題の解決をですね 本日のトークをパネルディスカンションを通してぜひですね
獲得 課題解決の一つのツールとしてですね 扱っていただければというふうに考えています
特にあの体系的な理解のところですと生成の技術 利活用 リスクで誰でも使えるというところを考えるとやはりですね
基本的な技術のところを踏まえつつ利活用とですね リスクについてちゃんと知るというところが非常に重要かなと思います
なのでまあ本日こちらのですね あの3つのテーマでもってパネルディスカッションの方で進めさせていただければと思います
最後にですねあのJDLA ジェネレティブAIテストということでまさにこういった課題をですね 解決する一つのツールとして
我々はこのJDLAのジェネレティブAIテストをですね 開発しているところになります
ここでは誰もが使えるですね この生成AIをちゃんとビジネスで皆さんが主体的に
活用を推進していけるようなそういったテストを目指しておりまして まさにそういったテーマとですね本日のパネルディスカッションのテーマはもうオーバーラップ
しておりますので まさにこちらのJDLA ジェネレティブAIテストの試験作成に関わる
プロジェクトメンバーでもってですね パネルディスカッションの方をやらせていただければというふうに考えています
ちょっとあの私の方からの話はですね これくらいにしておいて ここからですね実際にパネルディスカッションの方にですね 入っていければというふうに思います
まずはですね 生成AIの技術についてのパネルになります それぞれのパネルディスカッションのところでですね メインパネラーということで
3名もしくは2名ですね ちょっと選出させていただきました ちょっとあの進め方なんですけれども メインパネラーの方にメインでお話ししていただく一方でですね
おそらくかなり多様な話題が出てきますので ちょっとはそれに応じてですね メインパネラーじゃない方もですね ぜひ口を挟んでいただければと思いますので
ぜひ積極的なご発言を いつも通り試験作成している時のような感じですね
挟んでいただければと思いますので どうぞよろしくお願いします じゃあまずはですね 生成AIの技術のところでメインパネラーとしてですね
井上さん 川原先生 そして佐々木さんの3名でお送りさせていただければと思います
ちょっとあの3名ですね それぞれの自己紹介の方をしていただければと思います その際にですね ぜひ生成AIの関わり方とか 生成AIが自身に与えた影響とかですね
そのあたりもちょっと交えてお話しいただければ最後です 井上さんからよろしくお願いします
はい 株式会社エリスのファウンダーエンドシートをやってます 井上光輝と申します
普段はですね 東区大学の医学研究科の博士教育課程2年で 医療とLLMの研究をしておりまして
で あとはLLMの関わり方で言いますと 雑誌に寄稿させていただいたりとか 勢力的な活動をしております
で 私が与えた影響で言うと 私は博士教育課程でもともとセグメンテーションといろいろな研究をやってたんですけど
なぜかLLMが研究テーマに変わりまして 博士のっていうぐらいインパクトが自分的にでかくて 最近変わったんですけど
なのでそれぐらいインパクトが大きいなっていうぐらいのすごいものでした
ちょっとすごい大変なんですけど 頑張ってます 以上です ありがとうございます
はい 川原と申します 私は大瀬田大学で自然言語処理の研究をしておりまして
もう25、6年 この自然言語処理の研究をしております
2018年にGPTとかBERTとか そういったモデルが出てきて そこでも結構驚いたんですけど
かなりいろんなタスクで高精度にいろんなタスクが解けるというふうになりました
さらに先ほども話ありましたけれども 2022年の11月にJAT GPTが出てきまして さらにびっくりしまして
我々研究者の中でもかなりこれはできるぞみたいな話になりまして
そこからもすごい勢いでいろんな生成AIのモデルが出てきて ずっとびっくりし続けるという
そういった有り様です よろしくお願いいたします
はい よろしくお願いします スパイラルAIの佐々木と申します
もともとですね ニューラルポケットっていう会社のCTOをやっていたんですけれども
そちらから今 生成AI 文書処理系のところに 独立して会社を立ち上げたような形になっております
私が一番この転機にひとつきっかけになったところでいくと 去年の夏頃ですかね
Galacticaっていうメタが作った言語モデルがありました
何かっていうと 科学論文とかに対して非常に高精度に答えてくれるとか
非常にすごい知識持ってるとか そういうものがありまして
私もともと出身自体も研究者なんですけれども その業界がですね
もはや一振されそうな すごいパワフルさを感じたと
ちょっと残念ながらパワフルすぎるのと 当時まだハルシネーションの問題とか色々あったんで
3日ぐらいでちょっと閉じられちゃった企画になりましたけれども
でもそういう非常に強いパワーを持ったものが 言語モデルであるというところに衝撃を受けてですね
今後の繁盛を言語モデル業界に捧げていこうかなというふうに思ったという経緯になります
よろしくお願いいたします
ありがとうございます
ではまずはですね 生成AIの技術について このメインパネルの3名とですね
お話ししていければと思います
ちょっとおそらく話題がですね 結構発散するというところのリスクも見越しまして
簡単に私の方から前提となるような知識のところを 最大限抑えておかなければならないようなところについて
お話しさせていただきたいと思います
今ですね ちょっとスライド投影させていただいておりますけれども
まず人工知能と呼ばれるですね 技術がどのように進化してきたのか
ちょっと汎用性と性能というものを それぞれ横軸縦軸にとってですね
これはあくまでイメージ図なんですけれども
ちょっとその進化をですね 辿れるような整理をさせていただきました
一番左にありますルールベースの種
これをですね 人工知能と呼ぶかどうかというのも 意見が分かれるところだと思うんですけど
基本的に全処理を人間が作るところから 機械学習という技術が出てきて
これはデータに基づいてその特徴を学習して それを再表現するようなそういった技術になりますね
そういったところから真相学習といって
特に出力に影響を与える入力データの中で 非常に特徴的な成分ですね
特徴量と言われるものを自動的に抽出できるようになったと
さらにトランスフォーマーベースの手法というふうに 書かせていただきましたけれども
チャットGPTとのベースになっている技術になりますけれども
2017年18年ぐらいですかね
あらかじめ大量の言語データを与えることによって 基礎的な言語能力を身につけた上で
用途に特化させるところについては そのモデルのですね
微妙な微修正というんですかね
ファインチューニング等で行えるようになった といった技術になります
こういったファインチューニングであったりとか
あとは追加的な強化学習等をですね
このLLM トランスフォーマーベースの手法が 適用されたモデルに適用すると
しかもその適用の仕方をですね
人間へのアラインというふうに 書かせていただきましたけれども
自然で倫理的な受け答えに特化したような ファインチューニングであったり
強化学習をかけることによって
チャットGPTのような倫理性であったりとか
そういったかなり人間に近しい振る舞いをするような
先進的なLLMができたというふうに 言われているところになります
こういった技術的な進化があって
先ほど冒頭にお話ししたような
言葉で挙動をコントロールできるような そういったAIができたと
大きくはこういったAIの進化が あったのかなというふうに思います
ちょっとこういったですね AIの進化
そういったところを踏まえまして
パネルディスカッションの方に 移らせていただければと思います
本日ですね それぞれのパネルについて
4つのテーマを用意しておりまして
私の独断と偏見
もしくは視聴者の方からの多数決で
テーマを決めていければと思います
まずは私の方から独断と偏見でですね
偏見じゃない 独断でですね
Aのところですね 最先端のLLM
結局何がすごいのかと
今ちょっとAIの進化のところを お話しさせていただきましたけども
特にお三方から見て
ご意見を伺えればと思います
まず川原先生 いかがでしょうか
はい 何がすごいのかということですけれども
2点あると思います
1つ目は先ほど山本さんがおっしゃったように
汎用性ですよね
自然言語で指示をできるという点にあります
もう1個 高性能さんにありまして
すごい流暢な日本語でも英語でも
言語を返してくるというところが 大きいと思います
それはなぜできているのかというと
分かんないんですけれども
よく言われるのはスケーリングローって言って
モデルの大きさ パラメーター数とか言いますけれど
モデルの複雑さが大きくなると
それに伴って高性能になると
さらに学習するテキスト量を増やしていくと
どんどん賢くなると
そういったところにあって
それによって高性能さが出てきているというところが
すごいというところだと思います
ありがとうございます
このなぜ良くなっているのか分からないと
すごく惹かれるんですけれども
こういったなぜ良くなっているのかというところに
対する研究もいます
アカデミアのところでは進んでいるんでしょうか
いろんな研究がなされておりますし
なんで例えばチャットGPで
ほとんど英語でしか学習していないのに
日本語もかなりしゃべれるのはなぜだろうというところもありまして
いろんな研究がなされてますけれども
まだ全然分かってないというところだと思います
ありがとうございます
ではぜひですね
井上さん
人生を変えたLLMというふうに先ほどおっしゃってました
そうですね 私の人生を変えてくれたLLMなんですけど
2つあると思ってまして
1つ目がシンプルにパラメータ数というのがあると思います
例えば今までの言語モデルというのは
BERTとかだと3.4億ぐらいのパラメータ数があって
GPT3.5とかだと
これリファレンスちゃんとないんですけど
3.550億ぐらいのパラメータ数があるんですね
シンプルに1000倍ぐらい違うというところがまず1つあって
2つ目が先ほど川原先生おっしゃってくれたんですけど
ゼロショットの性能の良さというところで
今まではやはり学習しないと性能が出なかったんですけど
そこが学習しなくてもゼロショットである程度も使えものになると
素晴らしいところかなというふうに認識しております
以上です
ありがとうございます
一方でこれまでのAIを知っている我々からすると
パラメータ数が多いということは
説明可能性というんですかね
なぜそのAIがその出力を出したのかという
根拠が分かりづらくなるという
負の側面があると思うんですけど
このあたりについてはいかがお考えですかね
透明性みたいなところは
もともとグラッドカムとか画像だとあったんですけど
このあたりも今後研究が進んでいくんだろうなと
画像でもそういう流れになって
後に発展していったので
言語モデルでもこういうふうに進んでいくと思います
なるほど
結構先ほどの川原先生のお話じゃないですけど
何で良くなっているのか分からないというところがありつつも
パラメータ数が多くなることによって
さらに説明可能性というところが
多分損なわれていくという側面もありつつも
ただですね
ChatGPTとの先進的なエネルギーに
根拠と共に教えてくださいというとですね
人間が納得するような形で根拠を教えてくれるんですよね
なぜその根拠が出てくるのかというのは
理解はすごく難しいと思うんですよ
パラメータ数が多いから
一方で人間が理解しやすい
情報を得ることは簡単になっている
すごいトレードオフというんですかね
アンバランスな感じがすごいしてるんですよね
そのあたり何かご意見等お持ちでしょうか
そうですね
結構発散しそうな話題かなと
これ僕ばっかり喋って大丈夫ですか
何だろうな
このあたりは
頑張り屋さんな新入社員みたいなイメージがあって
とりあえず何でも喋るんですよ間違えてても
なのでこの辺のファインチューニングが
後で出てくると思うんですけど
ちゃんと学習で
そこら辺を学習させるみたいな必要で
後でまたこれ出ると思うんですけど
ラグとか最近あると思うんですけど
あれ使っても
やっぱり答えなんとなく出しちゃうみたいな
あったりするんで
ファインチューニングとか
もっとそれ以前のAIのルールベースであったりとか
そういうところが必要になってくるのかな
というふうに思ってます
ありがとうございます
まさに何かビジネス×性性愛の話題に
何か繋がりそうな回答いただきたいなと思いました
ありがとうございます
ありがとうございました
じゃあぜひ佐々木さんの方からも
これからの人生をLLMに捧げますと
おっしゃっておりましたけれども
やっぱすごいのは
お二方おっしゃった通りだと思うんですよね
まずいわゆるインコンテキストラーニングと呼ばれる
チューニング独自に学習させなくても
文章でこうしてくださいって言えば
どんなタスクでもやってくれますっていう
この手軽さは
もう何者にも変えがたい
それまでって結局GPU
いわゆるBERTの時代だと
まだタスクごとに
チューニングしないと性能出ないよね
っていう時代だったわけです
こうなると結局GPU持ってないとどうしようもないです
というところで
学習データの準備もやっぱり専門性欲しくなる
という世界観から
文章の中にプロンプトで指示書けば
もうそれでやってくれますってなったら
日本語とか言葉しゃべれる方だったら
誰でもできるってことを意味してるわけですよね
えらい裾の広がったなっていう風なことが
まず大きく違うのかなという風に
大きなポイントなのかなという風に
まず思いますね
ありがとうございます
まさにその通りかなという風に思います
では次のテーマに移れればと思いますけれども
ABCDで今Aのテーマについてお話させていただきましたが
BCDでどのテーマについて話すかについて
視聴者の方に多数決でアンケートを書いていただけたと
こちら結果どのような形になってますか
こちらですね
Dの技術動向何を注目すべきといったテーマについて
皆さんお聞きになりたいということなので
この辺りについてお話しいただければと思います
まさに先ほどスケーリングローみたいな話ありましたけども
データ量とか計算量とかパラメータ数
これを上げれば上げるほど性能が良くなっていく
量的な観点と一方で冒頭にもお話ししました
アライメントみたいな学習のさせ方を工夫することによって
高性能にしていくという量的質的2つの観点で
基本的には動向というのがあると思うんですけど
ぜひお三方からどういったところに
これから注目すべきかといったところを
お話しいただければと思います
まず川田先生から
はいいろいろあるんですけれども
一つ言うのであれば
まずチャットGPTとかは言語モデルですよね
言語なんですよね
今最近よく聞くのは
マルチモーダルというキーワードだと思うんですけれども
例えば画像であるとか映像そして音声であるとか
そういったいろんなモーダルのものを
くっつけたマルチモーダルモデルというのは
これからどんどん出てきて
重要になっていくというのは間違いないと思います
さらにロボットを制御するとか
そういったこともあると思いますので
そこら辺に広がっていくと思っていまして
そもそも赤ちゃんのときから言語を学習するというのは
言語だけじゃなくて
こういう実環境から学ぶというのが大きいと思います
そういったことを学習させて
まさに人間のようなモデル
基盤モデルと呼ばれるかもしれないですけれども
そういうものを作っていって
それが応用に使われていくというのが今後だと思います
なるほど
まさにテキストだけじゃなくて
モダリティのお話されていましたけれども
ロボットのお話もされていましたけれども
肉体を与えるであったりとか
人間の知覚を与えるというか
人間により近づける方向での
動向というところになりますかね
ぜひ井上さん
最初に言おうと思っていたことを
言われてしまってどうしようかな
今ちょっと考えているんですけど
何個かありましてマルチモデルがまず一つあって
そこから発展したところで
ドメイン適用みたいなところがあって
これは医療とか最近
マイクロソフトさんとか
Googleさんとかメドパルムとか
ラバーメドとかいろいろモデルがあるんですけど
医療特化にドメイン適用というところがありますと
3つ目だと
例えばGPT-4とかの
学習の方でいうと
いろんな実はモデルがあるんだみたいな
MOEみたいなエキスパートな
モデルがたくさんあってやっていくみたいなところで
専門的なリルムを作るみたいな
流れになっていくと思うんですね
そういうマルチプリなところが3つ目で
4つ目が学習のデータの質ですね
これはコーパスとか呼ばれるところの
学習をやっぱりきれいにするとか
学習方法でも
少ないデータでもきれいにしていけば
かなり性能が上がるみたいなのが知られてるんで
この辺りの4つぐらいを注目すると
結構面白いのかなという風に
思います
ありがとうございます さらに4つを出していただいたというところで
ハードルが
全部言っちゃいましたね
僕は
逆の視点からあえて言うと
社会応用の時代に入ったと思うんですよね
だから実際使ってみて
使いづらと思ったものが
全部技術的に解決されるべき課題だと思います
例えばコンテキスト帳が限定的で
長い文章入れられなくて困ってます
っていうのからドライブされて
最近コンテキスト帳の長めのやつも出てきてますよね
ストリーミングエレメントとかですけれども
みたいなものも
もちろん研究者の方ってそういう
使いづらさを一番よく理解されてるので
当然裏で研究動いてるんですけれども
そういうのが結局関係してくると
あとは関連する話的なコストみたいなところも
今度聞いてくるでしょうね
言語モデルが大きくなっていけば大きくなっていくほど
コストがかかっちゃいますので
ドメイン特化型みたいなところで
必要十分サイズみたいなものに
分化していくんだろうなという風に思っていたりとか
あと速度が遅いよねって話も
先ほど
事前の
かわわせみたいなところでも速度問題話出てましたけれども
やっぱり速度遅いんであれば
それを解消してあげるべきと
さらに言うと
推論環境をきちんとホストしてあげる
っていうのは思ったより難易度高いので
そのあたりの実用的な技術課題とか
あたりも含めて
さらに言うとあれですね
言語モデル個別に作って
よくお客様からもお話を伺うんですけれども
事業部ごとに言語モデル作りますと
この事業部の知識も出せますって言って
やるのはいいんですけれども
でもやっぱり細分化していくと
情報のセキュリティの話とかあって
この役職の人はここの情報にアクセスしていい
この情報はダメみたいな
時にどうやってそれを制御するのとか
結構現実問題いろいろ出てくるはずなので
そのあたりが全部今後解決されるべき
技術動向の論点になっていくんだろうな
というふうに思いますね
ありがとうございます
今すごくいい視点をご提供いただけたかな
というふうに思います
いろんな技術課題は
ニーズから生まれるというようなお話
いただいていたのかなと
誰もが使える生成案が出てきて
これをビジネスに応用しようとすると
本当にビジネスに関わるすべての人から
おそらくニーズが出てくるんじゃないかな
というふうに思います
なのでビジネスで実際に使っていて
不満に思うところであったりとか
課題に思うところ
こういったところはそれぞれの方々
結構これまでだと
技術に直接影響を与えるような
インタラクションというのは
結構ビジネスサイドからはしづらかった部分が
あると思うんですけど
そういったところがより活性化していくんじゃないかな
という印象もしました
ちょっと先ほどから
深津さんがニヤリとされているんですけど
何か
勉強になるなみたいな話
僕なんかは結構
どっちかというと
あとで自己紹介で言おうと思ったんですけど
MLそのもののプロじゃなくて
結局言語モデル使って
どうサービス作る
どう実レベルでいい出力出す
みたいなところで考えちゃう側なので
さっきの
間の問題みたいなのとかも
エージェントでやるときは
なるほどそれねみたいなのとかを
喋らせている間に
GPT-4に投げるとかみたいな
結構卑怯なことで解決とかも
したりするかも
面白いですね
ぜひそのあたり詳しくお聞かせください
ありがとうございます
そうですね
あと5分と迫ってきましたけれども
そうですね
私のほうから選ばせていただいて
Cのところですね
各種用途で性能を上げる方法
結構すごく性能がいい
ChatGPTのようなLLMが出てきて
ちょっとした調整で
性能を格段に上げることができるような
世界になってきていると
大きくはプロンプトエンジニアリングみたいな
質問文を変えることによる
調整と
もう1個はモデル自体を調整する
ファインチューニングみたいな方向性があると思うんですけど
このプロンプトエンジニアリングVS
ファインチューニングについてですね
ご意見を伺わせていただければと思います
川原先生いかがでしょうか
はいこれは派閥があります
派閥がありまして
私はどちらかというと
ファインチューニング派なんですけれども
少量でいいので
高品質なデータを作ると
つまりプロンプトに対して
こうレスポンスしたらいいよというデータを
数百でも作ってあげて
それでファインチューニングすると
驚くほど精度は
上がるケースが多いとは思いますので
そっち派なんですけれども
一方でお手軽にプロンプトエンジニアリングで
精度上がるというのはありますので
それはちょっと用途によって
使い分ける必要があるかなと思います
ありがとうございます
井上さんはどっち派閥でしょうか
あえて議論を崩したいと思っていて
プロンプトエンジニアリングVS
ファインチューニングがないというところで
これは両立できるよという話なんですよ
実は
ファインチューニングの方はRLHFとかで
人間が好ましいようなやつに作れるというのがありますし
あとはインストラクションチューニングとかで
これ学習結構いい感じにできますし
プロンプトエンジニアリングは
さらに学習しなくてもできるというところがあるんですけど
やっぱりプロンプトエンジニアリングだと
ちょっとお金かかっちゃったり
フューショットで結構文章なくなっちゃったりするので
推論時間かかったりとか
いろいろ問題があるんですね
ちゃんと学習させようと思うと
ファインチューニングが必要なんですけど
これは競合するものではないというところで
あえて議論を崩してみたというところです
ありがとうございます
佐々木さんいかがでしょう
これはケースバイケースですよね
ケースバイケースなので
そこら辺の体系的な知識を持つのが
この生成AIの試験であるというところだと思うんですけれども
そうですね
プロンプトエンジニアリングでまず突き詰めるだけ
突き詰めておいて
そうすると結局コストの問題もそうですし
やっぱりプロンプトインジェクション系のものに対して
どんなに言ってもやっぱり
露出しちゃうみたいな話も出てくるので
そういう時に
ファインチューニングみたいなテクノロジーに
スイッチしていくみたいな
開発前半は機動性優先で
なるべくプロンプトレベルで処理しておいて
その後もプロダクションで
マネタイズの段階に入ってきたら
ファインチューニングとか
どういう使い方なのかなという風な感じを
今のところ思ってますね
ありがとうございます
なるほど
一方でファインチューニングは結構な知識であったりとか
テクニックを知ってないと
なかなかいい結果を出せないというような
ちょっと側面もあるのかなと
ただ今まさに議論を崩す目的でという
お話でしたけれども
2つは共存するのかなという風に
すごい印象を受けまして
そういう観点だと
ビジネスサイドの機動性重視のところと
あとは技術観点でいいですかね
技術サイドの
ちゃんとしたAIの専門家が
チューニングするところと
ここがちゃんと連携することによって
その共存関係が保たれるのかなという風な
印象を受けました
これからまさに今日のテーマではありますけれども
ビジネスのアドオンというところでは
ビジネスの専門家と
あとはAIの専門家が本当に連携して
進めるべき課題なのかなという風にも
思いました ありがとうございます
残り3分ということで若干そうですね
微妙な時間ですけれども
そうですね
じゃあ最後のテーマいってみましょうか
モデル事情
いろんなモデルが出てきていると
チャットGPT以外にもいろんなモデルが出てきていると
先ほどちょっと佐々木さんの方からも
ありましたけれども
こういったモデルどういったバリエーションで
どんな感じの多様性が今あるのかみたいなところですね
ご意見を伺えればと思います
まずはじゃあ佐々木さんからお願いします
今すごい数ありますよね
1万種類以上あるとか
それの樹形図というか
架形図を作った方もいらっしゃるという話も
聞きますし
難しいトピックですよね
ただこれ
以前
柴田さんが主催されたセミナーで
お話を伺いましたけれども
使い方に関しては2つに分かれていて
本当にゼロから作りますか
流派と
もともとあるものを
目的にチューニングしますかの流派
多分この2つをまず一旦考えればよくて
仮に後者なんであれば
その後者向けの
ベースになるモデルを選ぶのは
そんな難しい話ではないので
そういう感じでちょっと大変すぎるので
全部追うのを諦めて
使い方だけ考えてますね
なるほど
ありがとうございます
これは3つに分類できます
実は
3つぐらい分類できると思っていて
このLLMですね
これは最近出た松尾健のやつとか
プリファラさんが出されているようなモデルがあって
あとは英語のやつを
日本で学習する
エライダさんがやっているような学習モデルがあって
もう1個がドメイン適用のモデルなんですけど
これで言うと圧倒的に少ないので
実はドメイン適用のモデルになってまして
ストックマークさん
ぐらいしかないんじゃないかなというところで
なので私はもっと
ドメイン適用のモデルがもっと増えていけば
いいなという風に
思っています
なるほど
ちなみに日本の技術
日本のモデルという観点で川原先生
お話できましたでしょうか
まずChatGPTなどにしても
英語で
入れると
日本語よりは精度が良いというのはありますので
やはり日本語のモデルを
使うというのは重要なことだと思います
日本語というモデルだと
さっき
松尾健が出している
いろんなところから出しているのがあるんですけれども
私が関与している
LLMJPというところで
これまさに金曜日に
13ビリオンのモデルがリリースされたんですけれども
割と高精度に
使えますし
何がポイントかと言いますとモデルだけじゃなくて
いろんなものつまりツールであるとか
コーパスであるとかそういったものをすべて
オープンにしていくということで
そういった活動をしておりますので
ぜひお使いいただければと思います
ありがとうございます
ということでキャッチーなフレーズで
テーマ名を考えたんですけれども
まさにすごく対応な
状況であると言ったところが
把握できました
ありがとうございます
では生成アイの技術パネルディスカッションテーマ1
については以上とさせていただきます
ありがとうございました
ありがとうございました
続きまして
パネルディスカッションテーマ2の方に
移れればと思います
生成アイの利活用を
使えるといったところで
いかに活用用途を見出すか
ご自身の生活や業務に照らし合わせて
そういったところについては
お話いただければと思います
メインパネルは
柴田さんと深津さんよろしくお願いします
ではぜひ自己紹介の方を
お願いできればと思います
まず柴田さんからお願いします
皆さんこんばんは柴田明と申します
ちょっと固くないですか
今日のイベントは
固いですか
いいんじゃないかなと
柔らかくいきましょう
最後のパートまた固いのが
来ちゃうから
ここは緩く
お手柔らかにしてもらえればなと
私は
今
ウェイズアドバイスという
アメリカのAIスタートアップの
日本と韓国のビジネス展開を
していまして
昨日まで韓国に
行ってたんですけど
韓国の会社とか面白いですね
勝つことしか考えてない
みたいなところがあって
すごい刺激をもらってます
そうですねLLMに関していうと
いろいろやってるんですけれども
最近は
深津さんも一緒に
計算書の委員会みたいなのも
いろいろやったりとか
なぜか僕もいらっしゃいますよね
あとは
リーダーボードというのはご存知の方も
最近増えてきて
ありがたいんですけれども
最後の話と同じところで
すごいいっぱいモデルが
あって
やっぱり海外から来るモデル多いですよね
日本でも結構増えてきたけど
日本のモデルと大きさ的には
小さいモデルが多くて
そういうモデルが
日本語でどれくらい性能を
持っているのかということに関しては
常にいろんな質問があったので
弊社では
ウェイズアドバイスという製品を使って
ちなみにこの製品を
ちょっと宣伝すると
オープンAIも
そのモデルを開発するために
使っている製品なんですけれども
この製品を使って
いろんなモデルの評価を自動化して
皆さん比較できるようにしよう
ということをやっています
ちょうどさっき
川橋先生ともお話してたんですけど
このLLMJPから出た
モデルというのが
金曜日ですよね
出て
私たちも評価したんですけれど
かなりGPT-4に迫る
スコアを
今出していて
これはすごいみたいな
ここ数時間の間にも
ツイッターとかで結構
盛り上がったりとかしているんですけど
一方で
川橋先生が
学習データを準備されていたので
お話を聞いていたところで
ファインチューニングに使われた
学習データに
コツというか
一つ大きいポイントがあって
結構どうやって
今後モデルを評価していくのか
みたいなところもかなりチャレンジングだな
みたいなお話を
していました
全然自分の自己紹介から
逸脱してきましたけれども
私の経歴は
ともかく
今モデルに関わったりとか
いろいろモデルを作っている
方々に
ウェイツアドバイスズというツールを提供する
そういう立場で
関わらせていただいています
よろしくお願いします
株式会社ザーギルドのふかつと申します
僕は皆さんと違って
言語モデルとかAIの専門家というよりは
言語モデルや
AI使ってどうサービス作ろうかとか
どうやって性能を引き出して
どんな変な使い方を見つけていこうかみたいな
そういったところの方がメインになってきます
お仕事としての
関わりとしては
スタビリティAIのジャパンチームの
アドバイザリーをやっていたり
あとは横須賀市
僕のちょうど地元なんですけれども
日本で一番最初に生成AI
実践で使った行政ということで
そこの導入のお手伝いをしていたり
とかいろんな会社の
サービスとか運用の部分で
アドバイスとかお手伝いをしていたりします
よろしくお願いします
ありがとうございます
では柴田さんと
深津さんとディスカッションをさせていただきたいと思いますけど
まずはちょっと
手堅いところで
ご説明のほうを差し上げて
それをベースにというか
踏まえなくてもいいですけれども
ディスカッションできればと思います
冒頭にもお話しさせていただいたとおり
いろいろな企業さんと
お話しする中で
活用用途の見出し方がわからない
結局チャットGPT
対話型AIなんだけどおしゃべりできるだけなんでしょう
っていう風に捉えちゃう人が多くて
おしゃべりできるってことは
何でもできる
っていう風に私とかは思うんですけど
なかなかそこまで
実感を持って
把握されている方が
そこまでいないのかなという風な
思いもありまして
いろいろ
私がいるデルトーマツの中でも
研修会とか勉強会とかやる中で
これポイントかなという風に思ったのが
こちらのスライドに記載させていただいているので
生成AIを
人として捉えると
人間として捉えると
そうすると結構いろいろ良い影響があるんじゃないかなという風に
思っています
特に人に良い仕事を
頼む時の指示文は
生成AIに良い仕事をさせる時の指示文と
同じだったりとかですね
あとは例えば外部委託とか
チームの新人に
仕事をお願いする時は
例えば外部委託だったら情報漏洩とか
気を付けるじゃないですか
出てきたものに対して正確性チェックとかするじゃないですか
そういった人間に対して
リスクと感じられる部分に対するリスク対策
そのまま生成AIに
使えるとかですね
この中で一番
効果を発揮するのはこの2番目のところかなと
どこでどのように使うか
まさにこのパネルの
テーマであるんですけども
かなり発散させてアイデアを
思いつきやすいというような側面があるかなという風に思っています
特に
このトピックでもあるビジネスというところを考えると
ビジネスなんて人との連携なんで
生成AIを人と捉えると
人との連携に関する
あらゆる側面で
あらゆる観点で持って用途を
見つけることができるんじゃないかなという風に
考えます
まさに企業の中で
効率的にビジネスを
回していくための
塊が組織であって
組織的な観点で用途を
見出すというのは全然あり得ますし
あとは業務ですよね
共通的な業務から個人業務さまざまありますけれども
そういった業務観点で洗い出すとか
あとは先ほどちょっと申し上げた
外部委託とかチームメンバーとの
連携であってとか
あとは個人の強み弱みこういったところを
踏まえた連携
こういったさまざまな人との連携に関する
観点から用途を
見つけ出すことができるんじゃないかなという風に
思います
こちらは組織観点で
洗い出した例ですけども
一部でしかないんですけども
本当に短期的には各企業さんですね
まず組織でどのように使えるかといった
ところをそれぞれ考えて
使っていくんじゃないかなと
活用用途を見出しているんじゃないかなという風に
思います ちょっと字が小さくて申し訳ないですけれども
一方で
個人の業務という風に見ると
すごく多様なので
一概にこういうところを使えるという風には
言いにくい側面があると思うんですけど
ただ一方で皆さんがやっている
業務をすごくすごく単純化すると
こういったフローパターン
業務フローパターンになるのかなと
基本的にはお客様から来た
問い合わせとか何かしらの依頼に対して
担当者が作業して
管理者がレビューして作業して
くるくる回ってですね
その後成果物をお客様に返すと
基本的にはこういった
フローで持って
ほぼ全ての
個人業務が回っているという風に考えると
こういったところにですね
パターン化されたものに対して個人の
依頼をしてて用途を見つけ出す
あとちょっと先ほど
申しました外部委託に例えば
する際にどういった業務を
外部委託するかといった観点で
基本的には
委託元のレビューの
しやすさであったりとか
委託元の作業時間みたいなところ
こういったところが
多いところについて
業務委託の候補とすることがあると思うんです
まさにこういった見つけ方
委託の業務の見つけ方で
使って用途を特定する
用途を見つけ出すというのはそういった方法もあるのかな
という風に思います
こちらですねまさに
深津さんの出演されていた
動画からですね私がすごい
共感しました
用途のイベントで作ったやつですかね
これはもう本当にしっくりきまして
使わせていただいているんですけども
まさに生成やチャットGPT等は
本当に大量の情報を学習して
それを再表現するような
技術になりますので
この回答される可能性のある
情報というのは無限大であると
そこから
ユーザー側が
求める出力にいかに近づいていくか
これがプロンプトエンジニアリング
というお話をされていてですね
その際にいろいろな情報を与えることによって
求める出力に近づいていくと
その与え方が
いまいちだったらまたハズレな情報が出てきたり
とか
情報を詳細にしすぎると
すごい抜け漏れがある
情報になってしまって
すごくいろいろな問題があって
基本的にそういったところに対して
ちゃんと求める出力に狭めていくという
考え方をお話しされていて
これはすごい共感しました
どっちかというとアートの考え方というか
もともとはミケランジェロが
大理石から像を作るときの
コンセプトの言い方で
何も削ってない大理石
四角の状態が一番可能性がある状況で
一発のみ入れて
パーツを外していって
物が出来上がるのに近づけば近づくほど
俺は大理石の可能性を殺していってるんだ
的なやつですよね
なんか
大理石の中の天使を解放するとか
そんなような言い方してたと思うんですけど
そういうことだったんですね
なるほど
今すごい例えが出てきたなと思ったんですけど
結構チャットGPTと会話していて
削りすぎてしまうことがあって
そこから元に戻すことが
あまりできないことがあるんですけど
そういったときにどうされてますか
もうリセットしますけれども
やっぱり
やっぱりそういうことですね
そこは大理石として
跳ね落ちちゃったみたいなときは
新しい大理石で
大理石を用意するということですね
なるほど
ありがとうございます
ちょっと長くなりましたけど
こちらのパネルも
四つのテーマを用意させて
いただいております
こちらも
独断とあとは
視聴者様からの多数決で
決めていきたいと思いますけれども
まずはですね
Bのところを選ばせて
いただきたいなと思います
不活式
しばた式
しばた式というフレーズを
世に広めたいなと思ってますので
よろしくお願いします
活用事例ですね
普通にベストプラクティスとして
元々
書いてたのは
ロールやタスク決めて
スペシフィケーション
使用書みたいの書いて
良いこととか悪いこととか書いて
要は結局言語モデルって究極的には
手前の文章に影響を受けて
後ろの文章を書くので
手前に良いことが書いて
第一原則は手前に良いことが書いてあれば
後ろのこともだいたい良くなるので
チェーン・ノブ・ソートだろうが
最近のベストプラクティス
頭に貼るのだろうとかも
統一で手前に良い感じのこと書いてあれば
解決するっていう
標準化ができるので
それをルールにしてたっていうのが
あるところですね
それが基礎の基礎というところ
シューショット・エグザンプルとかも
結局そういう話で
手前に良いものがあればなんとかなる
それが一般的な基礎の
非専門家に特に言うときとか
まずは押さえておくべき事項
ちょっとここでお伺いしたかったのが
まさに
日本を代表する
プロンプトエンジニアという風にも
言われてる
一番プロンプトエンジニアリングに
未来ないって言ってる人間なのに
そういう場合の人が多いですよね
その深津さんが
今まさに熱いと思ってるような
そういった活用事例とか
最近の活用事例というか
プロンプトの使い方だと
さっき人間見立てるって言ってたじゃないですか
最近僕の中で熱いのが
AIにできないことを
命令するっていうのが多くて
今僕の中で一番熱い
プロンプトの一個が
以上
今命令して出力させるじゃないですか
出力したときに
ではこの出力を
60点とします
これを60点としたときに
100点とは
どのようなものですか
100点にするために足りないものを
列挙した後に100点の答えを
生成してくださいっていうと
確実に良くなるんですよ
確実に良くなったのに
これをまた
60点で定義すると
っていうと
またずっと良くなるんで
同じ
プロンプトコピペするだけで
どんどん良くなるっていうのが
最近熱くて
しかも
同じプロンプト回すだけなんで
Python組める人はホワイルドでループ組めば
ウィーンって勝手に性能が良くなるんで
60点として100点を目指すには
みたいに
技術的に
プロンプトの中でベクトル化することで
性能とか方向性をものすごく
コントロールするっていうのが
今熱いんですよね
ただ人間にはできない
人間でやったら多分その人会社辞めちゃうと思うんで
すごいですね
すごい良いお話を伺えてきました
早速今日から
まさに私もコンサルやってるんですけど
お客様に
60点って言われることとかあるんですけど
それを100点にするための要件を
今人間が考えてると思うんですけど
そこすらも
チャットDBで考えさせる
どんな良いもの出てきても60点呼ばないと
とりあえずさらに良くするための
プランがずっと無限に出続ける
どこかでサチったりしないですか
サチってきますというか
それも
プロンプト次第だな
でいくともう
場合によっては
これ以上どこを良くしたら分かんない
具体的にしてくださいとか泣き言言うときもあったり
あるいはこれつけましょう
これ削りましょう
これつけましょう削りましょう
いったり来たりだったり
完全にやるよりは
ブレイク条件作っておいた方がいいんですけど
5、6回ループぐらいまでは
GPT-4だったら保証できるかな
ありがとうございます
では柴田式をお伺いできればと
僕はあんまり
プロンプトエンジニアみたいな
風にいっぱい使っては
ないですけどね
一番よく使うのは翻訳
で使いますね
今韓国語とかすごい
自分の知らない言語を書かないといけないから
合ってんのか分からないけど
とりあえず翻訳して
メールにペーストして送るっていうのは
一番よく
今一番使いますねそれ
あとは僕よく似たので
頼るのだと
論文読みたいんですよ最新のMLの
けど僕数学とか分かんなかったりとか
専門すぎるの分かんない
最近
GPTに論文をアップロードしながら
Udemyでチュートリアル
売りたいからこれをステップバイステップの
チュートリアルにしてくれやってあげると
論文が全部
初心者に分かるステップバイステップチュートリアルになるんで
めっちゃ読みやすくなるっていう
無限教育コントジェクト
これだと
実際に売るわけじゃないんだけど
自分でも簡単に読んで
場合によっては
Googleのコラボ用のサンプルコードまで
ついて出てくるんで
論文めっちゃ早く
専門家でも消化できるっていうのは
ちょっと個人的には熱い使い方
ありがとうございます
これは結構教育的な観点でも
すごく
使える可能性があるということですよね
専門分野じゃなかったとしても
それを分かりやすく説明してくれる
まさに教師のような役割を
生成案にならせるというところですかね
それで言うと今回も
テストで
生成案を使って問題を
出題しようという話がありましたよね
そうですね
それの話はしなくていいんですか
まさにしようと思ってました
GPT資金館がやってくる
今回は
選択肢問題だけじゃなくて
生成案を使わないとできない
出題をしましょうみたいな話から始まって
うよ曲折
いろいろありましたじゃないですか
あれプロンプトエンジニアリングで
プロンプトハッキングして高得点取っても
ありなんですかね
それはむしろ歓迎という感じ
じゃないかなと思いますけどね
そうですね
今回はJDLA
ジェネレティブAIテストの中で
記述式問題を
入れております
記述式問題って結構特徴があって
選択式問題と一番違うのが
資金館によって
採点の仕方
人が違うので
品質が採点館によって異なるというような
特徴があると
ここをまさに生成AIを使って
解決しようという風にしてます
それもそうですけど
やっぱり記憶して
知識を問う問題だけじゃなくて
理解度とか
応用力とか
そういう紙のテストでは
試しにくいこと
っていうのを
テストできるようにしようという目的も
結構大きかったかなと思いますね
しかも人間でやると
一人目の生徒はだいたい
7点とか8点でやりそうとか
ご飯食べた後とか
お腹空いた後とかに
裁判官の裁判の判決が
厳しくなるとか緩くなるとか
そういう揺らぎがあるんだけど
GPTでやったらそこの揺らぎは
だいぶ変わる
フェアになるんじゃないかなと
昨日お笑い番組で
お笑いコンテストの番組やってましたけど
そういったところでも使えそうですね
でもやっぱり
やってみて
私自身はすごい学びがあったので
確かに生成愛すごいし
いろいろできるといえばできるようで
本当になんか
シビアなことに使おうと思った時に
出てくる問題っていうのは
やっぱりやろうとして
初めてわかるなっていうことは
やったんですよね
それぐらいできるでしょうみたいな
深津さんもいるしみたいな感じで
言ってたけど
でもやっぱりテストで
命がかかっているとは言えないけど
それなりにお金も払って
真剣に受けに来る人たちに対して
生成愛が採点するっていうことが
どこまでが許容できて
どこからはできないのか
あんまりコンサバになりすぎると
こうやって結局選択問題出してやると
同じじゃんみたいな話になっちゃって
それは
私自身すごい学びでもあったし
それを通じてすごく
チームとしてもいろんなディスカッションができて
よかったこともありますけど
活用っていうことを
考えた時に
絶対にこれから来ると思うのは
案外生成愛は使えないよねっていう話が
絶対に来ると思うんですね
それはとりあえず流暢にしゃべるから
すごいし
翻訳とか予約とか
それぐらいのことをやろうとしているうちは
本当に目の前にある問題
この前
じゃあパレスナーとイスラエルが
どうやったら和解できますかって聞いて
そんな答えなんか出てくるわけがないし
現実問題って
そういう難しさや
リスクとかっていうのは
はらんでいるから
利活用の話をする時には
これからそういう話が出てくる
さっき佐々木さんもそういう
実際にやろうと思った時に
必要とされるブレイクスルーとか
何でもできると思わないで
実際にやってみて
どこができないのかっていうことを
経験していくっていうのは
すごい必要なことだなって思いました
ありがとうございます
私もすごい勉強になりまして
今回の件ですね
まさにアイデアを柴田さんが
最初に言い出した時に
2回目も選択していくんだろうという
当たり前な感覚でいたんですけども
確かに生成愛を使うと
いろんなことができるなと
本当に質を上げることができるな
って思ったテストですね
活用全般に言えることだと思うんですけども
なるべくアイデアを制限しないで
当たり前をどんどん疑っていく
っていうようなところが
非常に一般のビジネスマンも
すごく求められてくるような
そういった時代になってきている
本当に改めて思いました
深津さんとその話していた時に
深津さんはもう他の人がやったことは
やりたくないんですみたいな
フューショット的なことはやりたくないですみたいな
ミスターゼロショットですみたいな
話をされてて
本当そうだな
ちょっと飲んでたかもしれないけど
過去の経験とかでも
そういう事務所にいたんです
プロンプト的な話じゃなくて
仕事の話
僕の前職が
同じ仕事を2度やんないって
話をされてたじゃないですか
でもやっぱりこれから人間に
求められることって
そういうことだなってすごく思ったんです
なぜかというとファインチューニングとかしていくと
さっきの河原先生とも話したんですけど
やっぱり例を見せると
どんどんできるようになっていくから
そうするとやっぱりAIに奪われちゃうところが
増えていくので
やっぱり人間に求められることっていうのは
これまでになかったような
問題を解いていくっていうこと
それができないとどんどん差別化が難しくなるなって
思いました
そうですねゼロショット系はね
色々楽しいですよね
AIゼロショットというか
スタンダードないものが多すぎるので
僕そういうとこ大好きだから
今めっちゃ楽しいです
結構その人間の価値はこれからどうなるのか
みたいな議論は結構ありますけど
すごい今日ヒントいただけたような気がしました
ゼロショット
そうですね
あの
あれですね
今実際生成AIで問題を
批准式のやつやってみて
こんなんあったじゃないですか
聞こえたじゃないですか
これって結構大事なポイントだと思っていて
僕も色んな日本の会社さんで
生成AI使われてますで
多いのはラグみたいなものを使って
社内の文章を探しますみたいなパターンですけど
精度出なくてダメなんですみたいな感じで
おっしゃる方も多いんですよね
そこで諦めないことが大事だなと思っていて
やっぱり初め
AIなんてうまくいかなくて当たり前みたいな
気持ちで初め挑んで
そこからいかにしっかり作り込んでいくかっていうところ
これはぜひ諦めないでやっていただきたいな
と多分今回の試験問題っていうのは
そういうところに対する何らかの示唆を
与えてくれるんじゃないかなという風に思っている
ということを思いました
ありがとうございます
そうですね
このようなゼロショット的な試みを
これからも継続してできるように
頑張っていければと思います
これからもよろしくお願いします
ありがとうございます
やっぱり予想通りすごく盛り上がってですね
あと2分です
1個ぐらいしか答えてない
2つぐらいあったけど
巻いていかないと
そうですね
今アンケート取りまして
応用編脱チャット
このテーマについてちょっと伺いたいという
脱チャット
僕はあれですね
チャットは今年だけみたいな感じのイメージでいて
基本
僕の専門のUIとかの立場からすると
人はそんな140時も
チャット打ってくんねえだろっていうのがあるんで
目新しくなくなったらみんな入力しなくなるんですよ
だからどっちかっていうと
Googleカレンダーと
インテグレートして
今日これからミーティングってときに
あのミーティング前にこの文章
読んだ気になるとか
なんか体重計乗ったやつが
IFTT使って
体重計のデータスプレッドシート飛ばして
スプレッドシートから
ザピア使ってGPT飛ばすと
なんか体重毎日測ってないねって
褒めてくれたりとかみたいに
トリガーをもう
ちょっとじゃないものにしていって
そっちが9割とかになっていくんじゃないかな
って気はするんですよね
でもやっぱり
サービスとかに
入れようと思うと
開発に時間がかかるじゃないですか
ついこの前
メルカリさんとかも
商品出品するタイトルを
生成してくれるみたいなの
やってましたけど
ああいう既存のサービスに
入ってくるみたいなのがこれからどんどん出てくるんじゃないのかな
と思ってて
同じ意見なんですけど
個人がチャットでインタラクションするっていうよりも
それがパーツとなって
もっと大きなサービスを
形成していくみたいな話っていうのは
結構やってる人たちも
多いと思うし
多分今年の残りの
今年の残りの時間にも
結構いろいろ出てくるんじゃないかなっていう気がしてます
すごく便利な
世の中になりそうですね
だといいですけどね
ドラえもんの中で
半分ぐらい
どこでもドアとかはさすがに無理だとは思うんですけど
ドラえもんの便利ツールの何割かは
本当このね
生成AI
特にマルチモーダルのもので
達成できちゃう気はしますよね
そうですね
ドラえもんの知能はほぼできてると
言えるんですかね
多分処理速度遅くて良ければ
多分ドラえもん自体も
動くでしょう
生成AIバックエンドで
ちょっと動く話をしだすと
いろいろさっきのビデオのこととか
思い出しちゃって
見せきれないのかもしれないですけど
最近そういうの
深田さんは
GPTにボディーを与える実験を
いろいろ最近はしてますね
でもそういう話ですよね
今Amazon Echoみたいな
裏側が賢くなっちゃった
チャットボットみたいなもちろんそうだし
これからそういう風に
スペースで動向っていうよりも
APIを使ってどうやって実装していくのか
その結果として現れるサービスみたいなのが
すごいのがいっぱい出てくるんだろうな
多分究極的には
画像生成
AI
テキストAIで
今画像を読めるようになったじゃないですか
これがあれば
あとはPCの
スクリーンキャプチャを
1秒ごとに生成AIに渡して
あとはロボットアームとマウスとか
それを繋いどけば
割と何でもできる気がするんですよね
この前僕もイベントやったときに
うちのお客さんのチューリングさんっていう会社さん
自動運転を
開発してて
自動運転でどうやって
生成AIが関係してくるのかみたいな話を
ちょっとしてて
基本的に自動運転はここに車走ってます
子供が歩いてますとか
物体認識みたいなレベル感だったんですけど
やっぱり
例えば家の形した車が
道の真ん中走ってるとかになると
意味が分からないみたいな
家があるみたいになると
当然そっちには行かないみたいな話にしかならないけど
でもこれは車の形しててみたいな
ハイコンテクストな状況を
理解させるとか
あと分かりやすい話だと
すごい複雑な標識とかが出てたときに
それを画像をLLMに入れて
今ここ何て書いてあるのかみたいな
解析して
いろいろ
どういう意味だろうあれ
もう時間だってことか
そうですね
それも同じで
そういうふうに
LLMの能力っていうのが
そういうふうに
見てるもの全てに
適応されて
応用されていくっていう話をちょっと聞いてて
思い出しましたし
そういう意外なところにもどんどん入っていくんだろうな
自動運転みたいのだと
データセットのないシチュエーションを
カバーするためにやっぱり
LLMとか必要だと思うんで
普通のとこはずっと
画像から本能的に
ハンドルにつなげるときはいいや
毎日リングの人が
ツイッターで見たんだけど
道路を馬が走ってるデータセットとか
ないみたいな話があって
そういうのは例外的に
馬が走ってるっていうのは
ビジョンモデルと
組み合わせてやっていかないといけないのかな
そうですよね
だからちょっと考えないとわからないような
シチュエーションみたいなのが
出てきたときに役に立つ
人間の脳みそがシステム1システム2
直感系の処理の脳みそと
ロンリー系の処理の脳みそ
みたいな感じの概念モデルで
動くとかあるんですけど
それに近い感じで
言語モデル使ってシステム2作るんだけど
それだけだとコスト高なんで
素早い処理のシステム1と
併用するとかっていうのは
出てくるんじゃないかなと
すごいたくさんいろんな可能性を
お話しいただきましたありがとうございます
あと3つくらい
今もう時間過ぎたって出ましたね
ただ本日のテーマである
ビジネスへのアドオンっていう風に
考えるとビジネス面でも
すごく影響を与えそうな新たなサービスとか
新たなツールとか新たな機能が本当に
たくさん出てきそうだなっていう風なことは
ちょっと思いました
まさに脱チャットでもってどんどん業務が
効率化されていく未来っていうのを
見ることができました
プロトタイピングが意外と
産業を変えそうだ気がしてて
生成AIを使ったプロトタイピング
要はいろんな
関数とかサーバーとか
ガーって作る代わりにAPIの中に
APIに
インチキでヤフー
ファイナンスに通信したような感じの
雰囲気で株価データを返してください
リターンみたいに書いた関数とかで
インチキAPIを
5秒で作れたりするようになるんで
そういうので
実装が複雑だったりアルゴリズムは
まだ考えないまま関数の挙動で
中身だけGPTして
ガーみたいにすると結構複雑な
プログラム1日で作れる
ちょっと面白そうすぎて
絶対発散するんで
押してますマークも出てる
すごく面白い話いただきありがとうございました
ありがとうございました
はい
ではですね
最後のテーマになります
リスクですね
今すごく発散したような形で
すごく面白い話いただきましたけども
生成AIの非常に大きな
効果がある一方で非常に大きな
リスクもあるといったところが
知られているところです
そちらについてお話させていただければと思います
こちらはですね
私と若林さんで
お話できればと思いますけども
そうですね私まだ自己紹介しなかったですからね
デロイドトーマスの山本さんと申します
もともと15年ほどですね
AIの研究者やってまして
当時勤めてた会社の製品であったりとか
サービスとかですね国際標準みたいなところにも
人工知能とか機械学習の技術を
入れ込むといったところをやっておりました
2年ほど前にデロイドトーマスに
参画してからは色々な企業さんに
AIを導入するであったりとかですね
特にAIのリスクこのテーマでありますけど
そこに対するガバナンスの支援とか
といったところをですね
させていただいております
特に生成AIが私に
与えた影響ですけども
すごい影響がありまして
特にですねコミュニケーションについて
考える機会がすごく増えました
生成AIがですね
本当に躍進をしてからですね
まず私の
クライアントのですね
お話しする方の属性が結構変わってきておりまして
もともと結構技術の方が
多かったのがですね結構その
経営層とかあまりその技術に対して
あまりそこまで深い知見を
お持ちでない方々といったような
方々とのコミュニケーションが増えました
まさに
誰でも使える汎用性を持った
生成AIをビジネス適用する上では
そこまで技術力が
必要とされないといったところの
一つの表れなのかなというふうに
思いつつですね
あとは先ほどの活用用途のところでもお話しましたけど
基本的に良い支持文は
人に対する良い
支持文は生成AIに対する良い支持文でもあってですね
最近チームメンバーから
よく言われるのが山本さんなんか
私たちに対する支持が
プロンプトみたいなんですけど
たまにですね
皆さんもそうだと思うんですけど
ステップバイステップでとか言いませんか
そうですよ
本当にコミュニケーションについて
考える機会がすごく増えたなというのは
生成AIが私に与えた影響になります
じゃあ若林さんお願いします
はい
株式会社エリス・若林と申します
代表取締役をやっております
もともとは
私はシステム開発の領域におりまして
そちらで
20年近くですね
会社を経営してきました
自身も
エンジニア出身という形で
事業に関わっていまして
5年前にですね
AIの技術非常に可能性を感じまして
データ関連の事業を始めまして
現在ですと
昨年ですね
先ほど技術のところで
パネラーで参加させていただきました
井上と
共同創業という形で
AI開発の株式会社エリスを
立ち上げました
そこですと
生成AIとの関わり
生成AIとの関わりですと
やはりこのAIベンダーとして
生成AIの
活用推進をしていくというような
立場で現在は
関わっております
生成AIによって受けた
影響で言いますと
やはりシステム
ですとか
AIの開発の案件の
内容がですね
生成AIが出る前と
後ですと
出る前は
教師あり学習
先ほどAIの用途が
変わってきたというのは
ありましたけれども
以前はスーパーバイズと
ラーニングの開発が
主でした
そこがですね
生成AIが出て以降
多くの方が
使えるようになって
話題にもなって
引き合いがすごく増えたり
ですね
そういったところの案件
をすることが多くなりました
そうすると
AIの開発者の中でも
やはりそこは
競争みたいなところが
だんだん起こり始めて
そこをキャッチアップして
いかなきゃいけないというところに
会社としても巻き込まれて
いったかなと
そういうような影響がありました
今回は
経営者ですとか
エンジニアですとか
そういった話点で
リスクについてですね
お話できればと思います
よろしくお願いします
ちょっと時間もさせて待っておりますので
クイックに聞きたいと思いますけれども
先ほど冒頭というか
このパネルの冒頭で話させていただきましたけれども
今まで技術であったりとか
利活用のところで
非常に大きな効果がビジネスに
組み込めるといったところは
皆さん感じていただけたんじゃないかなという
思う一方で
その表裏一体という形でしょうかね
非常に大きな効果がある一方で
大きなリスクがあると
こちらちょっとまとめさせていただいたのが
生成AIの
こちらを左側に記載させていただいておりまして
そこから得られる
大きな効果とですね
表裏一体で出現してしまう
大きなリスクといったものを
まとめさせていただいております
一番右のところは
広く一般的に認知されている
リスクをですね
重たったものを挙げているような形になります
非常にリスクの
多様性があるのかなという風に
思います
こちらは中長期的に
日本の場合中長期的に
見るときのリスクという
形になると思うんですけれども
皆さんご存知の通り
特にGPT-4等の
最先端のモデルは
人間が受ける試験のほとんどで
人間の合格者と同等の
点数を叩き出すと
いったようなところから
機械が解ける問題を解く能力が
人間が身につける必要があるのかと
これからの教育のあり方が問われているみたいな
ちょっとネガティブな意見がある一方で
先ほどちょっと教育の話
あとGenerative AIテストの話も
ありましたけれども
これまでのような
1人の先生で30人の生徒みたいな
結構確立的統一的な教育から
1人1人の個性とか
強みに合わせた
まさに生成AIを教師として
使うことによってその教育革命が
起こるのではみたいな
そういったポジティブな意見もあるところになります
一方でロードウェイの影響のところですね
こちらもちょっと先ほどお話し出ましたけれども
特にホワイトカラーへの影響が
大きいとの見方があると
基本的に先ほど見たような
特に短期的なリスクのところから
中長期的な社会的な影響という
非常にいろいろなリスクが
知られているところになります
こちらの事前情報を踏まえまして
こちらも4つのテーマを
用意させていただいております
今から
多数決ですが
取らせていただく間に
まずは
生成AIのリスク
Aのところについて先ほど若林さんから
お話があるとお話ししましたけれども
先ほどちょっとお話し
させていただいたこちらの
リスク以外でまさに経営者として
感じているリスクとかですね
そういった視点でちょっとご意見
伺えればと思いますがいかがでしょうか
そうですねやはり
生成AIで
対象とするサービスを
利用する方が
一般向けのサービスだった場合って
多くの方が目にするので
法規制以外
の
リスクの対策が
必要になってくるっていうのが
今
弊社でも自社サービスを
開発ともしているんですけれども
そういうところが
大きいかなと思います
法規制以外の
そうですね
倫理に関わる部分ですとか
そういったところのリスク対策っていうのが
非常に
非常に気にするところかなと思います
今ちょっと
法規制の話が出たんですけれども
基本的に日本で現時点ですね
2023年の今日は10月の
22日ですかね
現時点では
生成AI含めAIに対する
ハードローといったものは
今存在しないと
一方で欧米のところでは
規制化が進んでいるという
ような話があります
特に欧州の方では
アクトであったりとか
あとは米国の方では
シューフォーというところで
個別具体の用途に対する
AIに対して
いろいろな規制がかけられて
いっているというような状況で
日本はこれからそういったところの
影響を受けていくような形になるんですかね
そうですね
日本だと今は規制に向かうのか
もしくは
自主規制みたいなところに行くのか
だと今まさに議論の
最中というところがあって
直近ですと
広島AI
プロセスですとか
AIの戦略会議ですとか
そういったところが
今年度中くらいで
一度何かしらの
結論というか
案内というか
そういうのを出すと言われて
まさに今はどちらに進むかが
日本の場合は議論されている
最中というところで
そうですね
EU、欧州ですと
規制の方向になっていまして
アメリカですと
フェアユースというところを
ベースに個別の
ケースバイケースで判断される
という状況に
なっています
ありがとうございます
まさにそういった先行する海外の
規制の動向というのは
おそらく少なからず日本に影響を与えるので
そういったところをウォッチするというのは
そうですね
まさにそこをしっかりと
キャッチアップして日本の動向に
私たちは注目しておく
ということが大事だと
思います
ありがとうございます
多数決の方が
取り終えたとのことなので
ちょっと見てみますけれども
Bですね
こんなリスクもあり得ますと
こちらについて
お話できればと思います
こんなリスクもあり得ますと
いろんなリスク
知られていないリスクもたくさんあると
やっぱり先ほども
お話しさせていただいたんですけど
これからいろんな用途が生まれていくので
それに応じて今は想定されないような
新たなリスクも出てくるのかなと
こちらのテーマについては
ぜひ皆さんにも
参加いただいて
それぞれの視点から
使ってて
感じたリスクであったりとか
そういったところについて
伺っていければと思います
リスクは洗い出すことが非常に重要だと思われます
ちょっと多様な観点でご意見伺えればと思います
どうぞ
プロンプトの
例えばインジェクションとかあると思うんですけど
皆さんどうされているのかな
みたいなところを
ぜひお聞きしたいです
いかがでしょうか
これ
僕確かにいい質問だと思っていて
日本の会社さんから
プロンプトインジェクションに関する
消息出してくださいって言われる例あるんですよね
ただ一方で
じゃあ
何のリスクなんだろうっていうのは
ひるがえって真面目に考えるとよく分からないと
最近オープンAIさんの
プロンプトインジェクションが実は
できるみたいな話がXで盛り上がったりもしてて
じゃあ果たして
それでダメージを負うのかというとそうでもないのかなと
どういうリスクに結局
落ちるんだろうっていうのはちょっと気になりますね
多分プロンプトの中に
DBへのプロトコルとか
パスとか生パス入れちゃう人とかが
いそうっていうのはありそうなんですけども
自分の場合だと
ツイッター上で
AI孔明っていうアカウントが
ありまして
ここで絶対プロンプトインジェクションされない
孔明さんっていうのの運用実験を
半年は行ってないから
3、4ヶ月ずっと回してて
ちょっと中身
やりたいこともあるんであれなんですけど
ちょっと鉄壁になんで皆さん試してみてください
そんな実験をされてたんです
実験してます
まさにその
深津さんは本当に
いろんな活用
多分人の100倍くらいいろんな活用
されてると思うんですけど
その中で感じたこれリスクかもみたいな
ところもしあれば
バックドアが怖い
バックドアを探せない
つまりその
言語モデルってこれから多分
パソコン直接操作できたり
API呼べるようになるじゃないですか
学習セットの中で
なんかうんこって入れたら
ハードディスク消すコマンド返すみたいなのとかが
学習データセットの中に入れられてて
それみんながガーって
学習したモデルあった後に
データセットからそのデータとか
消したりすると
モデルのウェイトからだけだと
うんこって書いたらハードディスク消されるとか
わからないじゃないですか
なのでバックドアが将来仕込まれたとき
どうやって対策取ればいいんだろう
っていうのは個人的に興味あるんですけど
そうですね
基本的には背後がAIの
ディープラーニングのモデルである限り
100%の対応
を学習時とかに
モデルに入れるっていうことが
原理的には
難しいと思うので
プロンプトのインジェクションも
そうですしバックドアの対策も
そうですしユーザーの
入力の部分とか出力の部分とか
後処理
とか
アライメントに近いかもしれないんですけど
そういうところで
ここは技術的にも
担保していく必要が
あるのかなとは思います
ここは
インジェクションに関しても結構
対策をしても
イタチごっこになるようなところがあって
あそこは
常に
監視をして
更新をしていくとか
そういう付き合い方が必要になってくるのかなと
思います
ありがとうございます
まさに本当に新たなリスクがいろいろ出てくると
言ったようなところで
ちょっとDのテーマに絡むかもしれないですけど
そういったところを全て一手でやっていくっていうのは
結構難しくなってくるんじゃないかなと
生成AIが
自分で
アルゴリズムを変えて
インジェクションの仕方を変えるみたいなところも
多分あり得る話だと思うんですよね
そうなったときに
例えば生成AIをリスク対策に
使うみたいなところって
いかが思いますか
今だと
例えば画像とか
リスクの検出で
AIが使われているってことはありますので
今後例えば
ビジョンランゲージの
モデルとかで画像から
怪しいところを判定するとか
そういうところに生成AIの
モデルが使われる可能性っていうのは
あるかなと思います
なるほど
今私もAIのリスクに対する
いろいろなクライアントの
業務であったりとか
研究活動もやってたりするんですけど
本当に思うのが
トライモンの時代の警察官を
作っているような
気持ちになるんですよね
まさにAIが
非連続的に進化を
取っていて
それに対するいろいろな規制とかが
出てきているところで
まさに未来につながるような
仕事をしているという
意識があります
リスクはあると思うんですけど
AIの評価っていうことで言うと
性能評価とかでは
結構AIを使って評価しましょう
って話は
既に出てきているわけですよね
特に選択問題とかで
評価できるような能力であれば
選択問題を解かせれば
いいんだけどもっとさっき
言ったみたいな論理的能力だったりとか
応用力が問われるような
能力っていうことになってくると
旧来式の
テストで
試すことが難しいから
他のモデルをGPT-4で
テストしましょうみたいな話もある
わけですよね
今後また出てくるのは
テストの内容を生成させるとか
テストケースのパターンを考えさせるとか
そういう話は出てくると思うんです
今まであったような
種類のテストを受けさせても
もういたちごっこになっちゃって
どんどん賢くなっちゃうから
今度はどんなテストを
すればいいのかっていうことを
生成させようみたいな話は
ちょうどさっき川内先生とも
そういう話をしてたんですよね
そういうセキュリティリスクの話とか
結構私の感覚では
いけるんじゃないのかなと思っていて
いろんな形で
本来望ましくないような入力を
生成させていれて
その結果を評価するとか
そういうことっていうのは
今すでにされていることとも
遠く離れてないんじゃないのかなって思います
ありがとうございます
まさに評価というものも
非常に多様性が
求められるようになってくるのかなと
これまでのAIであれば
用途が決められて
ある程度リスクっていうのは想定されたんだけれども
今も何でもできるような
いかようにでも使えるAIが出てきたので
リスクもすごく多様化して
それに追従するようなところが
非常に重要であると
さっきからテストテストテストっていう
ワードが繰り返されていまして
まさに人間に対するテスト
JDL Generative AI テストなんですけど
こういったところに対するフィードバック
かけてちゃんといいものにしていく
意義として
あるものにしていくっていう
このループっていうものは
生成案に対しても
人間に対してもすごく必要なんだなと
すごい必要だと思うんですよ
なぜかというとリスクっていうのは
今法規制だったりとか
私は個人的にはそういう規制は
あんまり基本的には
少ない方がいいとは思っていて
というのはやっぱり今って
すごくこの技術が出てきたばっかりで
まだまだ新しい音とかが
生まれると思ってるんですよね
ってなった時に先に
これはやっちゃいけないあれはやっちゃいけない
っていうことばっかり出てきちゃうと
どんどんそういうイノベーションの種を
積むことになるんじゃないかなと
じゃあどうしたらいいのかなって思った時に
やっぱり使う側だったりとか
それを使ったなんだかのアウトプットに
影響を受ける人たちが
AI に対する理解を持ってるかどうか
っていうことであれば
もしかしたらちょっと変な答えが出てきたとしても
そこからこういう事情なんじゃないかとか
そういうふうに使う側のリテラシーが
上がっていくっていうことで
無駄な規制だったりとか
そういったことをしなくていいっていうことになるんじゃないのかな
と思っていて
だからこそこのテストを受けるっていうことが
すごくこの AI を発展させていく
っていうことに重要なんじゃないかなと思っています
ありがとうございます
素晴らしいまとめで
いただきました
やはり生成AI を使っていく上で
リスクにどうやって対応するか
っていうところと
今話していただいたところも
すごく密接だなと思っていて
今回
パネルディスカッションのテーマで
技術と利活用と
リスクとで分かれていまして
柴田さんがさっきおっしゃったのは
後の方がちょっと固いんじゃないかって
リスクでおっしゃってたんですけど
そこは必ずしも
法律とか
決まりリスクっていうものが
使う上で何か堅苦しいっていうだけではなくて
実は
リスクは
利活用と
技術と
かなり密接に関わっていまして
例えば
法律に触れてしまうようなリスクっていうのも
これは規制があって
そこに引っかからないようにする必要がありますと
ってなった時に
私たちも今回チャレンジをした
生成AIテストに
技術式を導入する
した時に
どういう
風に進めていくか
考えた時はやはり最初に
この利用方法で
受講者さんに
受けてもらった時に
どんなリスクがあるかっていうのを
まず洗い出して考えて
その上で利活用ですよね
つまりこのテストが
どうあってほしいか
意義でやるとか
機能を持ってほしいか
っていうところを一体で考えましたし
それを判断するためには
技術的にどういうことができて
できていないかっていうのを
集まって議論する必要が
ありましたと
これがまさに
生成AIを利用して
いく上の
自分たちで
どういうことが
起こりうるかっていうのを考えて
ちゃんと自分たちで線引きをして
することによって
活用していく
使えていく
それをこのチームの中でも
体験できたのかなと思ってまして
そういうところから言いますと
こういったところを体系的な知識を
持っていただいて
活用を進めていただくというのも
今ちょうど聞いていて
感じたところでした
まさに
議論は
守りながら攻めてたっていうような感じですよね
まさに守りと攻め一体になって
やっていったのかな
山川さんいたから守りがあったっていう
僕だけだったら多分
攻めだけになって
多分やばかったんじゃないかなみたいなと
そういう意味では素晴らしいチームで
だったと思います
じゃあちょっと押してますマークが
再度出ましたので
ありがとうございました
最後ですね
まとめさせていただきます
本当に皆さんありがとうございました
本当に多様なお話が聞けて
すぐに試したい
プロンプとエンジニアリングの
手法も教えていただいて早く試したいんですけれども
本当に多様な
ディスカッションができたかなと思います
こちらは冒頭に
お見せしたアジェンダになりますけれども
実はこちらでですね
課題として扱っていたものに対する
解決の
糸口としてですね
本日のパネルディスカッションのテーマを
ちょっと立て付けで
置いておりましたけれども
実はこちらですね
3つのテーマはJDLA
Generative AIテスト2023のシラバ数の
体験に沿ったものになっていて
まさにこういった技術で利活用
リスクに対してですね
ちゃんと理解を深めて
生成AIをビジネスにアドオンしていく
能力を試すようなものになっております
ちょっと最後ですね
事務的なお知らせになりますけれども
こういったGenerative AIテスト
今さっきもすごい話題出てきましたけど
本当にこれからもですね
進化を遂げていくように
我々も検討を続けてまいりたいと思いますが
直近ですと
12月の2日にですね
試験が決まっております
申込期間は11月28日となっておりまして
詳しい内容はですね
動画ページの概要欄のリンクよりですね
見ていただければと思います
まさにこのGenerative AIテスト
こういったツールも活用してですね
ビジネスへのアドオン
皆様の立場から主体的にですね
推進していただければと思います
では本日のイベント
以上とさせていただければと思います
本日はどうもありがとうございました
ご清聴ありがとうございました
