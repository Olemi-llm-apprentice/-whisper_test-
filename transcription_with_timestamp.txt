[0s -> 9s] いうところでビジネスアドオンとビジネスかける生成AIというトピックにですね 非常に多くの方が関心を持たれているのかなというふうに
[9s -> 16s] 認識しています 本日ですねまさにこういった生成AIの業界にですね
[16s -> 24s] 多様な立場から携わっておられる 本当にトップランナーの方々をお招きしまして
[24s -> 30s] 時間が許す限りですね 語り尽くせればと思っていますのでどうぞよろしくお願いします
[30s -> 37s] 今多分私しか映ってないと思うんですけども こちらトップランナーの方々がおりまして
[37s -> 46s] すごくアットホームな雰囲気で渋谷のスタジオからお送りさせていただいております 今日ぜひですね試験の話もあってちょっとやりますけれども
[46s -> 52s] JDLAのGenerative AIテスト こちらの試験作成の時のアットホームなですね
[52s -> 57s] 感じもちょっと出しながらお話しできればと思います よろしくお願いします
[57s -> 68s] では早速ですねイベントの方を進めさせていただければと思いますけれども 本日ですねこちらのようなアジェンダで進めさせていただければというふうに思います
[68s -> 77s] 生成AIかけるビジネスというところですね 私もデロイドマツにおりまして本当に日々ですねいろんな方々とお話しさせていただくんですけども
[77s -> 86s] 生成AIのですね話題が出ないことはないっていうぐらいですね 本当に非常に多くの方々がビジネスかける生成AIにご関心を持ちであると
[86s -> 93s] ただ一方でですね非常にいろんな課題もあるところで どうやって使えばいいのかわからないとかですね
[93s -> 101s] 結局何ができるのかわからないとかですね そういった課題感であったりとか一方でその生成AIをどうやってビジネスに活用していくかって
[101s -> 108s] 大きな方向性みたいなのが結構見えてきているところがありまして そのあたりのですね試験のところとかも今回ですね
[108s -> 117s] いろいろと挟んでお話しできればというふうに考えております 本日ですね大きく3つのパネルディスカッションを用意しておりまして
[117s -> 127s] 生成AIの技術利活用それからリスクのところですね 大きくこの3つのテーマでですねトップランナーたちと一緒にディスカッションできればというふうに考えております
[127s -> 138s] まずあのちょっと私の方からですね冒頭ちょっとお時間いただきまして 生成AIに関してですねこのパネルディスカッションの前提といいますか
[138s -> 148s] 結局どういったところが従来のAIと違うのかみたいなところです ちょっと簡単にお話しさせていただいて その後にですねパネルディスカッションに移れればと思いますよろしくお願いします
[149s -> 158s] でこれどっから話そうかというふうにですね あちょっと渋谷っぽい音が聞こえておりますけれども
[159s -> 162s] 生放送あるあるですかね
[164s -> 168s] はいちょっと気を取り直して
[168s -> 175s] はい 生成AIも非常に多くのトピックがある中でどっから話そうかというふうにちょっと考えた中ですね
[175s -> 185s] 今日はちょっと生成AIの影響のところからお話しできればなというふうに思います 皆さんご承知の通りですね生成AIも本当に多方面に大きな影響を与えているかなと
[185s -> 194s] ただ一方でですね特徴がすごくあるなというふうに思っているのが ちょっとここですねあの間口をコンサルっぽくちょっとまとめておりますけれども
[194s -> 204s] まあこれからですねおそらくどんどんトピックに上がってくると思いますけれども 生成AI 言葉を使って振る舞いをコントロールできるという非常に大きな特徴があって
[204s -> 210s] であるがゆえに誰でも使えるというようなところが大きな特徴であると なのでちょっと3巻
[210s -> 218s] 学民というふうに書かせていただいておりますけれども 特にあの民のところですね 利用者側への影響が非常に大きくて
[218s -> 224s] 2022年11月30日にチャットGPTが出ましたけれども その当時ですね1週間で100万ユーザー
[224s -> 230s] 2ヶ月で1億ユーザーに到達したということで 人間がこれまで作ったものの中で最も早い
[230s -> 238s] 普及速度であるというふうに言われていることです こういった民へのユーザー側への大きな影響が起点となってですね
[238s -> 246s] 3巻学それぞれに影響を与えているのかなというふうに認識しています 特にこちらのですね左側3への影響のところがまさに本日の
[246s -> 251s] トピックであるビジネスかける生成アイのところになるのかなというふうに思います
[252s -> 262s] なぜですねこんな感じで利用者にとって非常に大きな影響を与えているのかといった ところですねこれまでのAIとの違いといったところからちょっとひもときて
[262s -> 270s] ひもときたいというふうに思います こちらですねこれまでのAI生成AI以前のAIで特に用途特化型の
[270s -> 274s] AIについてその振る舞いというものですね ちょっと端的に表した図になりますけれども
[274s -> 282s] これまでAIってデータが活用できるいろんなところでですね モデルが構築されて活用されてきたわけですけれども
[282s -> 288s] それぞれですね用途に応じてAIをモデルをですね 作る必要があったかなというふうに思います
[288s -> 295s] 作ったAIを使う際はですね 入力データとして決まった形式を入れてですね
[295s -> 301s] 出力データとして決まった形式を想定すると こういった形だったのかなと
[301s -> 308s] 例えば一番上のところにありますけれども 例えば中古商品のですね価格を予測するようなAIでしたら
[308s -> 315s] その商品に関する情報を入力データとして入れて それに基づいて予測価格を出力するといったような
[315s -> 321s] 決まった形式の入力と出力があって 用途に応じたAIを作る必要があったと
[321s -> 330s] その下はローン申し込み者データの 申し込み者がですね信用に足るかを判定するようなAIですけれども
[330s -> 334s] こちらも同様ですね その以下も同様であると
[334s -> 341s] 要は入出力の形式があらかじめ決められた形式であって それぞれ用途に特化したAIを作る必要があったというところが
[341s -> 350s] これまでのAIかなというふうに思います これに対してですね生成AI 例えばチャットGPTのような対話型AIを例にとりますと
[350s -> 355s] 先ほどのような構図がですねちょっと一変しますと まずあの
[355s -> 363s] すぐ分かるのがモデルですね 真ん中にあります生成AIがですね 先ほど用途ごとにそれぞれ3つあったと思うんですけれども
[363s -> 373s] それが一つでいいと かつですね入力データが自然文になっていると ユーザーが与える自然言語ですね
[373s -> 377s] AIとは何ですかとかですねコールセンターの オペレーターとして振る舞ってくださいとかですね
[377s -> 384s] 先ほどは決められた形式だったのが自然言語という 非常に柔軟で自由な入力データになったと
[384s -> 394s] それに対して主翼データもですね入力データ 自然文に合わせてですね柔軟に主翼をしてくれるといったような形になっています
[394s -> 401s] ここで非常に重要かなというふうに思うのがですね 人間であれば誰でも使えるような言葉というものを持ってですね
[401s -> 407s] AIの振る舞いをコントロールできるようになったと これが非常に大きな特徴であるかなというふうに思います
[407s -> 413s] 前までは用途ごとにAIを作る必要がありましたので 用途ごとにですね専門家が作る必要があった
[413s -> 418s] プログラミング言語とかあったりとか 技術をちゃんと学んでですね作る必要があったんですけども
[418s -> 423s] 今あの人間であれば誰もが使える言葉でもって振る舞いを コントロールできるということは
[423s -> 429s] 従来のAIの専門家がやっていたのことをですね 普通の誰でも誰もができるようになったと
[429s -> 433s] そういった時代になったかなというふうに思います 本当にあの誰もが簡単にですね
[433s -> 440s] どこでも最先端のAIを活用できる時代になったのかなというふうに思います
[440s -> 448s] あるがゆえにですね誰でも使えるという特徴があると これをですねビジネスに適応していく
[448s -> 453s] ビジネスで導入していくということを考えると いかに自信を持ってですね活用していけるかが
[453s -> 457s] ポイントであるかなというふうに思います
[458s -> 464s] ただこういったですねあの自信を持った活用というのは 非常に難しいということが結構ですね
[464s -> 470s] いろいろなお客様であったりいろいろな人と話している中ですごく思うことに なります
[470s -> 475s] これはまあ誰もが使えるという特徴があるがゆえの難しさであるというふうにも ちょっと感じてまして
[475s -> 483s] まあ誰もが使えるので世界中でですね新たな活用の方法 いろんな人が見出していていろんなメディアで発信してるんですよね
[483s -> 493s] 情報がすごく溢れているような形ですごく煩雑ですね 結局何ができるのかわからないっていうことが結構課題としてあるのかなというふうに思います
[493s -> 500s] まあこちら書かせていただいているところですと 体系的な理解が難しいというところに相当しますね
[500s -> 507s] さらにまあそれにまあ気にするんでしょうけども 業務のどこに生成が活用できるかわからないであったりとかですね
[507s -> 513s] あとはリテイラーシーが足りない 具体的なリスク対策の方法がわからないといった具体的な課題も出てきていると
[513s -> 523s] こういったところから本日ですね 本イベントにご参加の皆様がですね 自信を持って生成AIを活用していくために必要なですね
[523s -> 529s] こういった課題の解決をですね 本日のトークをパネルディスカンションを通してぜひですね
[529s -> 538s] 獲得 課題解決の一つのツールとしてですね 扱っていただければというふうに考えています
[539s -> 546s] 特にあの体系的な理解のところですと生成の技術 利活用 リスクで誰でも使えるというところを考えるとやはりですね
[546s -> 553s] 基本的な技術のところを踏まえつつ利活用とですね リスクについてちゃんと知るというところが非常に重要かなと思います
[553s -> 561s] なのでまあ本日こちらのですね あの3つのテーマでもってパネルディスカッションの方で進めさせていただければと思います
[562s -> 568s] 最後にですねあのJDLA ジェネレティブAIテストということでまさにこういった課題をですね 解決する一つのツールとして
[568s -> 574s] 我々はこのJDLAのジェネレティブAIテストをですね 開発しているところになります
[575s -> 582s] ここでは誰もが使えるですね この生成AIをちゃんとビジネスで皆さんが主体的に
[582s -> 590s] 活用を推進していけるようなそういったテストを目指しておりまして まさにそういったテーマとですね本日のパネルディスカッションのテーマはもうオーバーラップ
[590s -> 596s] しておりますので まさにこちらのJDLA ジェネレティブAIテストの試験作成に関わる
[596s -> 602s] プロジェクトメンバーでもってですね パネルディスカッションの方をやらせていただければというふうに考えています
[602s -> 612s] ちょっとあの私の方からの話はですね これくらいにしておいて ここからですね実際にパネルディスカッションの方にですね 入っていければというふうに思います
[613s -> 624s] まずはですね 生成AIの技術についてのパネルになります それぞれのパネルディスカッションのところでですね メインパネラーということで
[624s -> 636s] 3名もしくは2名ですね ちょっと選出させていただきました ちょっとあの進め方なんですけれども メインパネラーの方にメインでお話ししていただく一方でですね
[636s -> 645s] おそらくかなり多様な話題が出てきますので ちょっとはそれに応じてですね メインパネラーじゃない方もですね ぜひ口を挟んでいただければと思いますので
[645s -> 651s] ぜひ積極的なご発言を いつも通り試験作成している時のような感じですね
[651s -> 658s] 挟んでいただければと思いますので どうぞよろしくお願いします じゃあまずはですね 生成AIの技術のところでメインパネラーとしてですね
[658s -> 664s] 井上さん 川原先生 そして佐々木さんの3名でお送りさせていただければと思います
[664s -> 673s] ちょっとあの3名ですね それぞれの自己紹介の方をしていただければと思います その際にですね ぜひ生成AIの関わり方とか 生成AIが自身に与えた影響とかですね
[673s -> 680s] そのあたりもちょっと交えてお話しいただければ最後です 井上さんからよろしくお願いします
[680s -> 688s] はい 株式会社エリスのファウンダーエンドシートをやってます 井上光輝と申します
[689s -> 696s] 普段はですね 東区大学の医学研究科の博士教育課程2年で 医療とLLMの研究をしておりまして
[696s -> 703s] で あとはLLMの関わり方で言いますと 雑誌に寄稿させていただいたりとか 勢力的な活動をしております
[703s -> 711s] で 私が与えた影響で言うと 私は博士教育課程でもともとセグメンテーションといろいろな研究をやってたんですけど
[711s -> 718s] なぜかLLMが研究テーマに変わりまして 博士のっていうぐらいインパクトが自分的にでかくて 最近変わったんですけど
[718s -> 725s] なのでそれぐらいインパクトが大きいなっていうぐらいのすごいものでした
[725s -> 731s] ちょっとすごい大変なんですけど 頑張ってます 以上です ありがとうございます
[731s -> 738s] はい 川原と申します 私は大瀬田大学で自然言語処理の研究をしておりまして
[738s -> 743s] もう25、6年 この自然言語処理の研究をしております
[743s -> 752s] 2018年にGPTとかBERTとか そういったモデルが出てきて そこでも結構驚いたんですけど
[752s -> 756s] かなりいろんなタスクで高精度にいろんなタスクが解けるというふうになりました
[756s -> 765s] さらに先ほども話ありましたけれども 2022年の11月にJAT GPTが出てきまして さらにびっくりしまして
[765s -> 770s] 我々研究者の中でもかなりこれはできるぞみたいな話になりまして
[770s -> 776s] そこからもすごい勢いでいろんな生成AIのモデルが出てきて ずっとびっくりし続けるという
[776s -> 781s] そういった有り様です よろしくお願いいたします
[781s -> 785s] はい よろしくお願いします スパイラルAIの佐々木と申します
[785s -> 789s] もともとですね ニューラルポケットっていう会社のCTOをやっていたんですけれども
[789s -> 796s] そちらから今 生成AI 文書処理系のところに 独立して会社を立ち上げたような形になっております
[796s -> 803s] 私が一番この転機にひとつきっかけになったところでいくと 去年の夏頃ですかね
[803s -> 807s] Galacticaっていうメタが作った言語モデルがありました
[807s -> 813s] 何かっていうと 科学論文とかに対して非常に高精度に答えてくれるとか
[813s -> 816s] 非常にすごい知識持ってるとか そういうものがありまして
[816s -> 821s] 私もともと出身自体も研究者なんですけれども その業界がですね
[821s -> 825s] もはや一振されそうな すごいパワフルさを感じたと
[825s -> 829s] ちょっと残念ながらパワフルすぎるのと 当時まだハルシネーションの問題とか色々あったんで
[829s -> 834s] 3日ぐらいでちょっと閉じられちゃった企画になりましたけれども
[834s -> 839s] でもそういう非常に強いパワーを持ったものが 言語モデルであるというところに衝撃を受けてですね
[839s -> 844s] 今後の繁盛を言語モデル業界に捧げていこうかなというふうに思ったという経緯になります
[844s -> 846s] よろしくお願いいたします
[846s -> 848s] ありがとうございます
[848s -> 853s] ではまずはですね 生成AIの技術について このメインパネルの3名とですね
[853s -> 855s] お話ししていければと思います
[855s -> 861s] ちょっとおそらく話題がですね 結構発散するというところのリスクも見越しまして
[861s -> 867s] 簡単に私の方から前提となるような知識のところを 最大限抑えておかなければならないようなところについて
[867s -> 870s] お話しさせていただきたいと思います
[870s -> 874s] 今ですね ちょっとスライド投影させていただいておりますけれども
[874s -> 879s] まず人工知能と呼ばれるですね 技術がどのように進化してきたのか
[879s -> 883s] ちょっと汎用性と性能というものを それぞれ横軸縦軸にとってですね
[883s -> 885s] これはあくまでイメージ図なんですけれども
[885s -> 891s] ちょっとその進化をですね 辿れるような整理をさせていただきました
[891s -> 894s] 一番左にありますルールベースの種
[894s -> 897s] これをですね 人工知能と呼ぶかどうかというのも 意見が分かれるところだと思うんですけど
[897s -> 904s] 基本的に全処理を人間が作るところから 機械学習という技術が出てきて
[904s -> 909s] これはデータに基づいてその特徴を学習して それを再表現するようなそういった技術になりますね
[909s -> 912s] そういったところから真相学習といって
[912s -> 918s] 特に出力に影響を与える入力データの中で 非常に特徴的な成分ですね
[918s -> 922s] 特徴量と言われるものを自動的に抽出できるようになったと
[922s -> 927s] さらにトランスフォーマーベースの手法というふうに 書かせていただきましたけれども
[927s -> 930s] チャットGPTとのベースになっている技術になりますけれども
[930s -> 932s] 2017年18年ぐらいですかね
[932s -> 938s] あらかじめ大量の言語データを与えることによって 基礎的な言語能力を身につけた上で
[938s -> 942s] 用途に特化させるところについては そのモデルのですね
[942s -> 946s] 微妙な微修正というんですかね
[946s -> 949s] ファインチューニング等で行えるようになった といった技術になります
[949s -> 952s] こういったファインチューニングであったりとか
[952s -> 954s] あとは追加的な強化学習等をですね
[954s -> 961s] このLLM トランスフォーマーベースの手法が 適用されたモデルに適用すると
[961s -> 963s] しかもその適用の仕方をですね
[963s -> 966s] 人間へのアラインというふうに 書かせていただきましたけれども
[966s -> 970s] 自然で倫理的な受け答えに特化したような ファインチューニングであったり
[970s -> 972s] 強化学習をかけることによって
[972s -> 975s] チャットGPTのような倫理性であったりとか
[975s -> 978s] そういったかなり人間に近しい振る舞いをするような
[978s -> 982s] 先進的なLLMができたというふうに 言われているところになります
[982s -> 986s] こういった技術的な進化があって
[986s -> 988s] 先ほど冒頭にお話ししたような
[988s -> 992s] 言葉で挙動をコントロールできるような そういったAIができたと
[992s -> 996s] 大きくはこういったAIの進化が あったのかなというふうに思います
[996s -> 999s] ちょっとこういったですね AIの進化
[999s -> 1001s] そういったところを踏まえまして
[1001s -> 1004s] パネルディスカッションの方に 移らせていただければと思います
[1004s -> 1006s] 本日ですね それぞれのパネルについて
[1006s -> 1009s] 4つのテーマを用意しておりまして
[1009s -> 1011s] 私の独断と偏見
[1011s -> 1014s] もしくは視聴者の方からの多数決で
[1014s -> 1016s] テーマを決めていければと思います
[1016s -> 1019s] まずは私の方から独断と偏見でですね
[1019s -> 1021s] 偏見じゃない 独断でですね
[1021s -> 1023s] Aのところですね 最先端のLLM
[1023s -> 1025s] 結局何がすごいのかと
[1025s -> 1028s] 今ちょっとAIの進化のところを お話しさせていただきましたけども
[1028s -> 1030s] 特にお三方から見て
[1030s -> 1033s] ご意見を伺えればと思います
[1033s -> 1035s] まず川原先生 いかがでしょうか
[1035s -> 1038s] はい 何がすごいのかということですけれども
[1038s -> 1040s] 2点あると思います
[1040s -> 1043s] 1つ目は先ほど山本さんがおっしゃったように
[1043s -> 1045s] 汎用性ですよね
[1045s -> 1049s] 自然言語で指示をできるという点にあります
[1049s -> 1053s] もう1個 高性能さんにありまして
[1053s -> 1057s] すごい流暢な日本語でも英語でも
[1057s -> 1060s] 言語を返してくるというところが 大きいと思います
[1060s -> 1063s] それはなぜできているのかというと
[1063s -> 1065s] 分かんないんですけれども
[1065s -> 1068s] よく言われるのはスケーリングローって言って
[1068s -> 1071s] モデルの大きさ パラメーター数とか言いますけれど
[1071s -> 1074s] モデルの複雑さが大きくなると
[1074s -> 1076s] それに伴って高性能になると
[1076s -> 1080s] さらに学習するテキスト量を増やしていくと
[1080s -> 1082s] どんどん賢くなると
[1082s -> 1084s] そういったところにあって
[1084s -> 1087s] それによって高性能さが出てきているというところが
[1087s -> 1089s] すごいというところだと思います
[1089s -> 1091s] ありがとうございます
[1091s -> 1093s] このなぜ良くなっているのか分からないと
[1093s -> 1095s] すごく惹かれるんですけれども
[1095s -> 1098s] こういったなぜ良くなっているのかというところに
[1098s -> 1099s] 対する研究もいます
[1099s -> 1101s] アカデミアのところでは進んでいるんでしょうか
[1101s -> 1104s] いろんな研究がなされておりますし
[1104s -> 1107s] なんで例えばチャットGPで
[1107s -> 1110s] ほとんど英語でしか学習していないのに
[1110s -> 1114s] 日本語もかなりしゃべれるのはなぜだろうというところもありまして
[1114s -> 1116s] いろんな研究がなされてますけれども
[1116s -> 1120s] まだ全然分かってないというところだと思います
[1120s -> 1122s] ありがとうございます
[1122s -> 1124s] ではぜひですね
[1124s -> 1126s] 井上さん
[1126s -> 1130s] 人生を変えたLLMというふうに先ほどおっしゃってました
[1130s -> 1133s] そうですね 私の人生を変えてくれたLLMなんですけど
[1133s -> 1135s] 2つあると思ってまして
[1135s -> 1139s] 1つ目がシンプルにパラメータ数というのがあると思います
[1139s -> 1142s] 例えば今までの言語モデルというのは
[1142s -> 1146s] BERTとかだと3.4億ぐらいのパラメータ数があって
[1146s -> 1148s] GPT3.5とかだと
[1148s -> 1150s] これリファレンスちゃんとないんですけど
[1150s -> 1152s] 3.550億ぐらいのパラメータ数があるんですね
[1152s -> 1155s] シンプルに1000倍ぐらい違うというところがまず1つあって
[1155s -> 1159s] 2つ目が先ほど川原先生おっしゃってくれたんですけど
[1159s -> 1161s] ゼロショットの性能の良さというところで
[1161s -> 1165s] 今まではやはり学習しないと性能が出なかったんですけど
[1165s -> 1169s] そこが学習しなくてもゼロショットである程度も使えものになると
[1169s -> 1172s] 素晴らしいところかなというふうに認識しております
[1172s -> 1174s] 以上です
[1174s -> 1175s] ありがとうございます
[1175s -> 1178s] 一方でこれまでのAIを知っている我々からすると
[1178s -> 1180s] パラメータ数が多いということは
[1180s -> 1182s] 説明可能性というんですかね
[1182s -> 1185s] なぜそのAIがその出力を出したのかという
[1185s -> 1187s] 根拠が分かりづらくなるという
[1187s -> 1189s] 負の側面があると思うんですけど
[1189s -> 1192s] このあたりについてはいかがお考えですかね
[1192s -> 1194s] 透明性みたいなところは
[1194s -> 1197s] もともとグラッドカムとか画像だとあったんですけど
[1197s -> 1201s] このあたりも今後研究が進んでいくんだろうなと
[1201s -> 1203s] 画像でもそういう流れになって
[1203s -> 1205s] 後に発展していったので
[1205s -> 1209s] 言語モデルでもこういうふうに進んでいくと思います
[1209s -> 1210s] なるほど
[1210s -> 1215s] 結構先ほどの川原先生のお話じゃないですけど
[1215s -> 1218s] 何で良くなっているのか分からないというところがありつつも
[1218s -> 1221s] パラメータ数が多くなることによって
[1221s -> 1224s] さらに説明可能性というところが
[1224s -> 1227s] 多分損なわれていくという側面もありつつも
[1227s -> 1228s] ただですね
[1228s -> 1231s] ChatGPTとの先進的なエネルギーに
[1231s -> 1233s] 根拠と共に教えてくださいというとですね
[1233s -> 1237s] 人間が納得するような形で根拠を教えてくれるんですよね
[1237s -> 1240s] なぜその根拠が出てくるのかというのは
[1240s -> 1242s] 理解はすごく難しいと思うんですよ
[1242s -> 1243s] パラメータ数が多いから
[1243s -> 1245s] 一方で人間が理解しやすい
[1245s -> 1248s] 情報を得ることは簡単になっている
[1248s -> 1251s] すごいトレードオフというんですかね
[1252s -> 1254s] アンバランスな感じがすごいしてるんですよね
[1254s -> 1259s] そのあたり何かご意見等お持ちでしょうか
[1259s -> 1260s] そうですね
[1260s -> 1262s] 結構発散しそうな話題かなと
[1262s -> 1265s] これ僕ばっかり喋って大丈夫ですか
[1265s -> 1266s] 何だろうな
[1266s -> 1268s] このあたりは
[1268s -> 1272s] 頑張り屋さんな新入社員みたいなイメージがあって
[1272s -> 1275s] とりあえず何でも喋るんですよ間違えてても
[1275s -> 1277s] なのでこの辺のファインチューニングが
[1277s -> 1278s] 後で出てくると思うんですけど
[1278s -> 1279s] ちゃんと学習で
[1279s -> 1281s] そこら辺を学習させるみたいな必要で
[1281s -> 1283s] 後でまたこれ出ると思うんですけど
[1283s -> 1285s] ラグとか最近あると思うんですけど
[1285s -> 1286s] あれ使っても
[1286s -> 1288s] やっぱり答えなんとなく出しちゃうみたいな
[1288s -> 1289s] あったりするんで
[1289s -> 1290s] ファインチューニングとか
[1290s -> 1293s] もっとそれ以前のAIのルールベースであったりとか
[1293s -> 1295s] そういうところが必要になってくるのかな
[1295s -> 1297s] というふうに思ってます
[1297s -> 1298s] ありがとうございます
[1298s -> 1300s] まさに何かビジネス×性性愛の話題に
[1300s -> 1303s] 何か繋がりそうな回答いただきたいなと思いました
[1303s -> 1304s] ありがとうございます
[1304s -> 1305s] ありがとうございました
[1305s -> 1307s] じゃあぜひ佐々木さんの方からも
[1307s -> 1309s] これからの人生をLLMに捧げますと
[1309s -> 1311s] おっしゃっておりましたけれども
[1311s -> 1313s] やっぱすごいのは
[1313s -> 1315s] お二方おっしゃった通りだと思うんですよね
[1315s -> 1318s] まずいわゆるインコンテキストラーニングと呼ばれる
[1318s -> 1321s] チューニング独自に学習させなくても
[1321s -> 1323s] 文章でこうしてくださいって言えば
[1323s -> 1325s] どんなタスクでもやってくれますっていう
[1325s -> 1326s] この手軽さは
[1326s -> 1329s] もう何者にも変えがたい
[1329s -> 1332s] それまでって結局GPU
[1332s -> 1334s] いわゆるBERTの時代だと
[1334s -> 1335s] まだタスクごとに
[1336s -> 1338s] チューニングしないと性能出ないよね
[1338s -> 1339s] っていう時代だったわけです
[1339s -> 1341s] こうなると結局GPU持ってないとどうしようもないです
[1341s -> 1342s] というところで
[1342s -> 1344s] 学習データの準備もやっぱり専門性欲しくなる
[1344s -> 1346s] という世界観から
[1346s -> 1349s] 文章の中にプロンプトで指示書けば
[1349s -> 1351s] もうそれでやってくれますってなったら
[1351s -> 1354s] 日本語とか言葉しゃべれる方だったら
[1354s -> 1356s] 誰でもできるってことを意味してるわけですよね
[1356s -> 1358s] えらい裾の広がったなっていう風なことが
[1358s -> 1360s] まず大きく違うのかなという風に
[1360s -> 1362s] 大きなポイントなのかなという風に
[1362s -> 1364s] まず思いますね
[1365s -> 1366s] ありがとうございます
[1366s -> 1369s] まさにその通りかなという風に思います
[1369s -> 1373s] では次のテーマに移れればと思いますけれども
[1373s -> 1377s] ABCDで今Aのテーマについてお話させていただきましたが
[1377s -> 1383s] BCDでどのテーマについて話すかについて
[1383s -> 1389s] 視聴者の方に多数決でアンケートを書いていただけたと
[1389s -> 1393s] こちら結果どのような形になってますか
[1394s -> 1397s] こちらですね
[1397s -> 1401s] Dの技術動向何を注目すべきといったテーマについて
[1401s -> 1403s] 皆さんお聞きになりたいということなので
[1403s -> 1406s] この辺りについてお話しいただければと思います
[1406s -> 1410s] まさに先ほどスケーリングローみたいな話ありましたけども
[1410s -> 1412s] データ量とか計算量とかパラメータ数
[1412s -> 1414s] これを上げれば上げるほど性能が良くなっていく
[1414s -> 1417s] 量的な観点と一方で冒頭にもお話ししました
[1417s -> 1421s] アライメントみたいな学習のさせ方を工夫することによって
[1421s -> 1425s] 高性能にしていくという量的質的2つの観点で
[1425s -> 1428s] 基本的には動向というのがあると思うんですけど
[1428s -> 1431s] ぜひお三方からどういったところに
[1431s -> 1433s] これから注目すべきかといったところを
[1433s -> 1435s] お話しいただければと思います
[1435s -> 1437s] まず川田先生から
[1437s -> 1439s] はいいろいろあるんですけれども
[1439s -> 1441s] 一つ言うのであれば
[1441s -> 1445s] まずチャットGPTとかは言語モデルですよね
[1445s -> 1447s] 言語なんですよね
[1447s -> 1449s] 今最近よく聞くのは
[1449s -> 1452s] マルチモーダルというキーワードだと思うんですけれども
[1452s -> 1455s] 例えば画像であるとか映像そして音声であるとか
[1455s -> 1457s] そういったいろんなモーダルのものを
[1457s -> 1459s] くっつけたマルチモーダルモデルというのは
[1459s -> 1461s] これからどんどん出てきて
[1461s -> 1463s] 重要になっていくというのは間違いないと思います
[1463s -> 1466s] さらにロボットを制御するとか
[1466s -> 1468s] そういったこともあると思いますので
[1468s -> 1471s] そこら辺に広がっていくと思っていまして
[1471s -> 1475s] そもそも赤ちゃんのときから言語を学習するというのは
[1475s -> 1477s] 言語だけじゃなくて
[1477s -> 1480s] こういう実環境から学ぶというのが大きいと思います
[1480s -> 1482s] そういったことを学習させて
[1482s -> 1485s] まさに人間のようなモデル
[1485s -> 1488s] 基盤モデルと呼ばれるかもしれないですけれども
[1488s -> 1490s] そういうものを作っていって
[1490s -> 1493s] それが応用に使われていくというのが今後だと思います
[1493s -> 1495s] なるほど
[1495s -> 1497s] まさにテキストだけじゃなくて
[1497s -> 1499s] モダリティのお話されていましたけれども
[1499s -> 1501s] ロボットのお話もされていましたけれども
[1501s -> 1503s] 肉体を与えるであったりとか
[1503s -> 1505s] 人間の知覚を与えるというか
[1505s -> 1507s] 人間により近づける方向での
[1507s -> 1509s] 動向というところになりますかね
[1509s -> 1511s] ぜひ井上さん
[1511s -> 1513s] 最初に言おうと思っていたことを
[1513s -> 1515s] 言われてしまってどうしようかな
[1515s -> 1517s] 今ちょっと考えているんですけど
[1517s -> 1519s] 何個かありましてマルチモデルがまず一つあって
[1519s -> 1521s] そこから発展したところで
[1521s -> 1523s] ドメイン適用みたいなところがあって
[1523s -> 1525s] これは医療とか最近
[1525s -> 1527s] マイクロソフトさんとか
[1527s -> 1529s] Googleさんとかメドパルムとか
[1529s -> 1531s] ラバーメドとかいろいろモデルがあるんですけど
[1531s -> 1533s] 医療特化にドメイン適用というところがありますと
[1533s -> 1535s] 3つ目だと
[1535s -> 1537s] 例えばGPT-4とかの
[1537s -> 1539s] 学習の方でいうと
[1539s -> 1541s] いろんな実はモデルがあるんだみたいな
[1541s -> 1543s] MOEみたいなエキスパートな
[1543s -> 1545s] モデルがたくさんあってやっていくみたいなところで
[1545s -> 1547s] 専門的なリルムを作るみたいな
[1547s -> 1549s] 流れになっていくと思うんですね
[1549s -> 1551s] そういうマルチプリなところが3つ目で
[1551s -> 1553s] 4つ目が学習のデータの質ですね
[1553s -> 1555s] これはコーパスとか呼ばれるところの
[1555s -> 1557s] 学習をやっぱりきれいにするとか
[1557s -> 1559s] 学習方法でも
[1559s -> 1561s] 少ないデータでもきれいにしていけば
[1561s -> 1563s] かなり性能が上がるみたいなのが知られてるんで
[1563s -> 1565s] この辺りの4つぐらいを注目すると
[1565s -> 1567s] 結構面白いのかなという風に
[1567s -> 1569s] 思います
[1569s -> 1571s] ありがとうございます さらに4つを出していただいたというところで
[1571s -> 1573s] ハードルが
[1573s -> 1575s] 全部言っちゃいましたね
[1575s -> 1577s] 僕は
[1577s -> 1579s] 逆の視点からあえて言うと
[1579s -> 1581s] 社会応用の時代に入ったと思うんですよね
[1581s -> 1583s] だから実際使ってみて
[1583s -> 1585s] 使いづらと思ったものが
[1585s -> 1587s] 全部技術的に解決されるべき課題だと思います
[1587s -> 1589s] 例えばコンテキスト帳が限定的で
[1589s -> 1591s] 長い文章入れられなくて困ってます
[1591s -> 1593s] っていうのからドライブされて
[1593s -> 1595s] 最近コンテキスト帳の長めのやつも出てきてますよね
[1595s -> 1597s] ストリーミングエレメントとかですけれども
[1597s -> 1599s] みたいなものも
[1599s -> 1601s] もちろん研究者の方ってそういう
[1601s -> 1603s] 使いづらさを一番よく理解されてるので
[1603s -> 1605s] 当然裏で研究動いてるんですけれども
[1605s -> 1607s] そういうのが結局関係してくると
[1607s -> 1609s] あとは関連する話的なコストみたいなところも
[1609s -> 1611s] 今度聞いてくるでしょうね
[1611s -> 1613s] 言語モデルが大きくなっていけば大きくなっていくほど
[1613s -> 1615s] コストがかかっちゃいますので
[1615s -> 1617s] ドメイン特化型みたいなところで
[1617s -> 1619s] 必要十分サイズみたいなものに
[1619s -> 1621s] 分化していくんだろうなという風に思っていたりとか
[1621s -> 1623s] あと速度が遅いよねって話も
[1623s -> 1625s] 先ほど
[1625s -> 1627s] 事前の
[1627s -> 1629s] かわわせみたいなところでも速度問題話出てましたけれども
[1629s -> 1631s] やっぱり速度遅いんであれば
[1631s -> 1633s] それを解消してあげるべきと
[1633s -> 1635s] さらに言うと
[1635s -> 1637s] 推論環境をきちんとホストしてあげる
[1637s -> 1639s] っていうのは思ったより難易度高いので
[1639s -> 1641s] そのあたりの実用的な技術課題とか
[1641s -> 1643s] あたりも含めて
[1643s -> 1645s] さらに言うとあれですね
[1645s -> 1647s] 言語モデル個別に作って
[1647s -> 1649s] よくお客様からもお話を伺うんですけれども
[1649s -> 1651s] 事業部ごとに言語モデル作りますと
[1651s -> 1653s] この事業部の知識も出せますって言って
[1653s -> 1655s] やるのはいいんですけれども
[1655s -> 1657s] でもやっぱり細分化していくと
[1657s -> 1659s] 情報のセキュリティの話とかあって
[1659s -> 1661s] この役職の人はここの情報にアクセスしていい
[1661s -> 1663s] この情報はダメみたいな
[1663s -> 1665s] 時にどうやってそれを制御するのとか
[1665s -> 1667s] 結構現実問題いろいろ出てくるはずなので
[1667s -> 1669s] そのあたりが全部今後解決されるべき
[1669s -> 1671s] 技術動向の論点になっていくんだろうな
[1671s -> 1673s] というふうに思いますね
[1673s -> 1675s] ありがとうございます
[1675s -> 1677s] 今すごくいい視点をご提供いただけたかな
[1677s -> 1679s] というふうに思います
[1679s -> 1681s] いろんな技術課題は
[1681s -> 1683s] ニーズから生まれるというようなお話
[1683s -> 1685s] いただいていたのかなと
[1685s -> 1687s] 誰もが使える生成案が出てきて
[1687s -> 1689s] これをビジネスに応用しようとすると
[1689s -> 1691s] 本当にビジネスに関わるすべての人から
[1691s -> 1693s] おそらくニーズが出てくるんじゃないかな
[1693s -> 1695s] というふうに思います
[1695s -> 1697s] なのでビジネスで実際に使っていて
[1697s -> 1699s] 不満に思うところであったりとか
[1699s -> 1701s] 課題に思うところ
[1701s -> 1703s] こういったところはそれぞれの方々
[1703s -> 1705s] 結構これまでだと
[1705s -> 1707s] 技術に直接影響を与えるような
[1707s -> 1709s] インタラクションというのは
[1709s -> 1711s] 結構ビジネスサイドからはしづらかった部分が
[1711s -> 1713s] あると思うんですけど
[1713s -> 1715s] そういったところがより活性化していくんじゃないかな
[1715s -> 1717s] という印象もしました
[1717s -> 1719s] ちょっと先ほどから
[1719s -> 1721s] 深津さんがニヤリとされているんですけど
[1721s -> 1723s] 何か
[1723s -> 1725s] 勉強になるなみたいな話
[1725s -> 1727s] 僕なんかは結構
[1727s -> 1729s] どっちかというと
[1729s -> 1731s] あとで自己紹介で言おうと思ったんですけど
[1731s -> 1733s] MLそのもののプロじゃなくて
[1733s -> 1735s] 結局言語モデル使って
[1735s -> 1737s] どうサービス作る
[1737s -> 1739s] どう実レベルでいい出力出す
[1739s -> 1741s] みたいなところで考えちゃう側なので
[1741s -> 1743s] さっきの
[1743s -> 1745s] 間の問題みたいなのとかも
[1745s -> 1747s] エージェントでやるときは
[1747s -> 1749s] なるほどそれねみたいなのとかを
[1749s -> 1751s] 喋らせている間に
[1751s -> 1753s] GPT-4に投げるとかみたいな
[1753s -> 1755s] 結構卑怯なことで解決とかも
[1755s -> 1757s] したりするかも
[1757s -> 1759s] 面白いですね
[1759s -> 1761s] ぜひそのあたり詳しくお聞かせください
[1761s -> 1763s] ありがとうございます
[1763s -> 1765s] そうですね
[1765s -> 1767s] あと5分と迫ってきましたけれども
[1767s -> 1769s] そうですね
[1769s -> 1771s] 私のほうから選ばせていただいて
[1771s -> 1773s] Cのところですね
[1773s -> 1775s] 各種用途で性能を上げる方法
[1775s -> 1777s] 結構すごく性能がいい
[1777s -> 1779s] ChatGPTのようなLLMが出てきて
[1779s -> 1781s] ちょっとした調整で
[1781s -> 1783s] 性能を格段に上げることができるような
[1783s -> 1785s] 世界になってきていると
[1785s -> 1787s] 大きくはプロンプトエンジニアリングみたいな
[1787s -> 1789s] 質問文を変えることによる
[1789s -> 1791s] 調整と
[1791s -> 1793s] もう1個はモデル自体を調整する
[1793s -> 1795s] ファインチューニングみたいな方向性があると思うんですけど
[1795s -> 1797s] このプロンプトエンジニアリングVS
[1797s -> 1799s] ファインチューニングについてですね
[1799s -> 1801s] ご意見を伺わせていただければと思います
[1801s -> 1803s] 川原先生いかがでしょうか
[1803s -> 1805s] はいこれは派閥があります
[1805s -> 1807s] 派閥がありまして
[1807s -> 1809s] 私はどちらかというと
[1809s -> 1811s] ファインチューニング派なんですけれども
[1811s -> 1813s] 少量でいいので
[1813s -> 1815s] 高品質なデータを作ると
[1815s -> 1817s] つまりプロンプトに対して
[1817s -> 1819s] こうレスポンスしたらいいよというデータを
[1819s -> 1821s] 数百でも作ってあげて
[1821s -> 1823s] それでファインチューニングすると
[1823s -> 1825s] 驚くほど精度は
[1825s -> 1827s] 上がるケースが多いとは思いますので
[1827s -> 1829s] そっち派なんですけれども
[1829s -> 1831s] 一方でお手軽にプロンプトエンジニアリングで
[1831s -> 1833s] 精度上がるというのはありますので
[1833s -> 1835s] それはちょっと用途によって
[1835s -> 1837s] 使い分ける必要があるかなと思います
[1837s -> 1839s] ありがとうございます
[1839s -> 1841s] 井上さんはどっち派閥でしょうか
[1841s -> 1843s] あえて議論を崩したいと思っていて
[1843s -> 1845s] プロンプトエンジニアリングVS
[1845s -> 1847s] ファインチューニングがないというところで
[1847s -> 1849s] これは両立できるよという話なんですよ
[1849s -> 1851s] 実は
[1851s -> 1853s] ファインチューニングの方はRLHFとかで
[1853s -> 1855s] 人間が好ましいようなやつに作れるというのがありますし
[1855s -> 1857s] あとはインストラクションチューニングとかで
[1857s -> 1859s] これ学習結構いい感じにできますし
[1859s -> 1861s] プロンプトエンジニアリングは
[1861s -> 1863s] さらに学習しなくてもできるというところがあるんですけど
[1863s -> 1865s] やっぱりプロンプトエンジニアリングだと
[1865s -> 1867s] ちょっとお金かかっちゃったり
[1867s -> 1869s] フューショットで結構文章なくなっちゃったりするので
[1869s -> 1871s] 推論時間かかったりとか
[1871s -> 1873s] いろいろ問題があるんですね
[1873s -> 1875s] ちゃんと学習させようと思うと
[1875s -> 1877s] ファインチューニングが必要なんですけど
[1877s -> 1879s] これは競合するものではないというところで
[1879s -> 1881s] あえて議論を崩してみたというところです
[1881s -> 1883s] ありがとうございます
[1883s -> 1885s] 佐々木さんいかがでしょう
[1885s -> 1887s] これはケースバイケースですよね
[1887s -> 1889s] ケースバイケースなので
[1889s -> 1891s] そこら辺の体系的な知識を持つのが
[1891s -> 1893s] この生成AIの試験であるというところだと思うんですけれども
[1893s -> 1895s] そうですね
[1895s -> 1897s] プロンプトエンジニアリングでまず突き詰めるだけ
[1897s -> 1899s] 突き詰めておいて
[1899s -> 1901s] そうすると結局コストの問題もそうですし
[1901s -> 1903s] やっぱりプロンプトインジェクション系のものに対して
[1903s -> 1905s] どんなに言ってもやっぱり
[1905s -> 1907s] 露出しちゃうみたいな話も出てくるので
[1907s -> 1909s] そういう時に
[1909s -> 1911s] ファインチューニングみたいなテクノロジーに
[1911s -> 1913s] スイッチしていくみたいな
[1913s -> 1915s] 開発前半は機動性優先で
[1915s -> 1917s] なるべくプロンプトレベルで処理しておいて
[1917s -> 1919s] その後もプロダクションで
[1919s -> 1921s] マネタイズの段階に入ってきたら
[1921s -> 1923s] ファインチューニングとか
[1923s -> 1925s] どういう使い方なのかなという風な感じを
[1925s -> 1927s] 今のところ思ってますね
[1927s -> 1929s] ありがとうございます
[1929s -> 1931s] なるほど
[1931s -> 1933s] 一方でファインチューニングは結構な知識であったりとか
[1933s -> 1935s] テクニックを知ってないと
[1935s -> 1937s] なかなかいい結果を出せないというような
[1937s -> 1939s] ちょっと側面もあるのかなと
[1939s -> 1941s] ただ今まさに議論を崩す目的でという
[1941s -> 1943s] お話でしたけれども
[1943s -> 1945s] 2つは共存するのかなという風に
[1945s -> 1947s] すごい印象を受けまして
[1947s -> 1949s] そういう観点だと
[1949s -> 1951s] ビジネスサイドの機動性重視のところと
[1951s -> 1953s] あとは技術観点でいいですかね
[1953s -> 1955s] 技術サイドの
[1955s -> 1957s] ちゃんとしたAIの専門家が
[1957s -> 1959s] チューニングするところと
[1959s -> 1961s] ここがちゃんと連携することによって
[1961s -> 1963s] その共存関係が保たれるのかなという風な
[1963s -> 1965s] 印象を受けました
[1965s -> 1967s] これからまさに今日のテーマではありますけれども
[1967s -> 1969s] ビジネスのアドオンというところでは
[1969s -> 1971s] ビジネスの専門家と
[1971s -> 1973s] あとはAIの専門家が本当に連携して
[1973s -> 1975s] 進めるべき課題なのかなという風にも
[1975s -> 1977s] 思いました ありがとうございます
[1981s -> 1983s] 残り3分ということで若干そうですね
[1983s -> 1985s] 微妙な時間ですけれども
[1987s -> 1989s] そうですね
[1989s -> 1991s] じゃあ最後のテーマいってみましょうか
[1991s -> 1993s] モデル事情
[1993s -> 1995s] いろんなモデルが出てきていると
[1995s -> 1997s] チャットGPT以外にもいろんなモデルが出てきていると
[1997s -> 1999s] 先ほどちょっと佐々木さんの方からも
[1999s -> 2001s] ありましたけれども
[2001s -> 2003s] こういったモデルどういったバリエーションで
[2003s -> 2005s] どんな感じの多様性が今あるのかみたいなところですね
[2005s -> 2007s] ご意見を伺えればと思います
[2007s -> 2009s] まずはじゃあ佐々木さんからお願いします
[2009s -> 2011s] 今すごい数ありますよね
[2011s -> 2013s] 1万種類以上あるとか
[2013s -> 2015s] それの樹形図というか
[2015s -> 2017s] 架形図を作った方もいらっしゃるという話も
[2017s -> 2019s] 聞きますし
[2019s -> 2021s] 難しいトピックですよね
[2021s -> 2023s] ただこれ
[2023s -> 2025s] 以前
[2025s -> 2027s] 柴田さんが主催されたセミナーで
[2027s -> 2029s] お話を伺いましたけれども
[2029s -> 2031s] 使い方に関しては2つに分かれていて
[2031s -> 2033s] 本当にゼロから作りますか
[2033s -> 2035s] 流派と
[2035s -> 2037s] もともとあるものを
[2037s -> 2039s] 目的にチューニングしますかの流派
[2039s -> 2041s] 多分この2つをまず一旦考えればよくて
[2041s -> 2043s] 仮に後者なんであれば
[2043s -> 2045s] その後者向けの
[2045s -> 2047s] ベースになるモデルを選ぶのは
[2047s -> 2049s] そんな難しい話ではないので
[2049s -> 2051s] そういう感じでちょっと大変すぎるので
[2051s -> 2053s] 全部追うのを諦めて
[2053s -> 2055s] 使い方だけ考えてますね
[2055s -> 2057s] なるほど
[2057s -> 2059s] ありがとうございます
[2059s -> 2061s] これは3つに分類できます
[2061s -> 2063s] 実は
[2063s -> 2065s] 3つぐらい分類できると思っていて
[2065s -> 2067s] このLLMですね
[2067s -> 2069s] これは最近出た松尾健のやつとか
[2069s -> 2071s] プリファラさんが出されているようなモデルがあって
[2071s -> 2073s] あとは英語のやつを
[2073s -> 2075s] 日本で学習する
[2075s -> 2077s] エライダさんがやっているような学習モデルがあって
[2077s -> 2079s] もう1個がドメイン適用のモデルなんですけど
[2079s -> 2081s] これで言うと圧倒的に少ないので
[2081s -> 2083s] 実はドメイン適用のモデルになってまして
[2083s -> 2085s] ストックマークさん
[2085s -> 2087s] ぐらいしかないんじゃないかなというところで
[2087s -> 2089s] なので私はもっと
[2089s -> 2091s] ドメイン適用のモデルがもっと増えていけば
[2091s -> 2093s] いいなという風に
[2093s -> 2095s] 思っています
[2095s -> 2097s] なるほど
[2097s -> 2099s] ちなみに日本の技術
[2099s -> 2101s] 日本のモデルという観点で川原先生
[2101s -> 2103s] お話できましたでしょうか
[2103s -> 2105s] まずChatGPTなどにしても
[2105s -> 2107s] 英語で
[2107s -> 2109s] 入れると
[2109s -> 2111s] 日本語よりは精度が良いというのはありますので
[2111s -> 2113s] やはり日本語のモデルを
[2113s -> 2115s] 使うというのは重要なことだと思います
[2115s -> 2117s] 日本語というモデルだと
[2117s -> 2119s] さっき
[2119s -> 2121s] 松尾健が出している
[2121s -> 2123s] いろんなところから出しているのがあるんですけれども
[2123s -> 2125s] 私が関与している
[2125s -> 2127s] LLMJPというところで
[2127s -> 2129s] これまさに金曜日に
[2129s -> 2131s] 13ビリオンのモデルがリリースされたんですけれども
[2131s -> 2133s] 割と高精度に
[2133s -> 2135s] 使えますし
[2135s -> 2137s] 何がポイントかと言いますとモデルだけじゃなくて
[2137s -> 2139s] いろんなものつまりツールであるとか
[2139s -> 2141s] コーパスであるとかそういったものをすべて
[2141s -> 2143s] オープンにしていくということで
[2143s -> 2145s] そういった活動をしておりますので
[2145s -> 2147s] ぜひお使いいただければと思います
[2147s -> 2149s] ありがとうございます
[2149s -> 2151s] ということでキャッチーなフレーズで
[2151s -> 2153s] テーマ名を考えたんですけれども
[2153s -> 2155s] まさにすごく対応な
[2155s -> 2157s] 状況であると言ったところが
[2157s -> 2159s] 把握できました
[2159s -> 2161s] ありがとうございます
[2161s -> 2163s] では生成アイの技術パネルディスカッションテーマ1
[2163s -> 2165s] については以上とさせていただきます
[2165s -> 2167s] ありがとうございました
[2167s -> 2169s] ありがとうございました
[2169s -> 2171s] 続きまして
[2171s -> 2173s] パネルディスカッションテーマ2の方に
[2173s -> 2175s] 移れればと思います
[2175s -> 2177s] 生成アイの利活用を
[2177s -> 2179s] 使えるといったところで
[2179s -> 2181s] いかに活用用途を見出すか
[2181s -> 2183s] ご自身の生活や業務に照らし合わせて
[2183s -> 2185s] そういったところについては
[2185s -> 2187s] お話いただければと思います
[2187s -> 2189s] メインパネルは
[2189s -> 2191s] 柴田さんと深津さんよろしくお願いします
[2191s -> 2193s] ではぜひ自己紹介の方を
[2193s -> 2195s] お願いできればと思います
[2195s -> 2197s] まず柴田さんからお願いします
[2197s -> 2199s] 皆さんこんばんは柴田明と申します
[2199s -> 2201s] ちょっと固くないですか
[2201s -> 2203s] 今日のイベントは
[2203s -> 2205s] 固いですか
[2205s -> 2207s] いいんじゃないかなと
[2207s -> 2209s] 柔らかくいきましょう
[2209s -> 2211s] 最後のパートまた固いのが
[2211s -> 2213s] 来ちゃうから
[2213s -> 2215s] ここは緩く
[2215s -> 2217s] お手柔らかにしてもらえればなと
[2217s -> 2219s] 私は
[2219s -> 2221s] 今
[2221s -> 2223s] ウェイズアドバイスという
[2223s -> 2225s] アメリカのAIスタートアップの
[2225s -> 2227s] 日本と韓国のビジネス展開を
[2227s -> 2229s] していまして
[2229s -> 2231s] 昨日まで韓国に
[2231s -> 2233s] 行ってたんですけど
[2233s -> 2235s] 韓国の会社とか面白いですね
[2235s -> 2237s] 勝つことしか考えてない
[2237s -> 2239s] みたいなところがあって
[2239s -> 2241s] すごい刺激をもらってます
[2243s -> 2245s] そうですねLLMに関していうと
[2245s -> 2247s] いろいろやってるんですけれども
[2247s -> 2249s] 最近は
[2249s -> 2251s] 深津さんも一緒に
[2251s -> 2253s] 計算書の委員会みたいなのも
[2253s -> 2255s] いろいろやったりとか
[2255s -> 2257s] なぜか僕もいらっしゃいますよね
[2259s -> 2261s] あとは
[2261s -> 2263s] リーダーボードというのはご存知の方も
[2263s -> 2265s] 最近増えてきて
[2265s -> 2267s] ありがたいんですけれども
[2267s -> 2269s] 最後の話と同じところで
[2269s -> 2271s] すごいいっぱいモデルが
[2271s -> 2273s] あって
[2273s -> 2275s] やっぱり海外から来るモデル多いですよね
[2275s -> 2277s] 日本でも結構増えてきたけど
[2277s -> 2279s] 日本のモデルと大きさ的には
[2279s -> 2281s] 小さいモデルが多くて
[2281s -> 2283s] そういうモデルが
[2283s -> 2285s] 日本語でどれくらい性能を
[2285s -> 2287s] 持っているのかということに関しては
[2287s -> 2289s] 常にいろんな質問があったので
[2289s -> 2291s] 弊社では
[2291s -> 2293s] ウェイズアドバイスという製品を使って
[2293s -> 2295s] ちなみにこの製品を
[2295s -> 2297s] ちょっと宣伝すると
[2297s -> 2299s] オープンAIも
[2299s -> 2301s] そのモデルを開発するために
[2301s -> 2303s] 使っている製品なんですけれども
[2303s -> 2305s] この製品を使って
[2305s -> 2307s] いろんなモデルの評価を自動化して
[2307s -> 2309s] 皆さん比較できるようにしよう
[2309s -> 2311s] ということをやっています
[2311s -> 2313s] ちょうどさっき
[2313s -> 2315s] 川橋先生ともお話してたんですけど
[2315s -> 2317s] このLLMJPから出た
[2317s -> 2319s] モデルというのが
[2319s -> 2321s] 金曜日ですよね
[2321s -> 2323s] 出て
[2323s -> 2325s] 私たちも評価したんですけれど
[2325s -> 2327s] かなりGPT-4に迫る
[2327s -> 2329s] スコアを
[2329s -> 2331s] 今出していて
[2331s -> 2333s] これはすごいみたいな
[2333s -> 2335s] ここ数時間の間にも
[2335s -> 2337s] ツイッターとかで結構
[2337s -> 2339s] 盛り上がったりとかしているんですけど
[2339s -> 2341s] 一方で
[2341s -> 2343s] 川橋先生が
[2343s -> 2345s] 学習データを準備されていたので
[2345s -> 2347s] お話を聞いていたところで
[2347s -> 2349s] ファインチューニングに使われた
[2349s -> 2351s] 学習データに
[2351s -> 2353s] コツというか
[2353s -> 2355s] 一つ大きいポイントがあって
[2355s -> 2357s] 結構どうやって
[2357s -> 2359s] 今後モデルを評価していくのか
[2359s -> 2361s] みたいなところもかなりチャレンジングだな
[2361s -> 2363s] みたいなお話を
[2363s -> 2365s] していました
[2365s -> 2367s] 全然自分の自己紹介から
[2367s -> 2369s] 逸脱してきましたけれども
[2369s -> 2371s] 私の経歴は
[2371s -> 2373s] ともかく
[2373s -> 2375s] 今モデルに関わったりとか
[2375s -> 2377s] いろいろモデルを作っている
[2377s -> 2379s] 方々に
[2379s -> 2381s] ウェイツアドバイスズというツールを提供する
[2381s -> 2383s] そういう立場で
[2383s -> 2385s] 関わらせていただいています
[2385s -> 2387s] よろしくお願いします
[2387s -> 2389s] 株式会社ザーギルドのふかつと申します
[2389s -> 2391s] 僕は皆さんと違って
[2391s -> 2393s] 言語モデルとかAIの専門家というよりは
[2393s -> 2395s] 言語モデルや
[2395s -> 2397s] AI使ってどうサービス作ろうかとか
[2397s -> 2399s] どうやって性能を引き出して
[2399s -> 2401s] どんな変な使い方を見つけていこうかみたいな
[2401s -> 2403s] そういったところの方がメインになってきます
[2403s -> 2405s] お仕事としての
[2405s -> 2407s] 関わりとしては
[2407s -> 2409s] スタビリティAIのジャパンチームの
[2409s -> 2411s] アドバイザリーをやっていたり
[2411s -> 2413s] あとは横須賀市
[2413s -> 2415s] 僕のちょうど地元なんですけれども
[2415s -> 2417s] 日本で一番最初に生成AI
[2417s -> 2419s] 実践で使った行政ということで
[2419s -> 2421s] そこの導入のお手伝いをしていたり
[2421s -> 2423s] とかいろんな会社の
[2423s -> 2425s] サービスとか運用の部分で
[2425s -> 2427s] アドバイスとかお手伝いをしていたりします
[2427s -> 2429s] よろしくお願いします
[2429s -> 2431s] ありがとうございます
[2431s -> 2433s] では柴田さんと
[2433s -> 2435s] 深津さんとディスカッションをさせていただきたいと思いますけど
[2435s -> 2437s] まずはちょっと
[2437s -> 2439s] 手堅いところで
[2439s -> 2441s] ご説明のほうを差し上げて
[2441s -> 2443s] それをベースにというか
[2443s -> 2445s] 踏まえなくてもいいですけれども
[2445s -> 2447s] ディスカッションできればと思います
[2447s -> 2449s] 冒頭にもお話しさせていただいたとおり
[2449s -> 2451s] いろいろな企業さんと
[2451s -> 2453s] お話しする中で
[2453s -> 2455s] 活用用途の見出し方がわからない
[2455s -> 2457s] 結局チャットGPT
[2457s -> 2459s] 対話型AIなんだけどおしゃべりできるだけなんでしょう
[2459s -> 2461s] っていう風に捉えちゃう人が多くて
[2461s -> 2463s] おしゃべりできるってことは
[2463s -> 2465s] 何でもできる
[2465s -> 2467s] っていう風に私とかは思うんですけど
[2467s -> 2469s] なかなかそこまで
[2469s -> 2471s] 実感を持って
[2471s -> 2473s] 把握されている方が
[2473s -> 2475s] そこまでいないのかなという風な
[2475s -> 2477s] 思いもありまして
[2477s -> 2479s] いろいろ
[2479s -> 2481s] 私がいるデルトーマツの中でも
[2481s -> 2483s] 研修会とか勉強会とかやる中で
[2483s -> 2485s] これポイントかなという風に思ったのが
[2485s -> 2487s] こちらのスライドに記載させていただいているので
[2487s -> 2489s] 生成AIを
[2489s -> 2491s] 人として捉えると
[2491s -> 2493s] 人間として捉えると
[2493s -> 2495s] そうすると結構いろいろ良い影響があるんじゃないかなという風に
[2495s -> 2497s] 思っています
[2497s -> 2499s] 特に人に良い仕事を
[2499s -> 2501s] 頼む時の指示文は
[2501s -> 2503s] 生成AIに良い仕事をさせる時の指示文と
[2503s -> 2505s] 同じだったりとかですね
[2505s -> 2507s] あとは例えば外部委託とか
[2507s -> 2509s] チームの新人に
[2509s -> 2511s] 仕事をお願いする時は
[2511s -> 2513s] 例えば外部委託だったら情報漏洩とか
[2513s -> 2515s] 気を付けるじゃないですか
[2515s -> 2517s] 出てきたものに対して正確性チェックとかするじゃないですか
[2517s -> 2519s] そういった人間に対して
[2519s -> 2521s] リスクと感じられる部分に対するリスク対策
[2521s -> 2523s] そのまま生成AIに
[2523s -> 2525s] 使えるとかですね
[2525s -> 2527s] この中で一番
[2527s -> 2529s] 効果を発揮するのはこの2番目のところかなと
[2529s -> 2531s] どこでどのように使うか
[2531s -> 2533s] まさにこのパネルの
[2533s -> 2535s] テーマであるんですけども
[2535s -> 2537s] かなり発散させてアイデアを
[2537s -> 2539s] 思いつきやすいというような側面があるかなという風に思っています
[2539s -> 2541s] 特に
[2541s -> 2543s] このトピックでもあるビジネスというところを考えると
[2543s -> 2545s] ビジネスなんて人との連携なんで
[2545s -> 2547s] 生成AIを人と捉えると
[2547s -> 2549s] 人との連携に関する
[2549s -> 2551s] あらゆる側面で
[2551s -> 2553s] あらゆる観点で持って用途を
[2553s -> 2555s] 見つけることができるんじゃないかなという風に
[2555s -> 2557s] 考えます
[2557s -> 2559s] まさに企業の中で
[2559s -> 2561s] 効率的にビジネスを
[2561s -> 2563s] 回していくための
[2563s -> 2565s] 塊が組織であって
[2565s -> 2567s] 組織的な観点で用途を
[2567s -> 2569s] 見出すというのは全然あり得ますし
[2569s -> 2571s] あとは業務ですよね
[2571s -> 2573s] 共通的な業務から個人業務さまざまありますけれども
[2573s -> 2575s] そういった業務観点で洗い出すとか
[2575s -> 2577s] あとは先ほどちょっと申し上げた
[2577s -> 2579s] 外部委託とかチームメンバーとの
[2579s -> 2581s] 連携であってとか
[2581s -> 2583s] あとは個人の強み弱みこういったところを
[2583s -> 2585s] 踏まえた連携
[2585s -> 2587s] こういったさまざまな人との連携に関する
[2587s -> 2589s] 観点から用途を
[2589s -> 2591s] 見つけ出すことができるんじゃないかなという風に
[2591s -> 2593s] 思います
[2593s -> 2595s] こちらは組織観点で
[2595s -> 2597s] 洗い出した例ですけども
[2597s -> 2599s] 一部でしかないんですけども
[2599s -> 2601s] 本当に短期的には各企業さんですね
[2601s -> 2603s] まず組織でどのように使えるかといった
[2603s -> 2605s] ところをそれぞれ考えて
[2605s -> 2607s] 使っていくんじゃないかなと
[2607s -> 2609s] 活用用途を見出しているんじゃないかなという風に
[2609s -> 2611s] 思います ちょっと字が小さくて申し訳ないですけれども
[2611s -> 2613s] 一方で
[2613s -> 2615s] 個人の業務という風に見ると
[2615s -> 2617s] すごく多様なので
[2617s -> 2619s] 一概にこういうところを使えるという風には
[2619s -> 2621s] 言いにくい側面があると思うんですけど
[2621s -> 2623s] ただ一方で皆さんがやっている
[2623s -> 2625s] 業務をすごくすごく単純化すると
[2625s -> 2627s] こういったフローパターン
[2627s -> 2629s] 業務フローパターンになるのかなと
[2629s -> 2631s] 基本的にはお客様から来た
[2631s -> 2633s] 問い合わせとか何かしらの依頼に対して
[2633s -> 2635s] 担当者が作業して
[2635s -> 2637s] 管理者がレビューして作業して
[2637s -> 2639s] くるくる回ってですね
[2639s -> 2641s] その後成果物をお客様に返すと
[2641s -> 2643s] 基本的にはこういった
[2643s -> 2645s] フローで持って
[2645s -> 2647s] ほぼ全ての
[2647s -> 2649s] 個人業務が回っているという風に考えると
[2649s -> 2651s] こういったところにですね
[2651s -> 2653s] パターン化されたものに対して個人の
[2653s -> 2655s] 依頼をしてて用途を見つけ出す
[2655s -> 2657s] あとちょっと先ほど
[2657s -> 2659s] 申しました外部委託に例えば
[2659s -> 2661s] する際にどういった業務を
[2661s -> 2663s] 外部委託するかといった観点で
[2663s -> 2665s] 基本的には
[2665s -> 2667s] 委託元のレビューの
[2667s -> 2669s] しやすさであったりとか
[2669s -> 2671s] 委託元の作業時間みたいなところ
[2671s -> 2673s] こういったところが
[2673s -> 2675s] 多いところについて
[2675s -> 2677s] 業務委託の候補とすることがあると思うんです
[2677s -> 2679s] まさにこういった見つけ方
[2679s -> 2681s] 委託の業務の見つけ方で
[2681s -> 2683s] 使って用途を特定する
[2683s -> 2685s] 用途を見つけ出すというのはそういった方法もあるのかな
[2685s -> 2687s] という風に思います
[2687s -> 2689s] こちらですねまさに
[2689s -> 2691s] 深津さんの出演されていた
[2691s -> 2693s] 動画からですね私がすごい
[2693s -> 2695s] 共感しました
[2695s -> 2697s] 用途のイベントで作ったやつですかね
[2697s -> 2699s] これはもう本当にしっくりきまして
[2699s -> 2701s] 使わせていただいているんですけども
[2701s -> 2703s] まさに生成やチャットGPT等は
[2703s -> 2705s] 本当に大量の情報を学習して
[2705s -> 2707s] それを再表現するような
[2707s -> 2709s] 技術になりますので
[2709s -> 2711s] この回答される可能性のある
[2711s -> 2713s] 情報というのは無限大であると
[2713s -> 2715s] そこから
[2715s -> 2717s] ユーザー側が
[2717s -> 2719s] 求める出力にいかに近づいていくか
[2719s -> 2721s] これがプロンプトエンジニアリング
[2721s -> 2723s] というお話をされていてですね
[2723s -> 2725s] その際にいろいろな情報を与えることによって
[2725s -> 2727s] 求める出力に近づいていくと
[2727s -> 2729s] その与え方が
[2729s -> 2731s] いまいちだったらまたハズレな情報が出てきたり
[2731s -> 2733s] とか
[2733s -> 2735s] 情報を詳細にしすぎると
[2735s -> 2737s] すごい抜け漏れがある
[2737s -> 2739s] 情報になってしまって
[2739s -> 2741s] すごくいろいろな問題があって
[2741s -> 2743s] 基本的にそういったところに対して
[2743s -> 2745s] ちゃんと求める出力に狭めていくという
[2745s -> 2747s] 考え方をお話しされていて
[2747s -> 2749s] これはすごい共感しました
[2749s -> 2751s] どっちかというとアートの考え方というか
[2751s -> 2753s] もともとはミケランジェロが
[2753s -> 2755s] 大理石から像を作るときの
[2755s -> 2757s] コンセプトの言い方で
[2757s -> 2759s] 何も削ってない大理石
[2759s -> 2761s] 四角の状態が一番可能性がある状況で
[2761s -> 2763s] 一発のみ入れて
[2763s -> 2765s] パーツを外していって
[2765s -> 2767s] 物が出来上がるのに近づけば近づくほど
[2767s -> 2769s] 俺は大理石の可能性を殺していってるんだ
[2769s -> 2771s] 的なやつですよね
[2771s -> 2773s] なんか
[2773s -> 2775s] 大理石の中の天使を解放するとか
[2775s -> 2777s] そんなような言い方してたと思うんですけど
[2777s -> 2779s] そういうことだったんですね
[2779s -> 2781s] なるほど
[2781s -> 2783s] 今すごい例えが出てきたなと思ったんですけど
[2783s -> 2785s] 結構チャットGPTと会話していて
[2785s -> 2787s] 削りすぎてしまうことがあって
[2787s -> 2789s] そこから元に戻すことが
[2789s -> 2791s] あまりできないことがあるんですけど
[2791s -> 2793s] そういったときにどうされてますか
[2793s -> 2795s] もうリセットしますけれども
[2795s -> 2797s] やっぱり
[2797s -> 2799s] やっぱりそういうことですね
[2799s -> 2801s] そこは大理石として
[2801s -> 2803s] 跳ね落ちちゃったみたいなときは
[2803s -> 2805s] 新しい大理石で
[2805s -> 2807s] 大理石を用意するということですね
[2807s -> 2809s] なるほど
[2809s -> 2811s] ありがとうございます
[2811s -> 2813s] ちょっと長くなりましたけど
[2813s -> 2815s] こちらのパネルも
[2815s -> 2817s] 四つのテーマを用意させて
[2817s -> 2819s] いただいております
[2819s -> 2821s] こちらも
[2821s -> 2823s] 独断とあとは
[2823s -> 2825s] 視聴者様からの多数決で
[2825s -> 2827s] 決めていきたいと思いますけれども
[2827s -> 2829s] まずはですね
[2829s -> 2831s] Bのところを選ばせて
[2831s -> 2833s] いただきたいなと思います
[2833s -> 2835s] 不活式
[2835s -> 2837s] しばた式
[2837s -> 2839s] しばた式というフレーズを
[2839s -> 2841s] 世に広めたいなと思ってますので
[2841s -> 2843s] よろしくお願いします
[2843s -> 2845s] 活用事例ですね
[2845s -> 2847s] 普通にベストプラクティスとして
[2847s -> 2849s] 元々
[2849s -> 2851s] 書いてたのは
[2851s -> 2853s] ロールやタスク決めて
[2853s -> 2855s] スペシフィケーション
[2855s -> 2857s] 使用書みたいの書いて
[2857s -> 2859s] 良いこととか悪いこととか書いて
[2859s -> 2861s] 要は結局言語モデルって究極的には
[2861s -> 2863s] 手前の文章に影響を受けて
[2863s -> 2865s] 後ろの文章を書くので
[2865s -> 2867s] 手前に良いことが書いて
[2867s -> 2869s] 第一原則は手前に良いことが書いてあれば
[2869s -> 2871s] 後ろのこともだいたい良くなるので
[2871s -> 2873s] チェーン・ノブ・ソートだろうが
[2873s -> 2875s] 最近のベストプラクティス
[2875s -> 2877s] 頭に貼るのだろうとかも
[2877s -> 2879s] 統一で手前に良い感じのこと書いてあれば
[2879s -> 2881s] 解決するっていう
[2881s -> 2883s] 標準化ができるので
[2883s -> 2885s] それをルールにしてたっていうのが
[2885s -> 2887s] あるところですね
[2887s -> 2889s] それが基礎の基礎というところ
[2889s -> 2891s] シューショット・エグザンプルとかも
[2891s -> 2893s] 結局そういう話で
[2893s -> 2895s] 手前に良いものがあればなんとかなる
[2895s -> 2897s] それが一般的な基礎の
[2897s -> 2899s] 非専門家に特に言うときとか
[2899s -> 2901s] まずは押さえておくべき事項
[2901s -> 2903s] ちょっとここでお伺いしたかったのが
[2903s -> 2905s] まさに
[2905s -> 2907s] 日本を代表する
[2907s -> 2909s] プロンプトエンジニアという風にも
[2909s -> 2911s] 言われてる
[2911s -> 2913s] 一番プロンプトエンジニアリングに
[2913s -> 2915s] 未来ないって言ってる人間なのに
[2915s -> 2917s] そういう場合の人が多いですよね
[2919s -> 2921s] その深津さんが
[2921s -> 2923s] 今まさに熱いと思ってるような
[2923s -> 2925s] そういった活用事例とか
[2925s -> 2927s] 最近の活用事例というか
[2927s -> 2929s] プロンプトの使い方だと
[2929s -> 2931s] さっき人間見立てるって言ってたじゃないですか
[2931s -> 2933s] 最近僕の中で熱いのが
[2933s -> 2935s] AIにできないことを
[2935s -> 2937s] 命令するっていうのが多くて
[2937s -> 2939s] 今僕の中で一番熱い
[2939s -> 2941s] プロンプトの一個が
[2941s -> 2943s] 以上
[2943s -> 2945s] 今命令して出力させるじゃないですか
[2945s -> 2947s] 出力したときに
[2947s -> 2949s] ではこの出力を
[2949s -> 2951s] 60点とします
[2951s -> 2953s] これを60点としたときに
[2953s -> 2955s] 100点とは
[2955s -> 2957s] どのようなものですか
[2957s -> 2959s] 100点にするために足りないものを
[2959s -> 2961s] 列挙した後に100点の答えを
[2961s -> 2963s] 生成してくださいっていうと
[2963s -> 2965s] 確実に良くなるんですよ
[2965s -> 2967s] 確実に良くなったのに
[2967s -> 2969s] これをまた
[2969s -> 2971s] 60点で定義すると
[2971s -> 2973s] っていうと
[2973s -> 2975s] またずっと良くなるんで
[2975s -> 2977s] 同じ
[2977s -> 2979s] プロンプトコピペするだけで
[2979s -> 2981s] どんどん良くなるっていうのが
[2981s -> 2983s] 最近熱くて
[2983s -> 2985s] しかも
[2985s -> 2987s] 同じプロンプト回すだけなんで
[2987s -> 2989s] Python組める人はホワイルドでループ組めば
[2989s -> 2991s] ウィーンって勝手に性能が良くなるんで
[2993s -> 2995s] 60点として100点を目指すには
[2995s -> 2997s] みたいに
[2997s -> 2999s] 技術的に
[2999s -> 3001s] プロンプトの中でベクトル化することで
[3001s -> 3003s] 性能とか方向性をものすごく
[3003s -> 3005s] コントロールするっていうのが
[3005s -> 3007s] 今熱いんですよね
[3007s -> 3009s] ただ人間にはできない
[3009s -> 3011s] 人間でやったら多分その人会社辞めちゃうと思うんで
[3011s -> 3013s] すごいですね
[3013s -> 3015s] すごい良いお話を伺えてきました
[3015s -> 3017s] 早速今日から
[3017s -> 3019s] まさに私もコンサルやってるんですけど
[3019s -> 3021s] お客様に
[3021s -> 3023s] 60点って言われることとかあるんですけど
[3023s -> 3025s] それを100点にするための要件を
[3025s -> 3027s] 今人間が考えてると思うんですけど
[3027s -> 3029s] そこすらも
[3029s -> 3031s] チャットDBで考えさせる
[3031s -> 3033s] どんな良いもの出てきても60点呼ばないと
[3033s -> 3035s] とりあえずさらに良くするための
[3035s -> 3037s] プランがずっと無限に出続ける
[3037s -> 3039s] どこかでサチったりしないですか
[3039s -> 3041s] サチってきますというか
[3041s -> 3043s] それも
[3043s -> 3045s] プロンプト次第だな
[3045s -> 3047s] でいくともう
[3047s -> 3049s] 場合によっては
[3049s -> 3051s] これ以上どこを良くしたら分かんない
[3051s -> 3053s] 具体的にしてくださいとか泣き言言うときもあったり
[3053s -> 3055s] あるいはこれつけましょう
[3055s -> 3057s] これ削りましょう
[3057s -> 3059s] これつけましょう削りましょう
[3059s -> 3061s] いったり来たりだったり
[3061s -> 3063s] 完全にやるよりは
[3063s -> 3065s] ブレイク条件作っておいた方がいいんですけど
[3065s -> 3067s] 5、6回ループぐらいまでは
[3067s -> 3069s] GPT-4だったら保証できるかな
[3069s -> 3071s] ありがとうございます
[3071s -> 3073s] では柴田式をお伺いできればと
[3073s -> 3075s] 僕はあんまり
[3075s -> 3077s] プロンプトエンジニアみたいな
[3077s -> 3079s] 風にいっぱい使っては
[3079s -> 3081s] ないですけどね
[3081s -> 3083s] 一番よく使うのは翻訳
[3083s -> 3085s] で使いますね
[3085s -> 3087s] 今韓国語とかすごい
[3087s -> 3089s] 自分の知らない言語を書かないといけないから
[3089s -> 3091s] 合ってんのか分からないけど
[3091s -> 3093s] とりあえず翻訳して
[3093s -> 3095s] メールにペーストして送るっていうのは
[3095s -> 3097s] 一番よく
[3097s -> 3099s] 今一番使いますねそれ
[3099s -> 3101s] あとは僕よく似たので
[3101s -> 3103s] 頼るのだと
[3103s -> 3105s] 論文読みたいんですよ最新のMLの
[3105s -> 3107s] けど僕数学とか分かんなかったりとか
[3107s -> 3109s] 専門すぎるの分かんない
[3109s -> 3111s] 最近
[3111s -> 3113s] GPTに論文をアップロードしながら
[3113s -> 3115s] Udemyでチュートリアル
[3115s -> 3117s] 売りたいからこれをステップバイステップの
[3117s -> 3119s] チュートリアルにしてくれやってあげると
[3119s -> 3121s] 論文が全部
[3121s -> 3123s] 初心者に分かるステップバイステップチュートリアルになるんで
[3123s -> 3125s] めっちゃ読みやすくなるっていう
[3125s -> 3127s] 無限教育コントジェクト
[3127s -> 3129s] これだと
[3129s -> 3131s] 実際に売るわけじゃないんだけど
[3131s -> 3133s] 自分でも簡単に読んで
[3133s -> 3135s] 場合によっては
[3135s -> 3137s] Googleのコラボ用のサンプルコードまで
[3137s -> 3139s] ついて出てくるんで
[3139s -> 3141s] 論文めっちゃ早く
[3141s -> 3143s] 専門家でも消化できるっていうのは
[3143s -> 3145s] ちょっと個人的には熱い使い方
[3145s -> 3147s] ありがとうございます
[3147s -> 3149s] これは結構教育的な観点でも
[3149s -> 3151s] すごく
[3151s -> 3153s] 使える可能性があるということですよね
[3153s -> 3155s] 専門分野じゃなかったとしても
[3155s -> 3157s] それを分かりやすく説明してくれる
[3157s -> 3159s] まさに教師のような役割を
[3159s -> 3161s] 生成案にならせるというところですかね
[3161s -> 3163s] それで言うと今回も
[3163s -> 3165s] テストで
[3165s -> 3167s] 生成案を使って問題を
[3167s -> 3169s] 出題しようという話がありましたよね
[3169s -> 3171s] そうですね
[3171s -> 3173s] それの話はしなくていいんですか
[3173s -> 3175s] まさにしようと思ってました
[3175s -> 3177s] GPT資金館がやってくる
[3177s -> 3179s] 今回は
[3179s -> 3181s] 選択肢問題だけじゃなくて
[3181s -> 3183s] 生成案を使わないとできない
[3183s -> 3185s] 出題をしましょうみたいな話から始まって
[3185s -> 3187s] うよ曲折
[3187s -> 3189s] いろいろありましたじゃないですか
[3189s -> 3191s] あれプロンプトエンジニアリングで
[3191s -> 3193s] プロンプトハッキングして高得点取っても
[3193s -> 3195s] ありなんですかね
[3195s -> 3197s] それはむしろ歓迎という感じ
[3197s -> 3199s] じゃないかなと思いますけどね
[3199s -> 3201s] そうですね
[3201s -> 3203s] 今回はJDLA
[3203s -> 3205s] ジェネレティブAIテストの中で
[3205s -> 3207s] 記述式問題を
[3207s -> 3209s] 入れております
[3209s -> 3211s] 記述式問題って結構特徴があって
[3211s -> 3213s] 選択式問題と一番違うのが
[3213s -> 3215s] 資金館によって
[3215s -> 3217s] 採点の仕方
[3217s -> 3219s] 人が違うので
[3219s -> 3221s] 品質が採点館によって異なるというような
[3221s -> 3223s] 特徴があると
[3223s -> 3225s] ここをまさに生成AIを使って
[3225s -> 3227s] 解決しようという風にしてます
[3227s -> 3229s] それもそうですけど
[3229s -> 3231s] やっぱり記憶して
[3231s -> 3233s] 知識を問う問題だけじゃなくて
[3233s -> 3235s] 理解度とか
[3235s -> 3237s] 応用力とか
[3237s -> 3239s] そういう紙のテストでは
[3239s -> 3241s] 試しにくいこと
[3241s -> 3243s] っていうのを
[3243s -> 3245s] テストできるようにしようという目的も
[3245s -> 3247s] 結構大きかったかなと思いますね
[3247s -> 3249s] しかも人間でやると
[3249s -> 3251s] 一人目の生徒はだいたい
[3251s -> 3253s] 7点とか8点でやりそうとか
[3253s -> 3255s] ご飯食べた後とか
[3255s -> 3257s] お腹空いた後とかに
[3257s -> 3259s] 裁判官の裁判の判決が
[3259s -> 3261s] 厳しくなるとか緩くなるとか
[3261s -> 3263s] そういう揺らぎがあるんだけど
[3263s -> 3265s] GPTでやったらそこの揺らぎは
[3265s -> 3267s] だいぶ変わる
[3267s -> 3269s] フェアになるんじゃないかなと
[3269s -> 3271s] 昨日お笑い番組で
[3271s -> 3273s] お笑いコンテストの番組やってましたけど
[3273s -> 3275s] そういったところでも使えそうですね
[3275s -> 3277s] でもやっぱり
[3277s -> 3279s] やってみて
[3279s -> 3281s] 私自身はすごい学びがあったので
[3283s -> 3285s] 確かに生成愛すごいし
[3285s -> 3287s] いろいろできるといえばできるようで
[3287s -> 3289s] 本当になんか
[3289s -> 3291s] シビアなことに使おうと思った時に
[3291s -> 3293s] 出てくる問題っていうのは
[3293s -> 3295s] やっぱりやろうとして
[3295s -> 3297s] 初めてわかるなっていうことは
[3297s -> 3299s] やったんですよね
[3299s -> 3301s] それぐらいできるでしょうみたいな
[3301s -> 3303s] 深津さんもいるしみたいな感じで
[3303s -> 3305s] 言ってたけど
[3305s -> 3307s] でもやっぱりテストで
[3307s -> 3309s] 命がかかっているとは言えないけど
[3309s -> 3311s] それなりにお金も払って
[3311s -> 3313s] 真剣に受けに来る人たちに対して
[3313s -> 3315s] 生成愛が採点するっていうことが
[3315s -> 3317s] どこまでが許容できて
[3317s -> 3319s] どこからはできないのか
[3319s -> 3321s] あんまりコンサバになりすぎると
[3321s -> 3323s] こうやって結局選択問題出してやると
[3323s -> 3325s] 同じじゃんみたいな話になっちゃって
[3325s -> 3327s] それは
[3327s -> 3329s] 私自身すごい学びでもあったし
[3329s -> 3331s] それを通じてすごく
[3331s -> 3333s] チームとしてもいろんなディスカッションができて
[3333s -> 3335s] よかったこともありますけど
[3335s -> 3337s] 活用っていうことを
[3337s -> 3339s] 考えた時に
[3339s -> 3341s] 絶対にこれから来ると思うのは
[3341s -> 3343s] 案外生成愛は使えないよねっていう話が
[3343s -> 3345s] 絶対に来ると思うんですね
[3345s -> 3347s] それはとりあえず流暢にしゃべるから
[3347s -> 3349s] すごいし
[3349s -> 3351s] 翻訳とか予約とか
[3351s -> 3353s] それぐらいのことをやろうとしているうちは
[3353s -> 3355s] 本当に目の前にある問題
[3355s -> 3357s] この前
[3357s -> 3359s] じゃあパレスナーとイスラエルが
[3359s -> 3361s] どうやったら和解できますかって聞いて
[3361s -> 3363s] そんな答えなんか出てくるわけがないし
[3363s -> 3365s] 現実問題って
[3365s -> 3367s] そういう難しさや
[3367s -> 3369s] リスクとかっていうのは
[3369s -> 3371s] はらんでいるから
[3371s -> 3373s] 利活用の話をする時には
[3373s -> 3375s] これからそういう話が出てくる
[3375s -> 3377s] さっき佐々木さんもそういう
[3377s -> 3379s] 実際にやろうと思った時に
[3379s -> 3381s] 必要とされるブレイクスルーとか
[3381s -> 3383s] 何でもできると思わないで
[3383s -> 3385s] 実際にやってみて
[3385s -> 3387s] どこができないのかっていうことを
[3387s -> 3389s] 経験していくっていうのは
[3389s -> 3391s] すごい必要なことだなって思いました
[3391s -> 3393s] ありがとうございます
[3393s -> 3395s] 私もすごい勉強になりまして
[3395s -> 3397s] 今回の件ですね
[3397s -> 3399s] まさにアイデアを柴田さんが
[3399s -> 3401s] 最初に言い出した時に
[3401s -> 3403s] 2回目も選択していくんだろうという
[3403s -> 3405s] 当たり前な感覚でいたんですけども
[3405s -> 3407s] 確かに生成愛を使うと
[3407s -> 3409s] いろんなことができるなと
[3409s -> 3411s] 本当に質を上げることができるな
[3411s -> 3413s] って思ったテストですね
[3413s -> 3415s] 活用全般に言えることだと思うんですけども
[3415s -> 3417s] なるべくアイデアを制限しないで
[3417s -> 3419s] 当たり前をどんどん疑っていく
[3419s -> 3421s] っていうようなところが
[3421s -> 3423s] 非常に一般のビジネスマンも
[3423s -> 3425s] すごく求められてくるような
[3425s -> 3427s] そういった時代になってきている
[3427s -> 3429s] 本当に改めて思いました
[3429s -> 3431s] 深津さんとその話していた時に
[3431s -> 3433s] 深津さんはもう他の人がやったことは
[3433s -> 3435s] やりたくないんですみたいな
[3435s -> 3437s] フューショット的なことはやりたくないですみたいな
[3437s -> 3439s] ミスターゼロショットですみたいな
[3439s -> 3441s] 話をされてて
[3441s -> 3443s] 本当そうだな
[3443s -> 3445s] ちょっと飲んでたかもしれないけど
[3445s -> 3447s] 過去の経験とかでも
[3447s -> 3449s] そういう事務所にいたんです
[3449s -> 3451s] プロンプト的な話じゃなくて
[3451s -> 3453s] 仕事の話
[3453s -> 3455s] 僕の前職が
[3455s -> 3457s] 同じ仕事を2度やんないって
[3457s -> 3459s] 話をされてたじゃないですか
[3459s -> 3461s] でもやっぱりこれから人間に
[3461s -> 3463s] 求められることって
[3463s -> 3465s] そういうことだなってすごく思ったんです
[3465s -> 3467s] なぜかというとファインチューニングとかしていくと
[3467s -> 3469s] さっきの河原先生とも話したんですけど
[3469s -> 3471s] やっぱり例を見せると
[3471s -> 3473s] どんどんできるようになっていくから
[3473s -> 3475s] そうするとやっぱりAIに奪われちゃうところが
[3475s -> 3477s] 増えていくので
[3477s -> 3479s] やっぱり人間に求められることっていうのは
[3479s -> 3481s] これまでになかったような
[3481s -> 3483s] 問題を解いていくっていうこと
[3483s -> 3485s] それができないとどんどん差別化が難しくなるなって
[3485s -> 3487s] 思いました
[3489s -> 3491s] そうですねゼロショット系はね
[3491s -> 3493s] 色々楽しいですよね
[3493s -> 3495s] AIゼロショットというか
[3495s -> 3497s] スタンダードないものが多すぎるので
[3497s -> 3499s] 僕そういうとこ大好きだから
[3499s -> 3501s] 今めっちゃ楽しいです
[3501s -> 3503s] 結構その人間の価値はこれからどうなるのか
[3503s -> 3505s] みたいな議論は結構ありますけど
[3505s -> 3507s] すごい今日ヒントいただけたような気がしました
[3507s -> 3509s] ゼロショット
[3509s -> 3511s] そうですね
[3511s -> 3513s] あの
[3513s -> 3515s] あれですね
[3515s -> 3517s] 今実際生成AIで問題を
[3517s -> 3519s] 批准式のやつやってみて
[3519s -> 3521s] こんなんあったじゃないですか
[3521s -> 3523s] 聞こえたじゃないですか
[3523s -> 3525s] これって結構大事なポイントだと思っていて
[3525s -> 3527s] 僕も色んな日本の会社さんで
[3527s -> 3529s] 生成AI使われてますで
[3529s -> 3531s] 多いのはラグみたいなものを使って
[3531s -> 3533s] 社内の文章を探しますみたいなパターンですけど
[3533s -> 3535s] 精度出なくてダメなんですみたいな感じで
[3535s -> 3537s] おっしゃる方も多いんですよね
[3537s -> 3539s] そこで諦めないことが大事だなと思っていて
[3539s -> 3541s] やっぱり初め
[3541s -> 3543s] AIなんてうまくいかなくて当たり前みたいな
[3543s -> 3545s] 気持ちで初め挑んで
[3545s -> 3547s] そこからいかにしっかり作り込んでいくかっていうところ
[3547s -> 3549s] これはぜひ諦めないでやっていただきたいな
[3549s -> 3551s] と多分今回の試験問題っていうのは
[3551s -> 3553s] そういうところに対する何らかの示唆を
[3553s -> 3555s] 与えてくれるんじゃないかなという風に思っている
[3555s -> 3557s] ということを思いました
[3557s -> 3559s] ありがとうございます
[3559s -> 3561s] そうですね
[3561s -> 3563s] このようなゼロショット的な試みを
[3563s -> 3565s] これからも継続してできるように
[3565s -> 3567s] 頑張っていければと思います
[3567s -> 3569s] これからもよろしくお願いします
[3569s -> 3571s] ありがとうございます
[3571s -> 3573s] やっぱり予想通りすごく盛り上がってですね
[3573s -> 3575s] あと2分です
[3575s -> 3577s] 1個ぐらいしか答えてない
[3577s -> 3579s] 2つぐらいあったけど
[3579s -> 3581s] 巻いていかないと
[3581s -> 3583s] そうですね
[3583s -> 3585s] 今アンケート取りまして
[3585s -> 3587s] 応用編脱チャット
[3587s -> 3589s] このテーマについてちょっと伺いたいという
[3589s -> 3591s] 脱チャット
[3591s -> 3593s] 僕はあれですね
[3593s -> 3595s] チャットは今年だけみたいな感じのイメージでいて
[3595s -> 3597s] 基本
[3597s -> 3599s] 僕の専門のUIとかの立場からすると
[3599s -> 3601s] 人はそんな140時も
[3601s -> 3603s] チャット打ってくんねえだろっていうのがあるんで
[3603s -> 3605s] 目新しくなくなったらみんな入力しなくなるんですよ
[3605s -> 3607s] だからどっちかっていうと
[3607s -> 3609s] Googleカレンダーと
[3609s -> 3611s] インテグレートして
[3611s -> 3613s] 今日これからミーティングってときに
[3613s -> 3615s] あのミーティング前にこの文章
[3615s -> 3617s] 読んだ気になるとか
[3617s -> 3619s] なんか体重計乗ったやつが
[3619s -> 3621s] IFTT使って
[3621s -> 3623s] 体重計のデータスプレッドシート飛ばして
[3623s -> 3625s] スプレッドシートから
[3625s -> 3627s] ザピア使ってGPT飛ばすと
[3627s -> 3629s] なんか体重毎日測ってないねって
[3629s -> 3631s] 褒めてくれたりとかみたいに
[3631s -> 3633s] トリガーをもう
[3633s -> 3635s] ちょっとじゃないものにしていって
[3635s -> 3637s] そっちが9割とかになっていくんじゃないかな
[3637s -> 3639s] って気はするんですよね
[3639s -> 3641s] でもやっぱり
[3641s -> 3643s] サービスとかに
[3643s -> 3645s] 入れようと思うと
[3645s -> 3647s] 開発に時間がかかるじゃないですか
[3647s -> 3649s] ついこの前
[3649s -> 3651s] メルカリさんとかも
[3651s -> 3653s] 商品出品するタイトルを
[3653s -> 3655s] 生成してくれるみたいなの
[3655s -> 3657s] やってましたけど
[3657s -> 3659s] ああいう既存のサービスに
[3659s -> 3661s] 入ってくるみたいなのがこれからどんどん出てくるんじゃないのかな
[3661s -> 3663s] と思ってて
[3663s -> 3665s] 同じ意見なんですけど
[3665s -> 3667s] 個人がチャットでインタラクションするっていうよりも
[3667s -> 3669s] それがパーツとなって
[3669s -> 3671s] もっと大きなサービスを
[3671s -> 3673s] 形成していくみたいな話っていうのは
[3673s -> 3675s] 結構やってる人たちも
[3675s -> 3677s] 多いと思うし
[3677s -> 3679s] 多分今年の残りの
[3679s -> 3681s] 今年の残りの時間にも
[3681s -> 3683s] 結構いろいろ出てくるんじゃないかなっていう気がしてます
[3683s -> 3685s] すごく便利な
[3685s -> 3687s] 世の中になりそうですね
[3687s -> 3689s] だといいですけどね
[3689s -> 3691s] ドラえもんの中で
[3691s -> 3693s] 半分ぐらい
[3693s -> 3695s] どこでもドアとかはさすがに無理だとは思うんですけど
[3695s -> 3697s] ドラえもんの便利ツールの何割かは
[3697s -> 3699s] 本当このね
[3699s -> 3701s] 生成AI
[3701s -> 3703s] 特にマルチモーダルのもので
[3703s -> 3705s] 達成できちゃう気はしますよね
[3705s -> 3707s] そうですね
[3707s -> 3709s] ドラえもんの知能はほぼできてると
[3709s -> 3711s] 言えるんですかね
[3711s -> 3713s] 多分処理速度遅くて良ければ
[3713s -> 3715s] 多分ドラえもん自体も
[3715s -> 3717s] 動くでしょう
[3717s -> 3719s] 生成AIバックエンドで
[3719s -> 3721s] ちょっと動く話をしだすと
[3721s -> 3723s] いろいろさっきのビデオのこととか
[3723s -> 3725s] 思い出しちゃって
[3725s -> 3727s] 見せきれないのかもしれないですけど
[3727s -> 3729s] 最近そういうの
[3729s -> 3731s] 深田さんは
[3731s -> 3733s] GPTにボディーを与える実験を
[3733s -> 3735s] いろいろ最近はしてますね
[3735s -> 3737s] でもそういう話ですよね
[3737s -> 3739s] 今Amazon Echoみたいな
[3739s -> 3741s] 裏側が賢くなっちゃった
[3741s -> 3743s] チャットボットみたいなもちろんそうだし
[3743s -> 3745s] これからそういう風に
[3745s -> 3747s] スペースで動向っていうよりも
[3747s -> 3749s] APIを使ってどうやって実装していくのか
[3749s -> 3751s] その結果として現れるサービスみたいなのが
[3751s -> 3753s] すごいのがいっぱい出てくるんだろうな
[3753s -> 3755s] 多分究極的には
[3755s -> 3757s] 画像生成
[3757s -> 3759s] AI
[3759s -> 3761s] テキストAIで
[3761s -> 3763s] 今画像を読めるようになったじゃないですか
[3763s -> 3765s] これがあれば
[3765s -> 3767s] あとはPCの
[3767s -> 3769s] スクリーンキャプチャを
[3769s -> 3771s] 1秒ごとに生成AIに渡して
[3771s -> 3773s] あとはロボットアームとマウスとか
[3773s -> 3775s] それを繋いどけば
[3775s -> 3777s] 割と何でもできる気がするんですよね
[3777s -> 3779s] この前僕もイベントやったときに
[3779s -> 3781s] うちのお客さんのチューリングさんっていう会社さん
[3781s -> 3783s] 自動運転を
[3783s -> 3785s] 開発してて
[3785s -> 3787s] 自動運転でどうやって
[3787s -> 3789s] 生成AIが関係してくるのかみたいな話を
[3789s -> 3791s] ちょっとしてて
[3791s -> 3793s] 基本的に自動運転はここに車走ってます
[3793s -> 3795s] 子供が歩いてますとか
[3795s -> 3797s] 物体認識みたいなレベル感だったんですけど
[3797s -> 3799s] やっぱり
[3799s -> 3801s] 例えば家の形した車が
[3801s -> 3803s] 道の真ん中走ってるとかになると
[3803s -> 3805s] 意味が分からないみたいな
[3805s -> 3807s] 家があるみたいになると
[3807s -> 3809s] 当然そっちには行かないみたいな話にしかならないけど
[3809s -> 3811s] でもこれは車の形しててみたいな
[3811s -> 3813s] ハイコンテクストな状況を
[3813s -> 3815s] 理解させるとか
[3815s -> 3817s] あと分かりやすい話だと
[3817s -> 3819s] すごい複雑な標識とかが出てたときに
[3819s -> 3821s] それを画像をLLMに入れて
[3821s -> 3823s] 今ここ何て書いてあるのかみたいな
[3823s -> 3825s] 解析して
[3825s -> 3827s] いろいろ
[3827s -> 3829s] どういう意味だろうあれ
[3831s -> 3833s] もう時間だってことか
[3833s -> 3835s] そうですね
[3835s -> 3837s] それも同じで
[3837s -> 3839s] そういうふうに
[3839s -> 3841s] LLMの能力っていうのが
[3841s -> 3843s] そういうふうに
[3843s -> 3845s] 見てるもの全てに
[3845s -> 3847s] 適応されて
[3847s -> 3849s] 応用されていくっていう話をちょっと聞いてて
[3849s -> 3851s] 思い出しましたし
[3851s -> 3853s] そういう意外なところにもどんどん入っていくんだろうな
[3853s -> 3855s] 自動運転みたいのだと
[3855s -> 3857s] データセットのないシチュエーションを
[3857s -> 3859s] カバーするためにやっぱり
[3859s -> 3861s] LLMとか必要だと思うんで
[3861s -> 3863s] 普通のとこはずっと
[3863s -> 3865s] 画像から本能的に
[3865s -> 3867s] ハンドルにつなげるときはいいや
[3867s -> 3869s] 毎日リングの人が
[3869s -> 3871s] ツイッターで見たんだけど
[3871s -> 3873s] 道路を馬が走ってるデータセットとか
[3873s -> 3875s] ないみたいな話があって
[3875s -> 3877s] そういうのは例外的に
[3877s -> 3879s] 馬が走ってるっていうのは
[3879s -> 3881s] ビジョンモデルと
[3881s -> 3883s] 組み合わせてやっていかないといけないのかな
[3883s -> 3885s] そうですよね
[3885s -> 3887s] だからちょっと考えないとわからないような
[3887s -> 3889s] シチュエーションみたいなのが
[3889s -> 3891s] 出てきたときに役に立つ
[3891s -> 3893s] 人間の脳みそがシステム1システム2
[3893s -> 3895s] 直感系の処理の脳みそと
[3895s -> 3897s] ロンリー系の処理の脳みそ
[3897s -> 3899s] みたいな感じの概念モデルで
[3899s -> 3901s] 動くとかあるんですけど
[3901s -> 3903s] それに近い感じで
[3903s -> 3905s] 言語モデル使ってシステム2作るんだけど
[3905s -> 3907s] それだけだとコスト高なんで
[3907s -> 3909s] 素早い処理のシステム1と
[3909s -> 3911s] 併用するとかっていうのは
[3911s -> 3913s] 出てくるんじゃないかなと
[3913s -> 3915s] すごいたくさんいろんな可能性を
[3915s -> 3917s] お話しいただきましたありがとうございます
[3917s -> 3919s] あと3つくらい
[3919s -> 3921s] 今もう時間過ぎたって出ましたね
[3921s -> 3923s] ただ本日のテーマである
[3923s -> 3925s] ビジネスへのアドオンっていう風に
[3925s -> 3927s] 考えるとビジネス面でも
[3927s -> 3929s] すごく影響を与えそうな新たなサービスとか
[3929s -> 3931s] 新たなツールとか新たな機能が本当に
[3931s -> 3933s] たくさん出てきそうだなっていう風なことは
[3933s -> 3935s] ちょっと思いました
[3935s -> 3937s] まさに脱チャットでもってどんどん業務が
[3937s -> 3939s] 効率化されていく未来っていうのを
[3939s -> 3941s] 見ることができました
[3941s -> 3943s] プロトタイピングが意外と
[3943s -> 3945s] 産業を変えそうだ気がしてて
[3945s -> 3947s] 生成AIを使ったプロトタイピング
[3947s -> 3949s] 要はいろんな
[3949s -> 3951s] 関数とかサーバーとか
[3951s -> 3953s] ガーって作る代わりにAPIの中に
[3953s -> 3955s] APIに
[3955s -> 3957s] インチキでヤフー
[3957s -> 3959s] ファイナンスに通信したような感じの
[3959s -> 3961s] 雰囲気で株価データを返してください
[3961s -> 3963s] リターンみたいに書いた関数とかで
[3963s -> 3965s] インチキAPIを
[3965s -> 3967s] 5秒で作れたりするようになるんで
[3967s -> 3969s] そういうので
[3969s -> 3971s] 実装が複雑だったりアルゴリズムは
[3971s -> 3973s] まだ考えないまま関数の挙動で
[3973s -> 3975s] 中身だけGPTして
[3975s -> 3977s] ガーみたいにすると結構複雑な
[3977s -> 3979s] プログラム1日で作れる
[3979s -> 3981s] ちょっと面白そうすぎて
[3981s -> 3983s] 絶対発散するんで
[3985s -> 3987s] 押してますマークも出てる
[3987s -> 3989s] すごく面白い話いただきありがとうございました
[3989s -> 3991s] ありがとうございました
[3991s -> 3993s] はい
[3993s -> 3995s] ではですね
[3995s -> 3997s] 最後のテーマになります
[3997s -> 3999s] リスクですね
[3999s -> 4001s] 今すごく発散したような形で
[4001s -> 4003s] すごく面白い話いただきましたけども
[4003s -> 4005s] 生成AIの非常に大きな
[4005s -> 4007s] 効果がある一方で非常に大きな
[4007s -> 4009s] リスクもあるといったところが
[4009s -> 4011s] 知られているところです
[4011s -> 4013s] そちらについてお話させていただければと思います
[4013s -> 4015s] こちらはですね
[4015s -> 4017s] 私と若林さんで
[4017s -> 4019s] お話できればと思いますけども
[4019s -> 4021s] そうですね私まだ自己紹介しなかったですからね
[4021s -> 4023s] デロイドトーマスの山本さんと申します
[4023s -> 4025s] もともと15年ほどですね
[4025s -> 4027s] AIの研究者やってまして
[4027s -> 4029s] 当時勤めてた会社の製品であったりとか
[4029s -> 4031s] サービスとかですね国際標準みたいなところにも
[4031s -> 4033s] 人工知能とか機械学習の技術を
[4033s -> 4035s] 入れ込むといったところをやっておりました
[4035s -> 4037s] 2年ほど前にデロイドトーマスに
[4037s -> 4039s] 参画してからは色々な企業さんに
[4039s -> 4041s] AIを導入するであったりとかですね
[4041s -> 4043s] 特にAIのリスクこのテーマでありますけど
[4043s -> 4045s] そこに対するガバナンスの支援とか
[4045s -> 4047s] といったところをですね
[4047s -> 4049s] させていただいております
[4049s -> 4051s] 特に生成AIが私に
[4051s -> 4053s] 与えた影響ですけども
[4053s -> 4055s] すごい影響がありまして
[4055s -> 4057s] 特にですねコミュニケーションについて
[4057s -> 4059s] 考える機会がすごく増えました
[4059s -> 4061s] 生成AIがですね
[4061s -> 4063s] 本当に躍進をしてからですね
[4063s -> 4065s] まず私の
[4065s -> 4067s] クライアントのですね
[4067s -> 4069s] お話しする方の属性が結構変わってきておりまして
[4069s -> 4071s] もともと結構技術の方が
[4071s -> 4073s] 多かったのがですね結構その
[4073s -> 4075s] 経営層とかあまりその技術に対して
[4075s -> 4077s] あまりそこまで深い知見を
[4077s -> 4079s] お持ちでない方々といったような
[4079s -> 4081s] 方々とのコミュニケーションが増えました
[4081s -> 4083s] まさに
[4083s -> 4085s] 誰でも使える汎用性を持った
[4085s -> 4087s] 生成AIをビジネス適用する上では
[4087s -> 4089s] そこまで技術力が
[4089s -> 4091s] 必要とされないといったところの
[4091s -> 4093s] 一つの表れなのかなというふうに
[4093s -> 4095s] 思いつつですね
[4095s -> 4097s] あとは先ほどの活用用途のところでもお話しましたけど
[4097s -> 4099s] 基本的に良い支持文は
[4099s -> 4101s] 人に対する良い
[4101s -> 4103s] 支持文は生成AIに対する良い支持文でもあってですね
[4103s -> 4105s] 最近チームメンバーから
[4105s -> 4107s] よく言われるのが山本さんなんか
[4107s -> 4109s] 私たちに対する支持が
[4109s -> 4111s] プロンプトみたいなんですけど
[4111s -> 4113s] たまにですね
[4113s -> 4115s] 皆さんもそうだと思うんですけど
[4115s -> 4117s] ステップバイステップでとか言いませんか
[4119s -> 4121s] そうですよ
[4121s -> 4123s] 本当にコミュニケーションについて
[4123s -> 4125s] 考える機会がすごく増えたなというのは
[4125s -> 4127s] 生成AIが私に与えた影響になります
[4127s -> 4129s] じゃあ若林さんお願いします
[4129s -> 4131s] はい
[4131s -> 4133s] 株式会社エリス・若林と申します
[4133s -> 4135s] 代表取締役をやっております
[4135s -> 4137s] もともとは
[4137s -> 4139s] 私はシステム開発の領域におりまして
[4139s -> 4141s] そちらで
[4141s -> 4143s] 20年近くですね
[4143s -> 4145s] 会社を経営してきました
[4145s -> 4147s] 自身も
[4147s -> 4149s] エンジニア出身という形で
[4149s -> 4151s] 事業に関わっていまして
[4153s -> 4155s] 5年前にですね
[4155s -> 4157s] AIの技術非常に可能性を感じまして
[4157s -> 4159s] データ関連の事業を始めまして
[4163s -> 4165s] 現在ですと
[4165s -> 4167s] 昨年ですね
[4167s -> 4169s] 先ほど技術のところで
[4169s -> 4171s] パネラーで参加させていただきました
[4171s -> 4173s] 井上と
[4173s -> 4175s] 共同創業という形で
[4175s -> 4177s] AI開発の株式会社エリスを
[4177s -> 4179s] 立ち上げました
[4181s -> 4183s] そこですと
[4183s -> 4185s] 生成AIとの関わり
[4185s -> 4187s] 生成AIとの関わりですと
[4187s -> 4189s] やはりこのAIベンダーとして
[4189s -> 4191s] 生成AIの
[4191s -> 4193s] 活用推進をしていくというような
[4193s -> 4195s] 立場で現在は
[4195s -> 4197s] 関わっております
[4199s -> 4201s] 生成AIによって受けた
[4201s -> 4203s] 影響で言いますと
[4203s -> 4205s] やはりシステム
[4205s -> 4207s] ですとか
[4207s -> 4209s] AIの開発の案件の
[4209s -> 4211s] 内容がですね
[4211s -> 4213s] 生成AIが出る前と
[4213s -> 4215s] 後ですと
[4215s -> 4217s] 出る前は
[4217s -> 4219s] 教師あり学習
[4219s -> 4221s] 先ほどAIの用途が
[4221s -> 4223s] 変わってきたというのは
[4223s -> 4225s] ありましたけれども
[4225s -> 4227s] 以前はスーパーバイズと
[4227s -> 4229s] ラーニングの開発が
[4229s -> 4231s] 主でした
[4231s -> 4233s] そこがですね
[4233s -> 4235s] 生成AIが出て以降
[4235s -> 4237s] 多くの方が
[4237s -> 4239s] 使えるようになって
[4239s -> 4241s] 話題にもなって
[4241s -> 4243s] 引き合いがすごく増えたり
[4243s -> 4245s] ですね
[4245s -> 4247s] そういったところの案件
[4247s -> 4249s] をすることが多くなりました
[4249s -> 4251s] そうすると
[4251s -> 4253s] AIの開発者の中でも
[4253s -> 4255s] やはりそこは
[4255s -> 4257s] 競争みたいなところが
[4257s -> 4259s] だんだん起こり始めて
[4259s -> 4261s] そこをキャッチアップして
[4261s -> 4263s] いかなきゃいけないというところに
[4263s -> 4265s] 会社としても巻き込まれて
[4265s -> 4267s] いったかなと
[4267s -> 4269s] そういうような影響がありました
[4269s -> 4271s] 今回は
[4271s -> 4273s] 経営者ですとか
[4273s -> 4275s] エンジニアですとか
[4275s -> 4277s] そういった話点で
[4277s -> 4279s] リスクについてですね
[4279s -> 4281s] お話できればと思います
[4281s -> 4283s] よろしくお願いします
[4283s -> 4285s] ちょっと時間もさせて待っておりますので
[4285s -> 4287s] クイックに聞きたいと思いますけれども
[4287s -> 4289s] 先ほど冒頭というか
[4289s -> 4291s] このパネルの冒頭で話させていただきましたけれども
[4291s -> 4293s] 今まで技術であったりとか
[4293s -> 4295s] 利活用のところで
[4295s -> 4297s] 非常に大きな効果がビジネスに
[4297s -> 4299s] 組み込めるといったところは
[4299s -> 4301s] 皆さん感じていただけたんじゃないかなという
[4301s -> 4303s] 思う一方で
[4303s -> 4305s] その表裏一体という形でしょうかね
[4305s -> 4307s] 非常に大きな効果がある一方で
[4307s -> 4309s] 大きなリスクがあると
[4309s -> 4311s] こちらちょっとまとめさせていただいたのが
[4311s -> 4313s] 生成AIの
[4313s -> 4315s] こちらを左側に記載させていただいておりまして
[4315s -> 4317s] そこから得られる
[4317s -> 4319s] 大きな効果とですね
[4319s -> 4321s] 表裏一体で出現してしまう
[4321s -> 4323s] 大きなリスクといったものを
[4323s -> 4325s] まとめさせていただいております
[4325s -> 4327s] 一番右のところは
[4327s -> 4329s] 広く一般的に認知されている
[4329s -> 4331s] リスクをですね
[4331s -> 4333s] 重たったものを挙げているような形になります
[4333s -> 4335s] 非常にリスクの
[4335s -> 4337s] 多様性があるのかなという風に
[4337s -> 4339s] 思います
[4341s -> 4343s] こちらは中長期的に
[4343s -> 4345s] 日本の場合中長期的に
[4345s -> 4347s] 見るときのリスクという
[4347s -> 4349s] 形になると思うんですけれども
[4349s -> 4351s] 皆さんご存知の通り
[4351s -> 4353s] 特にGPT-4等の
[4353s -> 4355s] 最先端のモデルは
[4355s -> 4357s] 人間が受ける試験のほとんどで
[4357s -> 4359s] 人間の合格者と同等の
[4359s -> 4361s] 点数を叩き出すと
[4361s -> 4363s] いったようなところから
[4363s -> 4365s] 機械が解ける問題を解く能力が
[4365s -> 4367s] 人間が身につける必要があるのかと
[4367s -> 4369s] これからの教育のあり方が問われているみたいな
[4369s -> 4371s] ちょっとネガティブな意見がある一方で
[4371s -> 4373s] 先ほどちょっと教育の話
[4373s -> 4375s] あとGenerative AIテストの話も
[4375s -> 4377s] ありましたけれども
[4377s -> 4379s] これまでのような
[4379s -> 4381s] 1人の先生で30人の生徒みたいな
[4381s -> 4383s] 結構確立的統一的な教育から
[4383s -> 4385s] 1人1人の個性とか
[4385s -> 4387s] 強みに合わせた
[4387s -> 4389s] まさに生成AIを教師として
[4389s -> 4391s] 使うことによってその教育革命が
[4391s -> 4393s] 起こるのではみたいな
[4393s -> 4395s] そういったポジティブな意見もあるところになります
[4395s -> 4397s] 一方でロードウェイの影響のところですね
[4397s -> 4399s] こちらもちょっと先ほどお話し出ましたけれども
[4399s -> 4401s] 特にホワイトカラーへの影響が
[4401s -> 4403s] 大きいとの見方があると
[4403s -> 4405s] 基本的に先ほど見たような
[4405s -> 4407s] 特に短期的なリスクのところから
[4407s -> 4409s] 中長期的な社会的な影響という
[4409s -> 4411s] 非常にいろいろなリスクが
[4411s -> 4413s] 知られているところになります
[4413s -> 4415s] こちらの事前情報を踏まえまして
[4415s -> 4417s] こちらも4つのテーマを
[4417s -> 4419s] 用意させていただいております
[4419s -> 4421s] 今から
[4421s -> 4423s] 多数決ですが
[4423s -> 4425s] 取らせていただく間に
[4425s -> 4427s] まずは
[4427s -> 4429s] 生成AIのリスク
[4429s -> 4431s] Aのところについて先ほど若林さんから
[4431s -> 4433s] お話があるとお話ししましたけれども
[4433s -> 4435s] 先ほどちょっとお話し
[4435s -> 4437s] させていただいたこちらの
[4437s -> 4439s] リスク以外でまさに経営者として
[4439s -> 4441s] 感じているリスクとかですね
[4441s -> 4443s] そういった視点でちょっとご意見
[4443s -> 4445s] 伺えればと思いますがいかがでしょうか
[4445s -> 4447s] そうですねやはり
[4447s -> 4449s] 生成AIで
[4449s -> 4451s] 対象とするサービスを
[4451s -> 4453s] 利用する方が
[4455s -> 4457s] 一般向けのサービスだった場合って
[4459s -> 4461s] 多くの方が目にするので
[4461s -> 4463s] 法規制以外
[4463s -> 4465s] の
[4465s -> 4467s] リスクの対策が
[4467s -> 4469s] 必要になってくるっていうのが
[4469s -> 4471s] 今
[4471s -> 4473s] 弊社でも自社サービスを
[4473s -> 4475s] 開発ともしているんですけれども
[4475s -> 4477s] そういうところが
[4477s -> 4479s] 大きいかなと思います
[4479s -> 4481s] 法規制以外の
[4481s -> 4483s] そうですね
[4483s -> 4485s] 倫理に関わる部分ですとか
[4485s -> 4487s] そういったところのリスク対策っていうのが
[4487s -> 4489s] 非常に
[4489s -> 4491s] 非常に気にするところかなと思います
[4491s -> 4493s] 今ちょっと
[4493s -> 4495s] 法規制の話が出たんですけれども
[4495s -> 4497s] 基本的に日本で現時点ですね
[4497s -> 4499s] 2023年の今日は10月の
[4499s -> 4501s] 22日ですかね
[4501s -> 4503s] 現時点では
[4503s -> 4505s] 生成AI含めAIに対する
[4505s -> 4507s] ハードローといったものは
[4507s -> 4509s] 今存在しないと
[4509s -> 4511s] 一方で欧米のところでは
[4511s -> 4513s] 規制化が進んでいるという
[4513s -> 4515s] ような話があります
[4515s -> 4517s] 特に欧州の方では
[4517s -> 4519s] アクトであったりとか
[4519s -> 4521s] あとは米国の方では
[4521s -> 4523s] シューフォーというところで
[4523s -> 4525s] 個別具体の用途に対する
[4525s -> 4527s] AIに対して
[4527s -> 4529s] いろいろな規制がかけられて
[4529s -> 4531s] いっているというような状況で
[4531s -> 4533s] 日本はこれからそういったところの
[4533s -> 4535s] 影響を受けていくような形になるんですかね
[4535s -> 4537s] そうですね
[4537s -> 4539s] 日本だと今は規制に向かうのか
[4539s -> 4541s] もしくは
[4541s -> 4543s] 自主規制みたいなところに行くのか
[4543s -> 4545s] だと今まさに議論の
[4545s -> 4547s] 最中というところがあって
[4547s -> 4549s] 直近ですと
[4549s -> 4551s] 広島AI
[4551s -> 4553s] プロセスですとか
[4553s -> 4555s] AIの戦略会議ですとか
[4555s -> 4557s] そういったところが
[4557s -> 4559s] 今年度中くらいで
[4559s -> 4561s] 一度何かしらの
[4561s -> 4563s] 結論というか
[4563s -> 4565s] 案内というか
[4565s -> 4567s] そういうのを出すと言われて
[4567s -> 4569s] まさに今はどちらに進むかが
[4569s -> 4571s] 日本の場合は議論されている
[4571s -> 4573s] 最中というところで
[4573s -> 4575s] そうですね
[4575s -> 4577s] EU、欧州ですと
[4577s -> 4579s] 規制の方向になっていまして
[4579s -> 4581s] アメリカですと
[4581s -> 4583s] フェアユースというところを
[4583s -> 4585s] ベースに個別の
[4585s -> 4587s] ケースバイケースで判断される
[4587s -> 4589s] という状況に
[4589s -> 4591s] なっています
[4591s -> 4593s] ありがとうございます
[4593s -> 4595s] まさにそういった先行する海外の
[4595s -> 4597s] 規制の動向というのは
[4597s -> 4599s] おそらく少なからず日本に影響を与えるので
[4599s -> 4601s] そういったところをウォッチするというのは
[4601s -> 4603s] そうですね
[4603s -> 4605s] まさにそこをしっかりと
[4605s -> 4607s] キャッチアップして日本の動向に
[4607s -> 4609s] 私たちは注目しておく
[4609s -> 4611s] ということが大事だと
[4611s -> 4613s] 思います
[4613s -> 4615s] ありがとうございます
[4615s -> 4617s] 多数決の方が
[4617s -> 4619s] 取り終えたとのことなので
[4619s -> 4621s] ちょっと見てみますけれども
[4621s -> 4623s] Bですね
[4623s -> 4625s] こんなリスクもあり得ますと
[4625s -> 4627s] こちらについて
[4627s -> 4629s] お話できればと思います
[4629s -> 4631s] こんなリスクもあり得ますと
[4631s -> 4633s] いろんなリスク
[4633s -> 4635s] 知られていないリスクもたくさんあると
[4635s -> 4637s] やっぱり先ほども
[4637s -> 4639s] お話しさせていただいたんですけど
[4639s -> 4641s] これからいろんな用途が生まれていくので
[4641s -> 4643s] それに応じて今は想定されないような
[4643s -> 4645s] 新たなリスクも出てくるのかなと
[4645s -> 4647s] こちらのテーマについては
[4647s -> 4649s] ぜひ皆さんにも
[4649s -> 4651s] 参加いただいて
[4651s -> 4653s] それぞれの視点から
[4653s -> 4655s] 使ってて
[4655s -> 4657s] 感じたリスクであったりとか
[4657s -> 4659s] そういったところについて
[4659s -> 4661s] 伺っていければと思います
[4661s -> 4663s] リスクは洗い出すことが非常に重要だと思われます
[4663s -> 4665s] ちょっと多様な観点でご意見伺えればと思います
[4665s -> 4667s] どうぞ
[4667s -> 4669s] プロンプトの
[4669s -> 4671s] 例えばインジェクションとかあると思うんですけど
[4671s -> 4673s] 皆さんどうされているのかな
[4673s -> 4675s] みたいなところを
[4675s -> 4677s] ぜひお聞きしたいです
[4677s -> 4679s] いかがでしょうか
[4683s -> 4685s] これ
[4685s -> 4687s] 僕確かにいい質問だと思っていて
[4687s -> 4689s] 日本の会社さんから
[4689s -> 4691s] プロンプトインジェクションに関する
[4691s -> 4693s] 消息出してくださいって言われる例あるんですよね
[4693s -> 4695s] ただ一方で
[4695s -> 4697s] じゃあ
[4697s -> 4699s] 何のリスクなんだろうっていうのは
[4699s -> 4701s] ひるがえって真面目に考えるとよく分からないと
[4701s -> 4703s] 最近オープンAIさんの
[4703s -> 4705s] プロンプトインジェクションが実は
[4705s -> 4707s] できるみたいな話がXで盛り上がったりもしてて
[4707s -> 4709s] じゃあ果たして
[4709s -> 4711s] それでダメージを負うのかというとそうでもないのかなと
[4711s -> 4713s] どういうリスクに結局
[4713s -> 4715s] 落ちるんだろうっていうのはちょっと気になりますね
[4715s -> 4717s] 多分プロンプトの中に
[4717s -> 4719s] DBへのプロトコルとか
[4719s -> 4721s] パスとか生パス入れちゃう人とかが
[4721s -> 4723s] いそうっていうのはありそうなんですけども
[4723s -> 4725s] 自分の場合だと
[4725s -> 4727s] ツイッター上で
[4727s -> 4729s] AI孔明っていうアカウントが
[4729s -> 4731s] ありまして
[4731s -> 4733s] ここで絶対プロンプトインジェクションされない
[4733s -> 4735s] 孔明さんっていうのの運用実験を
[4735s -> 4737s] 半年は行ってないから
[4737s -> 4739s] 3、4ヶ月ずっと回してて
[4739s -> 4741s] ちょっと中身
[4741s -> 4743s] やりたいこともあるんであれなんですけど
[4743s -> 4745s] ちょっと鉄壁になんで皆さん試してみてください
[4747s -> 4749s] そんな実験をされてたんです
[4749s -> 4751s] 実験してます
[4755s -> 4757s] まさにその
[4757s -> 4759s] 深津さんは本当に
[4759s -> 4761s] いろんな活用
[4761s -> 4763s] 多分人の100倍くらいいろんな活用
[4763s -> 4765s] されてると思うんですけど
[4765s -> 4767s] その中で感じたこれリスクかもみたいな
[4767s -> 4769s] ところもしあれば
[4769s -> 4771s] バックドアが怖い
[4771s -> 4773s] バックドアを探せない
[4773s -> 4775s] つまりその
[4775s -> 4777s] 言語モデルってこれから多分
[4777s -> 4779s] パソコン直接操作できたり
[4779s -> 4781s] API呼べるようになるじゃないですか
[4783s -> 4785s] 学習セットの中で
[4785s -> 4787s] なんかうんこって入れたら
[4787s -> 4789s] ハードディスク消すコマンド返すみたいなのとかが
[4789s -> 4791s] 学習データセットの中に入れられてて
[4791s -> 4793s] それみんながガーって
[4793s -> 4795s] 学習したモデルあった後に
[4795s -> 4797s] データセットからそのデータとか
[4797s -> 4799s] 消したりすると
[4799s -> 4801s] モデルのウェイトからだけだと
[4801s -> 4803s] うんこって書いたらハードディスク消されるとか
[4803s -> 4805s] わからないじゃないですか
[4805s -> 4807s] なのでバックドアが将来仕込まれたとき
[4807s -> 4809s] どうやって対策取ればいいんだろう
[4809s -> 4811s] っていうのは個人的に興味あるんですけど
[4811s -> 4813s] そうですね
[4813s -> 4815s] 基本的には背後がAIの
[4815s -> 4817s] ディープラーニングのモデルである限り
[4817s -> 4819s] 100%の対応
[4819s -> 4821s] を学習時とかに
[4821s -> 4823s] モデルに入れるっていうことが
[4823s -> 4825s] 原理的には
[4825s -> 4827s] 難しいと思うので
[4827s -> 4829s] プロンプトのインジェクションも
[4829s -> 4831s] そうですしバックドアの対策も
[4831s -> 4833s] そうですしユーザーの
[4833s -> 4835s] 入力の部分とか出力の部分とか
[4835s -> 4837s] 後処理
[4837s -> 4839s] とか
[4839s -> 4841s] アライメントに近いかもしれないんですけど
[4841s -> 4843s] そういうところで
[4843s -> 4845s] ここは技術的にも
[4845s -> 4847s] 担保していく必要が
[4847s -> 4849s] あるのかなとは思います
[4849s -> 4851s] ここは
[4851s -> 4853s] インジェクションに関しても結構
[4853s -> 4855s] 対策をしても
[4855s -> 4857s] イタチごっこになるようなところがあって
[4857s -> 4859s] あそこは
[4859s -> 4861s] 常に
[4861s -> 4863s] 監視をして
[4863s -> 4865s] 更新をしていくとか
[4865s -> 4867s] そういう付き合い方が必要になってくるのかなと
[4867s -> 4869s] 思います
[4869s -> 4871s] ありがとうございます
[4871s -> 4873s] まさに本当に新たなリスクがいろいろ出てくると
[4873s -> 4875s] 言ったようなところで
[4875s -> 4877s] ちょっとDのテーマに絡むかもしれないですけど
[4877s -> 4879s] そういったところを全て一手でやっていくっていうのは
[4879s -> 4881s] 結構難しくなってくるんじゃないかなと
[4881s -> 4883s] 生成AIが
[4883s -> 4885s] 自分で
[4885s -> 4887s] アルゴリズムを変えて
[4887s -> 4889s] インジェクションの仕方を変えるみたいなところも
[4889s -> 4891s] 多分あり得る話だと思うんですよね
[4891s -> 4893s] そうなったときに
[4893s -> 4895s] 例えば生成AIをリスク対策に
[4895s -> 4897s] 使うみたいなところって
[4897s -> 4899s] いかが思いますか
[4899s -> 4901s] 今だと
[4901s -> 4903s] 例えば画像とか
[4903s -> 4905s] リスクの検出で
[4905s -> 4907s] AIが使われているってことはありますので
[4907s -> 4909s] 今後例えば
[4909s -> 4911s] ビジョンランゲージの
[4911s -> 4913s] モデルとかで画像から
[4913s -> 4915s] 怪しいところを判定するとか
[4915s -> 4917s] そういうところに生成AIの
[4917s -> 4919s] モデルが使われる可能性っていうのは
[4919s -> 4921s] あるかなと思います
[4921s -> 4923s] なるほど
[4923s -> 4925s] 今私もAIのリスクに対する
[4925s -> 4927s] いろいろなクライアントの
[4927s -> 4929s] 業務であったりとか
[4929s -> 4931s] 研究活動もやってたりするんですけど
[4931s -> 4933s] 本当に思うのが
[4933s -> 4935s] トライモンの時代の警察官を
[4935s -> 4937s] 作っているような
[4937s -> 4939s] 気持ちになるんですよね
[4939s -> 4941s] まさにAIが
[4941s -> 4943s] 非連続的に進化を
[4943s -> 4945s] 取っていて
[4945s -> 4947s] それに対するいろいろな規制とかが
[4947s -> 4949s] 出てきているところで
[4949s -> 4951s] まさに未来につながるような
[4951s -> 4953s] 仕事をしているという
[4953s -> 4955s] 意識があります
[4955s -> 4957s] リスクはあると思うんですけど
[4957s -> 4959s] AIの評価っていうことで言うと
[4959s -> 4961s] 性能評価とかでは
[4961s -> 4963s] 結構AIを使って評価しましょう
[4963s -> 4965s] って話は
[4965s -> 4967s] 既に出てきているわけですよね
[4967s -> 4969s] 特に選択問題とかで
[4969s -> 4971s] 評価できるような能力であれば
[4971s -> 4973s] 選択問題を解かせれば
[4973s -> 4975s] いいんだけどもっとさっき
[4975s -> 4977s] 言ったみたいな論理的能力だったりとか
[4977s -> 4979s] 応用力が問われるような
[4979s -> 4981s] 能力っていうことになってくると
[4981s -> 4983s] 旧来式の
[4983s -> 4985s] テストで
[4987s -> 4989s] 試すことが難しいから
[4989s -> 4991s] 他のモデルをGPT-4で
[4991s -> 4993s] テストしましょうみたいな話もある
[4993s -> 4995s] わけですよね
[4995s -> 4997s] 今後また出てくるのは
[4997s -> 4999s] テストの内容を生成させるとか
[4999s -> 5001s] テストケースのパターンを考えさせるとか
[5001s -> 5003s] そういう話は出てくると思うんです
[5003s -> 5005s] 今まであったような
[5005s -> 5007s] 種類のテストを受けさせても
[5007s -> 5009s] もういたちごっこになっちゃって
[5009s -> 5011s] どんどん賢くなっちゃうから
[5011s -> 5013s] 今度はどんなテストを
[5013s -> 5015s] すればいいのかっていうことを
[5015s -> 5017s] 生成させようみたいな話は
[5017s -> 5019s] ちょうどさっき川内先生とも
[5019s -> 5021s] そういう話をしてたんですよね
[5021s -> 5023s] そういうセキュリティリスクの話とか
[5025s -> 5027s] 結構私の感覚では
[5027s -> 5029s] いけるんじゃないのかなと思っていて
[5029s -> 5031s] いろんな形で
[5031s -> 5033s] 本来望ましくないような入力を
[5033s -> 5035s] 生成させていれて
[5035s -> 5037s] その結果を評価するとか
[5037s -> 5039s] そういうことっていうのは
[5039s -> 5041s] 今すでにされていることとも
[5041s -> 5043s] 遠く離れてないんじゃないのかなって思います
[5043s -> 5045s] ありがとうございます
[5045s -> 5047s] まさに評価というものも
[5047s -> 5049s] 非常に多様性が
[5049s -> 5051s] 求められるようになってくるのかなと
[5051s -> 5053s] これまでのAIであれば
[5053s -> 5055s] 用途が決められて
[5055s -> 5057s] ある程度リスクっていうのは想定されたんだけれども
[5057s -> 5059s] 今も何でもできるような
[5059s -> 5061s] いかようにでも使えるAIが出てきたので
[5061s -> 5063s] リスクもすごく多様化して
[5063s -> 5065s] それに追従するようなところが
[5065s -> 5067s] 非常に重要であると
[5067s -> 5069s] さっきからテストテストテストっていう
[5069s -> 5071s] ワードが繰り返されていまして
[5071s -> 5073s] まさに人間に対するテスト
[5073s -> 5075s] JDL Generative AI テストなんですけど
[5075s -> 5077s] こういったところに対するフィードバック
[5077s -> 5079s] かけてちゃんといいものにしていく
[5079s -> 5081s] 意義として
[5081s -> 5083s] あるものにしていくっていう
[5083s -> 5085s] このループっていうものは
[5085s -> 5087s] 生成案に対しても
[5087s -> 5089s] 人間に対してもすごく必要なんだなと
[5089s -> 5091s] すごい必要だと思うんですよ
[5091s -> 5093s] なぜかというとリスクっていうのは
[5093s -> 5095s] 今法規制だったりとか
[5095s -> 5097s] 私は個人的にはそういう規制は
[5097s -> 5099s] あんまり基本的には
[5099s -> 5101s] 少ない方がいいとは思っていて
[5101s -> 5103s] というのはやっぱり今って
[5103s -> 5105s] すごくこの技術が出てきたばっかりで
[5105s -> 5107s] まだまだ新しい音とかが
[5107s -> 5109s] 生まれると思ってるんですよね
[5109s -> 5111s] ってなった時に先に
[5111s -> 5113s] これはやっちゃいけないあれはやっちゃいけない
[5113s -> 5115s] っていうことばっかり出てきちゃうと
[5115s -> 5117s] どんどんそういうイノベーションの種を
[5117s -> 5119s] 積むことになるんじゃないかなと
[5119s -> 5121s] じゃあどうしたらいいのかなって思った時に
[5121s -> 5123s] やっぱり使う側だったりとか
[5123s -> 5125s] それを使ったなんだかのアウトプットに
[5125s -> 5127s] 影響を受ける人たちが
[5127s -> 5129s] AI に対する理解を持ってるかどうか
[5129s -> 5131s] っていうことであれば
[5131s -> 5133s] もしかしたらちょっと変な答えが出てきたとしても
[5133s -> 5135s] そこからこういう事情なんじゃないかとか
[5135s -> 5137s] そういうふうに使う側のリテラシーが
[5137s -> 5139s] 上がっていくっていうことで
[5139s -> 5141s] 無駄な規制だったりとか
[5141s -> 5143s] そういったことをしなくていいっていうことになるんじゃないのかな
[5143s -> 5145s] と思っていて
[5145s -> 5147s] だからこそこのテストを受けるっていうことが
[5147s -> 5149s] すごくこの AI を発展させていく
[5149s -> 5151s] っていうことに重要なんじゃないかなと思っています
[5151s -> 5153s] ありがとうございます
[5153s -> 5155s] 素晴らしいまとめで
[5155s -> 5157s] いただきました
[5159s -> 5161s] やはり生成AI を使っていく上で
[5161s -> 5163s] リスクにどうやって対応するか
[5163s -> 5165s] っていうところと
[5165s -> 5167s] 今話していただいたところも
[5167s -> 5169s] すごく密接だなと思っていて
[5169s -> 5171s] 今回
[5171s -> 5173s] パネルディスカッションのテーマで
[5173s -> 5175s] 技術と利活用と
[5175s -> 5177s] リスクとで分かれていまして
[5177s -> 5179s] 柴田さんがさっきおっしゃったのは
[5179s -> 5181s] 後の方がちょっと固いんじゃないかって
[5181s -> 5183s] リスクでおっしゃってたんですけど
[5183s -> 5185s] そこは必ずしも
[5185s -> 5187s] 法律とか
[5187s -> 5189s] 決まりリスクっていうものが
[5189s -> 5191s] 使う上で何か堅苦しいっていうだけではなくて
[5191s -> 5193s] 実は
[5193s -> 5195s] リスクは
[5195s -> 5197s] 利活用と
[5197s -> 5199s] 技術と
[5199s -> 5201s] かなり密接に関わっていまして
[5203s -> 5205s] 例えば
[5205s -> 5207s] 法律に触れてしまうようなリスクっていうのも
[5207s -> 5209s] これは規制があって
[5209s -> 5211s] そこに引っかからないようにする必要がありますと
[5211s -> 5213s] ってなった時に
[5213s -> 5215s] 私たちも今回チャレンジをした
[5215s -> 5217s] 生成AIテストに
[5217s -> 5219s] 技術式を導入する
[5219s -> 5221s] した時に
[5221s -> 5223s] どういう
[5223s -> 5225s] 風に進めていくか
[5225s -> 5227s] 考えた時はやはり最初に
[5227s -> 5229s] この利用方法で
[5231s -> 5233s] 受講者さんに
[5233s -> 5235s] 受けてもらった時に
[5235s -> 5237s] どんなリスクがあるかっていうのを
[5237s -> 5239s] まず洗い出して考えて
[5239s -> 5241s] その上で利活用ですよね
[5241s -> 5243s] つまりこのテストが
[5243s -> 5245s] どうあってほしいか
[5245s -> 5247s] 意義でやるとか
[5247s -> 5249s] 機能を持ってほしいか
[5249s -> 5251s] っていうところを一体で考えましたし
[5253s -> 5255s] それを判断するためには
[5255s -> 5257s] 技術的にどういうことができて
[5257s -> 5259s] できていないかっていうのを
[5261s -> 5263s] 集まって議論する必要が
[5263s -> 5265s] ありましたと
[5265s -> 5267s] これがまさに
[5267s -> 5269s] 生成AIを利用して
[5269s -> 5271s] いく上の
[5271s -> 5273s] 自分たちで
[5273s -> 5275s] どういうことが
[5275s -> 5277s] 起こりうるかっていうのを考えて
[5277s -> 5279s] ちゃんと自分たちで線引きをして
[5279s -> 5281s] することによって
[5281s -> 5283s] 活用していく
[5283s -> 5285s] 使えていく
[5285s -> 5287s] それをこのチームの中でも
[5287s -> 5289s] 体験できたのかなと思ってまして
[5289s -> 5291s] そういうところから言いますと
[5291s -> 5293s] こういったところを体系的な知識を
[5293s -> 5295s] 持っていただいて
[5295s -> 5297s] 活用を進めていただくというのも
[5297s -> 5299s] 今ちょうど聞いていて
[5299s -> 5301s] 感じたところでした
[5301s -> 5303s] まさに
[5303s -> 5305s] 議論は
[5305s -> 5307s] 守りながら攻めてたっていうような感じですよね
[5307s -> 5309s] まさに守りと攻め一体になって
[5309s -> 5311s] やっていったのかな
[5311s -> 5313s] 山川さんいたから守りがあったっていう
[5313s -> 5315s] 僕だけだったら多分
[5315s -> 5317s] 攻めだけになって
[5317s -> 5319s] 多分やばかったんじゃないかなみたいなと
[5319s -> 5321s] そういう意味では素晴らしいチームで
[5321s -> 5323s] だったと思います
[5323s -> 5325s] じゃあちょっと押してますマークが
[5325s -> 5327s] 再度出ましたので
[5327s -> 5329s] ありがとうございました
[5331s -> 5333s] 最後ですね
[5333s -> 5335s] まとめさせていただきます
[5335s -> 5337s] 本当に皆さんありがとうございました
[5337s -> 5339s] 本当に多様なお話が聞けて
[5339s -> 5341s] すぐに試したい
[5341s -> 5343s] プロンプとエンジニアリングの
[5343s -> 5345s] 手法も教えていただいて早く試したいんですけれども
[5345s -> 5347s] 本当に多様な
[5347s -> 5349s] ディスカッションができたかなと思います
[5349s -> 5351s] こちらは冒頭に
[5351s -> 5353s] お見せしたアジェンダになりますけれども
[5353s -> 5355s] 実はこちらでですね
[5355s -> 5357s] 課題として扱っていたものに対する
[5357s -> 5359s] 解決の
[5359s -> 5361s] 糸口としてですね
[5361s -> 5363s] 本日のパネルディスカッションのテーマを
[5363s -> 5365s] ちょっと立て付けで
[5365s -> 5367s] 置いておりましたけれども
[5367s -> 5369s] 実はこちらですね
[5369s -> 5371s] 3つのテーマはJDLA
[5371s -> 5373s] Generative AIテスト2023のシラバ数の
[5373s -> 5375s] 体験に沿ったものになっていて
[5375s -> 5377s] まさにこういった技術で利活用
[5377s -> 5379s] リスクに対してですね
[5379s -> 5381s] ちゃんと理解を深めて
[5381s -> 5383s] 生成AIをビジネスにアドオンしていく
[5383s -> 5385s] 能力を試すようなものになっております
[5387s -> 5389s] ちょっと最後ですね
[5389s -> 5391s] 事務的なお知らせになりますけれども
[5391s -> 5393s] こういったGenerative AIテスト
[5393s -> 5395s] 今さっきもすごい話題出てきましたけど
[5395s -> 5397s] 本当にこれからもですね
[5397s -> 5399s] 進化を遂げていくように
[5399s -> 5401s] 我々も検討を続けてまいりたいと思いますが
[5401s -> 5403s] 直近ですと
[5403s -> 5405s] 12月の2日にですね
[5405s -> 5407s] 試験が決まっております
[5407s -> 5409s] 申込期間は11月28日となっておりまして
[5409s -> 5411s] 詳しい内容はですね
[5411s -> 5413s] 動画ページの概要欄のリンクよりですね
[5413s -> 5415s] 見ていただければと思います
[5417s -> 5419s] まさにこのGenerative AIテスト
[5419s -> 5421s] こういったツールも活用してですね
[5421s -> 5423s] ビジネスへのアドオン
[5423s -> 5425s] 皆様の立場から主体的にですね
[5425s -> 5427s] 推進していただければと思います
[5427s -> 5429s] では本日のイベント
[5429s -> 5431s] 以上とさせていただければと思います
[5431s -> 5433s] 本日はどうもありがとうございました
[5439s -> 5441s] ご清聴ありがとうございました
